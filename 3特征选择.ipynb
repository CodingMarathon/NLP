{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文本向量化的不足\n",
    "在将文本分词并向量化后，我们可以得到词汇表中每个词在各个文本中形成的词向量\n",
    "\n",
    "corpus=[ \"I come to China to travel\" \n",
    "\n",
    "        \"This is a car polupar in China\",  \n",
    "    \n",
    "        \"I love tea and Apple \",\n",
    "    \n",
    "        \"The work is to write some papers in science\"] \n",
    "    \n",
    "不考虑停用词，处理后得到的词向量如下：\n",
    "    \n",
    "[[0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 2 1 0 0]\n",
    "\n",
    "[0 0 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0]\n",
    " \n",
    "[1 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0]\n",
    " \n",
    "[0 0 0 0 0 1 1 0 1 0 1 1 0 1 0 1 0 1 1]]\n",
    " \n",
    "如果我们直接将统计词频后的19维特征做为文本分类的输入，会发现有一些问题。比如第一个文本，我们发现\"come\",\"China\"和“Travel”各出现1次，而“to“出现了两次。似乎看起来这个文本与”to“这个特征更关系紧密。但是实际上”to“是一个非常普遍的词，几乎所有的文本都会用到，因此虽然它的词频为2，但是重要性却比词频为1的\"China\"和“Travel”要低的多。如果我们的向量化特征仅仅用词频表示就无法反应这一点。因此我们需要进一步的预处理来反应文本的这个特征，而这个预处理就是TF-IDF。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF概述\n",
    "TF-IDF是Term Frequency -  Inverse Document Frequency的缩写，即“词频-逆文本频率”。它由两部分组成，TF和IDF。\n",
    "\n",
    "前面的TF也就是我们前面说到的词频，我们之前做的向量化也就是做了文本中各个词的出现频率统计，并作为文本特征，这个很好理解。关键是后面的这个IDF，即“逆文本频率”如何理解。在上一节中，我们讲到几乎所有文本都会出现的\"to\"其词频虽然高，但是重要性却应该比词频低的\"China\"和“Travel”要低。我们的IDF就是来帮助我们来反应这个词的重要性的，进而修正仅仅用词频表示的词特征值。\n",
    "\n",
    "概括来讲， IDF反应了一个词在所有文本中出现的频率，如果一个词在很多的文本中出现，那么它的IDF值应该低，比如上文中的“to”。而反过来如果一个词在比较少的文本中出现，那么它的IDF值应该高。比如一些专业的名词如“Machine Learning”。这样的词IDF值应该高。一个极端的情况，如果一个词在所有的文本中都出现，那么它的IDF值应该为0。\n",
    "\n",
    "上面是从定性上说明的IDF的作用，那么如何对一个词的IDF进行定量分析呢？这里直接给出一个词x的IDF的基本公式如下：\n",
    "    \n",
    "                                IDF(x)=logNN(x)\n",
    "　　　　\n",
    "其中，N代表语料库中文本的总数，而N(x)代表语料库中包含词x的文本总数。为什么IDF的基本公式应该是是上面这样的而不是像N/N(x)这样的形式呢？这就涉及到信息论相关的一些知识了。感兴趣的朋友建议阅读吴军博士的《数学之美》第11章。\n",
    "\n",
    "上面的IDF公式已经可以使用了，但是在一些特殊的情况会有一些小问题，比如某一个生僻词在语料库中没有，这样我们的分母为0， IDF没有意义了。所以常用的IDF我们需要做一些平滑，使语料库中没有出现的词也可以得到一个合适的IDF值。平滑的方法有很多种，最常见的IDF平滑后的公式之一为：\n",
    "    \n",
    "                          IDF(x)=logN+1N(x)+1+1\n",
    "\n",
    "有了IDF的定义，我们就可以计算某一个词的TF-IDF值了：\n",
    "    \n",
    "                          TF−IDF(x)=TF(x)∗IDF(x)\n",
    "\n",
    "其中TF(x)指词x在当前文本中的词频。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用scikit-learn进行TF-IDF预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 16)\t0.4424621378947393\n",
      "  (0, 15)\t0.697684463383976\n",
      "  (0, 4)\t0.4424621378947393\n",
      "  (0, 3)\t0.348842231691988\n",
      "  (1, 14)\t0.45338639737285463\n",
      "  (1, 9)\t0.45338639737285463\n",
      "  (1, 6)\t0.3574550433419527\n",
      "  (1, 5)\t0.3574550433419527\n",
      "  (1, 3)\t0.3574550433419527\n",
      "  (1, 2)\t0.45338639737285463\n",
      "  (2, 12)\t0.5\n",
      "  (2, 7)\t0.5\n",
      "  (2, 1)\t0.5\n",
      "  (2, 0)\t0.5\n",
      "  (3, 18)\t0.3565798233381452\n",
      "  (3, 17)\t0.3565798233381452\n",
      "  (3, 15)\t0.2811316284405006\n",
      "  (3, 13)\t0.3565798233381452\n",
      "  (3, 11)\t0.3565798233381452\n",
      "  (3, 10)\t0.3565798233381452\n",
      "  (3, 8)\t0.3565798233381452\n",
      "  (3, 6)\t0.2811316284405006\n",
      "  (3, 5)\t0.2811316284405006\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer  \n",
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "\n",
    "corpus=[\"I come to China to travel\", \n",
    "    \"This is a car polupar in China\",          \n",
    "    \"I love tea and Apple \",   \n",
    "    \"The work is to write some papers in science\"] \n",
    "\n",
    "vectorizer=CountVectorizer()\n",
    "\n",
    "transformer = TfidfTransformer()\n",
    "tfidf = transformer.fit_transform(vectorizer.fit_transform(corpus))  \n",
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4)\t0.4424621378947393\n",
      "  (0, 15)\t0.697684463383976\n",
      "  (0, 3)\t0.348842231691988\n",
      "  (0, 16)\t0.4424621378947393\n",
      "  (1, 3)\t0.3574550433419527\n",
      "  (1, 14)\t0.45338639737285463\n",
      "  (1, 6)\t0.3574550433419527\n",
      "  (1, 2)\t0.45338639737285463\n",
      "  (1, 9)\t0.45338639737285463\n",
      "  (1, 5)\t0.3574550433419527\n",
      "  (2, 7)\t0.5\n",
      "  (2, 12)\t0.5\n",
      "  (2, 0)\t0.5\n",
      "  (2, 1)\t0.5\n",
      "  (3, 15)\t0.2811316284405006\n",
      "  (3, 6)\t0.2811316284405006\n",
      "  (3, 5)\t0.2811316284405006\n",
      "  (3, 13)\t0.3565798233381452\n",
      "  (3, 17)\t0.3565798233381452\n",
      "  (3, 18)\t0.3565798233381452\n",
      "  (3, 11)\t0.3565798233381452\n",
      "  (3, 8)\t0.3565798233381452\n",
      "  (3, 10)\t0.3565798233381452\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf2 = TfidfVectorizer()\n",
    "re = tfidf2.fit_transform(corpus)\n",
    "print(re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
