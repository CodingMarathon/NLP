{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks for Text Classification\n",
    "\n",
    "Github: https://github.com/dennybritz/cnn-text-classification-tf\n",
    "\n",
    "Paper:  https://arxiv.org/pdf/1408.5882.pdf\n",
    "\n",
    "video：https://www.bilibili.com/video/av64670062\n",
    "\n",
    "## Task Introduction\n",
    "\n",
    "### Input\n",
    "\n",
    "A sentence in the format of a string from the movie comments.\n",
    "\n",
    "Eg. 1:  \"a thoughtful , provocative , insistently humanizing film . \"\n",
    "\n",
    "Eg. 2:  \"the effort is sincere and the results are honest , but the film is so bleak that it's hardly watchable .\"\n",
    "\n",
    "### Output\n",
    "\n",
    "A binary sentiment classification result of the input sentence, 0 indicates negative and 1 indicates positive.\n",
    "\n",
    "Eg. 1:  1 (positive)\n",
    "\n",
    "Eg. 2:  0 (negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./input\\rt-polarity.neg\n",
      "./input\\rt-polarity.pos\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('./input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5331\n",
      "simplistic , silly and tedious . \n",
      "\n",
      "it's so laddish and juvenile , only teenage boys could possibly find it funny . \n",
      "\n",
      "exploitative and largely devoid of the depth or sophistication that would make watching such a graphic treatment of the crimes bearable . \n",
      "\n",
      "[garbus] discards the potential for pathological study , exhuming instead , the skewed melodrama of the circumstantial situation . \n",
      "\n",
      "a visually flashy but narratively opaque and emotionally vapid exercise in style and mystification . \n",
      "\n",
      "the story is also as unoriginal as they come , already having been recycled more times than i'd care to count . \n",
      "\n",
      "about the only thing to give the movie points for is bravado -- to take an entirely stale concept and push it through the audience's meat grinder one more time . \n",
      "\n",
      "not so much farcical as sour . \n",
      "\n",
      "unfortunately the story and the actors are served with a hack script . \n",
      "\n",
      "all the more disquieting for its relatively gore-free allusions to the serial murders , but it falls down in its attempts to humanize its subject . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open(\"./input/rt-polarity.neg\", \"r\", encoding='utf-8')\n",
    "a = f.readlines()\n",
    "print(len(a))\n",
    "for i in range(10):\n",
    "    print(a[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()\n",
    "\n",
    "\n",
    "def load_data_and_labels(positive_data_file, negative_data_file):\n",
    "    \"\"\"\n",
    "    Loads MR polarity data from files, splits the data into words and generates labels.\n",
    "    Returns split sentences and labels.\n",
    "    \"\"\"\n",
    "    # Load data from files\n",
    "    positive_examples = list(open(positive_data_file, \"r\", encoding='utf-8').readlines())\n",
    "    positive_examples = [s.strip() for s in positive_examples]\n",
    "    negative_examples = list(open(negative_data_file, \"r\", encoding='utf-8').readlines())\n",
    "    negative_examples = [s.strip() for s in negative_examples]\n",
    "    # Split by words\n",
    "    x_text = positive_examples + negative_examples\n",
    "    x_text = [clean_str(sent) for sent in x_text]\n",
    "    # Generate labels\n",
    "    # 第一维表示为负面的概率，第二维表示为正面的概率\n",
    "    positive_labels = [[0, 1] for _ in positive_examples]\n",
    "    negative_labels = [[1, 0] for _ in negative_examples]\n",
    "    y = np.concatenate([positive_labels, negative_labels], 0)\n",
    "    return [x_text, y]\n",
    "\n",
    "\n",
    "def batch_iter(data, batch_size, num_epochs, shuffle=True):\n",
    "    \"\"\"\n",
    "    Generates a batch iterator for a dataset.\n",
    "    \"\"\"\n",
    "    data = np.array(data)\n",
    "    data_size = len(data)\n",
    "    num_batches_per_epoch = int((len(data)-1)/batch_size) + 1\n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle the data at each epoch\n",
    "        if shuffle:\n",
    "            shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "            shuffled_data = data[shuffle_indices]\n",
    "        else:\n",
    "            shuffled_data = data\n",
    "        for batch_num in range(num_batches_per_epoch):\n",
    "            start_index = batch_num * batch_size\n",
    "            end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "            yield shuffled_data[start_index:end_index]"
   ]
  },
  {
   "attachments": {
    "cnn%20model.png": {
     "image/png": "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"
    },
    "cross%20entropy.png": {
     "image/png": "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"
    },
    "softmax.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Model Description\n",
    "\n",
    "![cnn%20model.png](attachment:cnn%20model.png)\n",
    "\n",
    "### Embedding Lookup Layer (Line 22 - 28)\n",
    "\n",
    "You may use Word2vec or GloVe to replace the random initialization.\n",
    "\n",
    "Tunable hyper parameters:\n",
    "\n",
    "    embedding_dim\n",
    "\n",
    "### Convolution Layer (Line 34 - 45)\n",
    "\n",
    "You may try different nonlinearity other than relu.\n",
    "\n",
    "Tunable hyper parameters:\n",
    "\n",
    "    filter_sizes\n",
    "    num_filters\n",
    "    \n",
    "### Max Pooling Layer (Line 46 - 53)\n",
    "\n",
    "### Fully Connected Layer with Dropout and Softmax Output (Line 60 - 79)\n",
    "\n",
    "Softmax function:\n",
    "\n",
    "![softmax.png](attachment:softmax.png)\n",
    "\n",
    "Cross Entropy Loss:\n",
    "\n",
    "![cross%20entropy.png](attachment:cross%20entropy.png)\n",
    "\n",
    "Tunable hyper parameters:\n",
    "\n",
    "    dropout_keep_prob (only for training)\n",
    "    l2_reg_lambda\n",
    "\n",
    "All the tunable hyper parameters can be tuned at the third code block (train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class TextCNN(object):\n",
    "    \"\"\"\n",
    "    A CNN for text classification.\n",
    "    Uses an embedding layer, followed by a convolutional, max-pooling and softmax layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, sequence_length, num_classes, vocab_size, embedding_size, filter_sizes, num_filters, l2_reg_lambda=0.0):\n",
    "\n",
    "        # Placeholders for input, output and dropout\n",
    "        self.input_x = tf.placeholder(tf.int32, [None, sequence_length], name=\"input_x\")\n",
    "        self.input_y = tf.placeholder(tf.float32, [None, num_classes], name=\"input_y\")\n",
    "        self.dropout_keep_prob = tf.placeholder(tf.float32, name=\"dropout_keep_prob\")\n",
    "\n",
    "        # Keeping track of l2 regularization loss (optional)\n",
    "        l2_loss = tf.constant(0.0)\n",
    "\n",
    "        # Embedding layer\n",
    "        with tf.device('/cpu:0'), tf.name_scope(\"embedding\"):\n",
    "            # 随机初始化词嵌入，可以改成word2vec\n",
    "            self.W = tf.Variable(\n",
    "                tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0),\n",
    "                name=\"W\")\n",
    "            self.embedded_chars = tf.nn.embedding_lookup(self.W, self.input_x)\n",
    "            # 在最后面增加一个维度，[None, sequence_length, embedding_size，1]\n",
    "            self.embedded_chars_expanded = tf.expand_dims(self.embedded_chars, -1)\n",
    "\n",
    "        # Create a convolution + maxpool layer for each filter size\n",
    "        pooled_outputs = []\n",
    "        for i, filter_size in enumerate(filter_sizes):\n",
    "            with tf.name_scope(\"conv-maxpool-%s\" % filter_size):\n",
    "                # Convolution Layer\n",
    "                filter_shape = [filter_size, embedding_size, 1, num_filters]\n",
    "                W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1), name=\"W\")\n",
    "                b = tf.Variable(tf.constant(0.1, shape=[num_filters]), name=\"b\")\n",
    "                conv = tf.nn.conv2d(\n",
    "                    self.embedded_chars_expanded,\n",
    "                    W,\n",
    "                    strides=[1, 1, 1, 1],\n",
    "                    padding=\"VALID\",\n",
    "                    name=\"conv\")\n",
    "                # Apply nonlinearity\n",
    "                h = tf.nn.relu(tf.nn.bias_add(conv, b), name=\"relu\")\n",
    "                # Maxpooling over the outputs\n",
    "                pooled = tf.nn.max_pool(\n",
    "                    h,\n",
    "                    ksize=[1, sequence_length - filter_size + 1, 1, 1],\n",
    "                    strides=[1, 1, 1, 1],\n",
    "                    padding='VALID',\n",
    "                    name=\"pool\")\n",
    "                # [[batch,1,1,num_filters],[batch,1,1,num_filters],[batch,1,1,num_filters],....]\n",
    "                pooled_outputs.append(pooled)\n",
    "\n",
    "        # Combine all the pooled features\n",
    "        num_filters_total = num_filters * len(filter_sizes)\n",
    "        # [batch,1,1,num_filters_total]\n",
    "        self.h_pool = tf.concat(pooled_outputs, 3)\n",
    "        # [batch,num_filters_total]\n",
    "        self.h_pool_flat = tf.reshape(self.h_pool, [-1, num_filters_total])\n",
    "\n",
    "        # Add dropout\n",
    "        with tf.name_scope(\"dropout\"):\n",
    "            self.h_drop = tf.nn.dropout(self.h_pool_flat, self.dropout_keep_prob)\n",
    "\n",
    "        # Final (unnormalized) scores and predictions\n",
    "        with tf.name_scope(\"output\"):\n",
    "            W = tf.get_variable(\n",
    "                \"W\",\n",
    "                shape=[num_filters_total, num_classes],\n",
    "                initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[num_classes]), name=\"b\")\n",
    "            l2_loss += tf.nn.l2_loss(W)\n",
    "            l2_loss += tf.nn.l2_loss(b)\n",
    "            self.scores = tf.nn.xw_plus_b(self.h_drop, W, b, name=\"scores\")\n",
    "            self.predictions = tf.argmax(self.scores, 1, name=\"predictions\")\n",
    "\n",
    "        # Calculate mean cross-entropy loss\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            losses = tf.nn.softmax_cross_entropy_with_logits(logits=self.scores, labels=self.input_y)\n",
    "            self.loss = tf.reduce_mean(losses) + l2_reg_lambda * l2_loss\n",
    "\n",
    "        # Accuracy\n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            correct_predictions = tf.equal(self.predictions, tf.argmax(self.input_y, 1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "\n",
    "Some tunable training hyper parameters which may influence the results:\n",
    "\n",
    "    batch_size\n",
    "    num_epochs\n",
    "    optimizer (line 94)\n",
    "\n",
    "All the tunable hyper parameters can be tuned here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "WARNING:tensorflow:From <ipython-input-5-204bbea25ab2>:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0429 11:38:06.188759  8284 deprecation.py:323] From <ipython-input-5-204bbea25ab2>:54: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\tensorflow1.15-cpu\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\preprocessing\\text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0429 11:38:06.188759  8284 deprecation.py:323] From D:\\anaconda3\\envs\\tensorflow1.15-cpu\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\preprocessing\\text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\tensorflow1.15-cpu\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\preprocessing\\text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0429 11:38:06.204387  8284 deprecation.py:323] From D:\\anaconda3\\envs\\tensorflow1.15-cpu\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\preprocessing\\text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 18758\n",
      "Train/Dev split: 9596/1066\n",
      "WARNING:tensorflow:From <ipython-input-4-93eeefc639d8>:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0429 11:38:06.774735  8284 deprecation.py:506] From <ipython-input-4-93eeefc639d8>:62: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0429 11:38:06.791117  8284 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-93eeefc639d8>:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0429 11:38:06.814099  8284 deprecation.py:323] From <ipython-input-4-93eeefc639d8>:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0429 11:38:07.066048  8284 summary_op_util.py:66] Summary name embedding/W:0/grad/hist is illegal; using embedding/W_0/grad/hist instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0429 11:38:07.119035  8284 summary_op_util.py:66] Summary name embedding/W:0/grad/sparsity is illegal; using embedding/W_0/grad/sparsity instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0429 11:38:07.125014  8284 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/hist is illegal; using conv-maxpool-3/W_0/grad/hist instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0429 11:38:07.161021  8284 summary_op_util.py:66] Summary name conv-maxpool-3/W:0/grad/sparsity is illegal; using conv-maxpool-3/W_0/grad/sparsity instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0429 11:38:07.166995  8284 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0429 11:38:07.193977  8284 summary_op_util.py:66] Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0429 11:38:07.198974  8284 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/hist is illegal; using conv-maxpool-4/W_0/grad/hist instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0429 11:38:07.234951  8284 summary_op_util.py:66] Summary name conv-maxpool-4/W:0/grad/sparsity is illegal; using conv-maxpool-4/W_0/grad/sparsity instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0429 11:38:07.241947  8284 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0429 11:38:07.270933  8284 summary_op_util.py:66] Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0429 11:38:07.277927  8284 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/hist is illegal; using conv-maxpool-5/W_0/grad/hist instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0429 11:38:07.315905  8284 summary_op_util.py:66] Summary name conv-maxpool-5/W:0/grad/sparsity is illegal; using conv-maxpool-5/W_0/grad/sparsity instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0429 11:38:07.322901  8284 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0429 11:38:07.355883  8284 summary_op_util.py:66] Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0429 11:38:07.363877  8284 summary_op_util.py:66] Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0429 11:38:07.396857  8284 summary_op_util.py:66] Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0429 11:38:07.400856  8284 summary_op_util.py:66] Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0429 11:38:07.427839  8284 summary_op_util.py:66] Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to E:\\Project\\伯禹自然语言处理\\03基于卷积神经网络的文本分类\\runs\\1588131485\n",
      "\n",
      "2020-04-29T11:38:08.745096: step 1, loss 2.51557, acc 0.53125\n",
      "2020-04-29T11:38:08.944150: step 2, loss 2.06716, acc 0.53125\n",
      "2020-04-29T11:38:09.145035: step 3, loss 1.72793, acc 0.546875\n",
      "2020-04-29T11:38:09.340921: step 4, loss 2.37388, acc 0.484375\n",
      "2020-04-29T11:38:09.549802: step 5, loss 2.17035, acc 0.515625\n",
      "2020-04-29T11:38:09.740339: step 6, loss 1.86862, acc 0.5625\n",
      "2020-04-29T11:38:09.910865: step 7, loss 1.63498, acc 0.640625\n",
      "2020-04-29T11:38:10.096393: step 8, loss 2.37348, acc 0.53125\n",
      "2020-04-29T11:38:10.256005: step 9, loss 1.86854, acc 0.609375\n",
      "2020-04-29T11:38:10.451704: step 10, loss 2.78262, acc 0.40625\n",
      "2020-04-29T11:38:10.650589: step 11, loss 1.55885, acc 0.5\n",
      "2020-04-29T11:38:10.822902: step 12, loss 1.45327, acc 0.546875\n",
      "2020-04-29T11:38:11.003520: step 13, loss 2.6656, acc 0.46875\n",
      "2020-04-29T11:38:11.168424: step 14, loss 1.957, acc 0.5625\n",
      "2020-04-29T11:38:11.337308: step 15, loss 1.61012, acc 0.484375\n",
      "2020-04-29T11:38:11.493546: step 16, loss 1.77631, acc 0.453125\n",
      "2020-04-29T11:38:11.674370: step 17, loss 2.2001, acc 0.4375\n",
      "2020-04-29T11:38:11.846231: step 18, loss 2.02014, acc 0.46875\n",
      "2020-04-29T11:38:12.014458: step 19, loss 2.2016, acc 0.4375\n",
      "2020-04-29T11:38:12.186320: step 20, loss 2.01752, acc 0.4375\n",
      "2020-04-29T11:38:12.358622: step 21, loss 2.02599, acc 0.546875\n",
      "2020-04-29T11:38:12.514860: step 22, loss 1.96705, acc 0.5\n",
      "2020-04-29T11:38:12.692683: step 23, loss 1.73905, acc 0.484375\n",
      "2020-04-29T11:38:12.848922: step 24, loss 1.64448, acc 0.578125\n",
      "2020-04-29T11:38:13.024995: step 25, loss 1.45442, acc 0.609375\n",
      "2020-04-29T11:38:13.181233: step 26, loss 1.81636, acc 0.484375\n",
      "2020-04-29T11:38:13.360172: step 27, loss 1.92581, acc 0.515625\n",
      "2020-04-29T11:38:13.532035: step 28, loss 1.85586, acc 0.5625\n",
      "2020-04-29T11:38:13.709900: step 29, loss 1.97141, acc 0.53125\n",
      "2020-04-29T11:38:13.881763: step 30, loss 1.69037, acc 0.625\n",
      "2020-04-29T11:38:14.055748: step 31, loss 1.80269, acc 0.609375\n",
      "2020-04-29T11:38:14.221094: step 32, loss 1.38295, acc 0.578125\n",
      "2020-04-29T11:38:14.392738: step 33, loss 1.94747, acc 0.5\n",
      "2020-04-29T11:38:14.564601: step 34, loss 1.8333, acc 0.515625\n",
      "2020-04-29T11:38:14.743911: step 35, loss 1.81818, acc 0.484375\n",
      "2020-04-29T11:38:14.900148: step 36, loss 2.12897, acc 0.578125\n",
      "2020-04-29T11:38:15.078105: step 37, loss 1.91588, acc 0.4375\n",
      "2020-04-29T11:38:15.234344: step 38, loss 1.63643, acc 0.625\n",
      "2020-04-29T11:38:15.396034: step 39, loss 1.51533, acc 0.609375\n",
      "2020-04-29T11:38:15.567896: step 40, loss 1.61792, acc 0.5\n",
      "2020-04-29T11:38:15.729324: step 41, loss 2.49481, acc 0.328125\n",
      "2020-04-29T11:38:15.901187: step 42, loss 1.58875, acc 0.578125\n",
      "2020-04-29T11:38:16.078943: step 43, loss 2.4244, acc 0.46875\n",
      "2020-04-29T11:38:16.266834: step 44, loss 1.87222, acc 0.5625\n",
      "2020-04-29T11:38:16.457723: step 45, loss 1.75397, acc 0.578125\n",
      "2020-04-29T11:38:16.613729: step 46, loss 1.9274, acc 0.484375\n",
      "2020-04-29T11:38:16.783510: step 47, loss 1.49277, acc 0.515625\n",
      "2020-04-29T11:38:16.959783: step 48, loss 1.47108, acc 0.546875\n",
      "2020-04-29T11:38:17.132683: step 49, loss 2.1006, acc 0.453125\n",
      "2020-04-29T11:38:17.287022: step 50, loss 1.56786, acc 0.515625\n",
      "2020-04-29T11:38:17.467143: step 51, loss 1.41539, acc 0.625\n",
      "2020-04-29T11:38:17.623383: step 52, loss 1.76899, acc 0.515625\n",
      "2020-04-29T11:38:17.799355: step 53, loss 1.95789, acc 0.515625\n",
      "2020-04-29T11:38:17.979068: step 54, loss 2.04767, acc 0.4375\n",
      "2020-04-29T11:38:18.149967: step 55, loss 1.55756, acc 0.5625\n",
      "2020-04-29T11:38:18.305595: step 56, loss 1.50732, acc 0.5625\n",
      "2020-04-29T11:38:18.485164: step 57, loss 1.62192, acc 0.5\n",
      "2020-04-29T11:38:18.684050: step 58, loss 1.4574, acc 0.578125\n",
      "2020-04-29T11:38:18.872942: step 59, loss 1.57716, acc 0.59375\n",
      "2020-04-29T11:38:19.050840: step 60, loss 1.69685, acc 0.515625\n",
      "2020-04-29T11:38:19.244728: step 61, loss 1.93426, acc 0.5\n",
      "2020-04-29T11:38:19.403841: step 62, loss 1.43274, acc 0.5\n",
      "2020-04-29T11:38:19.605051: step 63, loss 1.96093, acc 0.59375\n",
      "2020-04-29T11:38:19.798937: step 64, loss 1.69011, acc 0.53125\n",
      "2020-04-29T11:38:19.999822: step 65, loss 1.87026, acc 0.453125\n",
      "2020-04-29T11:38:20.169949: step 66, loss 1.35592, acc 0.515625\n",
      "2020-04-29T11:38:20.370942: step 67, loss 2.0476, acc 0.421875\n",
      "2020-04-29T11:38:20.575826: step 68, loss 1.47313, acc 0.515625\n",
      "2020-04-29T11:38:20.773711: step 69, loss 1.27355, acc 0.5625\n",
      "2020-04-29T11:38:20.976595: step 70, loss 2.02715, acc 0.515625\n",
      "2020-04-29T11:38:21.170481: step 71, loss 1.28921, acc 0.609375\n",
      "2020-04-29T11:38:21.366369: step 72, loss 1.5311, acc 0.53125\n",
      "2020-04-29T11:38:21.540109: step 73, loss 2.05117, acc 0.53125\n",
      "2020-04-29T11:38:21.727003: step 74, loss 1.39664, acc 0.578125\n",
      "2020-04-29T11:38:21.905450: step 75, loss 1.60075, acc 0.4375\n",
      "2020-04-29T11:38:22.084188: step 76, loss 2.05825, acc 0.484375\n",
      "2020-04-29T11:38:22.280076: step 77, loss 1.16619, acc 0.65625\n",
      "2020-04-29T11:38:22.458910: step 78, loss 1.41248, acc 0.515625\n",
      "2020-04-29T11:38:22.658795: step 79, loss 1.62963, acc 0.5625\n",
      "2020-04-29T11:38:22.818567: step 80, loss 1.25726, acc 0.625\n",
      "2020-04-29T11:38:22.995835: step 81, loss 1.86018, acc 0.546875\n",
      "2020-04-29T11:38:23.184727: step 82, loss 1.75442, acc 0.5\n",
      "2020-04-29T11:38:23.385451: step 83, loss 2.00153, acc 0.390625\n",
      "2020-04-29T11:38:23.577768: step 84, loss 1.31368, acc 0.5625\n",
      "2020-04-29T11:38:23.775320: step 85, loss 1.48015, acc 0.515625\n",
      "2020-04-29T11:38:23.968648: step 86, loss 1.41923, acc 0.640625\n",
      "2020-04-29T11:38:24.167534: step 87, loss 1.57792, acc 0.546875\n",
      "2020-04-29T11:38:24.370417: step 88, loss 1.10682, acc 0.625\n",
      "2020-04-29T11:38:24.593290: step 89, loss 1.48041, acc 0.5625\n",
      "2020-04-29T11:38:24.775184: step 90, loss 1.82522, acc 0.5\n",
      "2020-04-29T11:38:24.971071: step 91, loss 1.43679, acc 0.546875\n",
      "2020-04-29T11:38:25.146970: step 92, loss 2.03036, acc 0.46875\n",
      "2020-04-29T11:38:25.383836: step 93, loss 1.62838, acc 0.59375\n",
      "2020-04-29T11:38:25.571943: step 94, loss 1.55156, acc 0.5625\n",
      "2020-04-29T11:38:25.759145: step 95, loss 1.64493, acc 0.46875\n",
      "2020-04-29T11:38:25.939514: step 96, loss 1.02234, acc 0.625\n",
      "2020-04-29T11:38:26.107649: step 97, loss 1.65412, acc 0.453125\n",
      "2020-04-29T11:38:26.279511: step 98, loss 1.54793, acc 0.546875\n",
      "2020-04-29T11:38:26.456462: step 99, loss 1.55771, acc 0.515625\n",
      "2020-04-29T11:38:26.612699: step 100, loss 1.23078, acc 0.546875\n",
      "\n",
      "Evaluation:\n",
      "2020-04-29T11:38:26.886216: step 100, loss 0.962184, acc 0.545028\n",
      "\n",
      "Saved model checkpoint to E:\\Project\\伯禹自然语言处理\\03基于卷积神经网络的文本分类\\runs\\1588131485\\checkpoints\\model-100\n",
      "\n",
      "2020-04-29T11:38:27.485886: step 101, loss 1.72424, acc 0.453125\n",
      "2020-04-29T11:38:27.659824: step 102, loss 1.66328, acc 0.453125\n",
      "2020-04-29T11:38:27.835704: step 103, loss 1.50742, acc 0.59375\n",
      "2020-04-29T11:38:28.024595: step 104, loss 1.44399, acc 0.59375\n",
      "2020-04-29T11:38:28.195799: step 105, loss 1.49232, acc 0.46875\n",
      "2020-04-29T11:38:28.370173: step 106, loss 1.41932, acc 0.578125\n",
      "2020-04-29T11:38:28.522674: step 107, loss 1.37985, acc 0.53125\n",
      "2020-04-29T11:38:28.694487: step 108, loss 1.3917, acc 0.5625\n",
      "2020-04-29T11:38:28.866351: step 109, loss 1.8537, acc 0.5\n",
      "2020-04-29T11:38:29.050604: step 110, loss 1.39403, acc 0.578125\n",
      "2020-04-29T11:38:29.217952: step 111, loss 1.28463, acc 0.53125\n",
      "2020-04-29T11:38:29.377748: step 112, loss 1.25613, acc 0.59375\n",
      "2020-04-29T11:38:29.559589: step 113, loss 1.55101, acc 0.515625\n",
      "2020-04-29T11:38:29.742484: step 114, loss 1.49592, acc 0.5\n",
      "2020-04-29T11:38:29.913660: step 115, loss 0.982889, acc 0.609375\n",
      "2020-04-29T11:38:30.085568: step 116, loss 1.91849, acc 0.421875\n",
      "2020-04-29T11:38:30.242813: step 117, loss 1.27094, acc 0.5\n",
      "2020-04-29T11:38:30.441212: step 118, loss 1.60053, acc 0.484375\n",
      "2020-04-29T11:38:30.641097: step 119, loss 1.30414, acc 0.5625\n",
      "2020-04-29T11:38:30.837985: step 120, loss 1.36035, acc 0.46875\n",
      "2020-04-29T11:38:31.001381: step 121, loss 1.42632, acc 0.59375\n",
      "2020-04-29T11:38:31.199101: step 122, loss 1.39556, acc 0.421875\n",
      "2020-04-29T11:38:31.359142: step 123, loss 1.47023, acc 0.515625\n",
      "2020-04-29T11:38:31.533631: step 124, loss 1.76599, acc 0.484375\n",
      "2020-04-29T11:38:31.723801: step 125, loss 1.44029, acc 0.5\n",
      "2020-04-29T11:38:31.936678: step 126, loss 1.35992, acc 0.546875\n",
      "2020-04-29T11:38:32.157551: step 127, loss 1.47586, acc 0.515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-29T11:38:32.364432: step 128, loss 1.25514, acc 0.59375\n",
      "2020-04-29T11:38:32.536591: step 129, loss 1.19885, acc 0.53125\n",
      "2020-04-29T11:38:32.762669: step 130, loss 1.81976, acc 0.53125\n",
      "2020-04-29T11:38:32.982542: step 131, loss 1.22768, acc 0.578125\n",
      "2020-04-29T11:38:33.176431: step 132, loss 1.37515, acc 0.5\n",
      "2020-04-29T11:38:33.334055: step 133, loss 1.00475, acc 0.640625\n",
      "2020-04-29T11:38:33.553187: step 134, loss 1.62492, acc 0.515625\n",
      "2020-04-29T11:38:33.742077: step 135, loss 1.24625, acc 0.453125\n",
      "2020-04-29T11:38:33.953964: step 136, loss 1.33309, acc 0.578125\n",
      "2020-04-29T11:38:34.144846: step 137, loss 1.17793, acc 0.59375\n",
      "2020-04-29T11:38:34.324786: step 138, loss 1.69571, acc 0.4375\n",
      "2020-04-29T11:38:34.530667: step 139, loss 1.31817, acc 0.546875\n",
      "2020-04-29T11:38:34.701435: step 140, loss 1.22115, acc 0.546875\n",
      "2020-04-29T11:38:34.871928: step 141, loss 1.00176, acc 0.625\n",
      "2020-04-29T11:38:35.043752: step 142, loss 1.31794, acc 0.46875\n",
      "2020-04-29T11:38:35.250631: step 143, loss 1.23973, acc 0.546875\n",
      "2020-04-29T11:38:35.441521: step 144, loss 1.05272, acc 0.59375\n",
      "2020-04-29T11:38:35.625416: step 145, loss 1.14468, acc 0.546875\n",
      "2020-04-29T11:38:35.862282: step 146, loss 1.35041, acc 0.5625\n",
      "2020-04-29T11:38:36.097144: step 147, loss 1.39137, acc 0.46875\n",
      "2020-04-29T11:38:36.320018: step 148, loss 1.22803, acc 0.515625\n",
      "2020-04-29T11:38:36.530895: step 149, loss 1.03653, acc 0.53125\n",
      "2020-04-29T11:38:36.698588: step 150, loss 1.50864, acc 0.45\n",
      "2020-04-29T11:38:36.884136: step 151, loss 0.914385, acc 0.703125\n",
      "2020-04-29T11:38:37.041379: step 152, loss 0.687803, acc 0.71875\n",
      "2020-04-29T11:38:37.220477: step 153, loss 1.32825, acc 0.515625\n",
      "2020-04-29T11:38:37.392339: step 154, loss 1.24059, acc 0.453125\n",
      "2020-04-29T11:38:37.569994: step 155, loss 1.23404, acc 0.453125\n",
      "2020-04-29T11:38:37.726231: step 156, loss 1.03986, acc 0.625\n",
      "2020-04-29T11:38:37.891249: step 157, loss 0.810994, acc 0.65625\n",
      "2020-04-29T11:38:38.063111: step 158, loss 0.920658, acc 0.703125\n",
      "2020-04-29T11:38:38.236794: step 159, loss 0.89399, acc 0.625\n",
      "2020-04-29T11:38:38.429682: step 160, loss 1.09636, acc 0.640625\n",
      "2020-04-29T11:38:38.586827: step 161, loss 0.745664, acc 0.671875\n",
      "2020-04-29T11:38:38.755124: step 162, loss 1.16349, acc 0.484375\n",
      "2020-04-29T11:38:38.926986: step 163, loss 0.924229, acc 0.609375\n",
      "2020-04-29T11:38:39.087907: step 164, loss 1.35701, acc 0.484375\n",
      "2020-04-29T11:38:39.259770: step 165, loss 0.76123, acc 0.671875\n",
      "2020-04-29T11:38:39.422605: step 166, loss 0.767482, acc 0.703125\n",
      "2020-04-29T11:38:39.594466: step 167, loss 0.830171, acc 0.625\n",
      "2020-04-29T11:38:39.771437: step 168, loss 0.800143, acc 0.65625\n",
      "2020-04-29T11:38:39.943301: step 169, loss 1.24505, acc 0.546875\n",
      "2020-04-29T11:38:40.115295: step 170, loss 0.958756, acc 0.625\n",
      "2020-04-29T11:38:40.271533: step 171, loss 1.07807, acc 0.609375\n",
      "2020-04-29T11:38:40.443227: step 172, loss 0.877182, acc 0.671875\n",
      "2020-04-29T11:38:40.615089: step 173, loss 1.10606, acc 0.578125\n",
      "2020-04-29T11:38:40.788852: step 174, loss 0.927369, acc 0.625\n",
      "2020-04-29T11:38:40.945089: step 175, loss 1.11765, acc 0.546875\n",
      "2020-04-29T11:38:41.122781: step 176, loss 1.22031, acc 0.546875\n",
      "2020-04-29T11:38:41.279020: step 177, loss 1.15988, acc 0.625\n",
      "2020-04-29T11:38:41.460170: step 178, loss 0.803085, acc 0.703125\n",
      "2020-04-29T11:38:41.616409: step 179, loss 0.776418, acc 0.65625\n",
      "2020-04-29T11:38:41.796861: step 180, loss 1.02945, acc 0.609375\n",
      "2020-04-29T11:38:41.953101: step 181, loss 1.03558, acc 0.578125\n",
      "2020-04-29T11:38:42.125464: step 182, loss 0.8492, acc 0.609375\n",
      "2020-04-29T11:38:42.297327: step 183, loss 1.12914, acc 0.5625\n",
      "2020-04-29T11:38:42.459112: step 184, loss 0.879531, acc 0.625\n",
      "2020-04-29T11:38:42.630974: step 185, loss 0.744717, acc 0.671875\n",
      "2020-04-29T11:38:42.792686: step 186, loss 1.01164, acc 0.640625\n",
      "2020-04-29T11:38:42.966078: step 187, loss 1.20806, acc 0.5625\n",
      "2020-04-29T11:38:43.140049: step 188, loss 0.899671, acc 0.609375\n",
      "2020-04-29T11:38:43.311912: step 189, loss 0.535044, acc 0.6875\n",
      "2020-04-29T11:38:43.477192: step 190, loss 0.993128, acc 0.640625\n",
      "2020-04-29T11:38:43.649054: step 191, loss 1.00904, acc 0.625\n",
      "2020-04-29T11:38:43.825889: step 192, loss 1.19378, acc 0.578125\n",
      "2020-04-29T11:38:43.985739: step 193, loss 1.35118, acc 0.453125\n",
      "2020-04-29T11:38:44.163767: step 194, loss 1.27674, acc 0.53125\n",
      "2020-04-29T11:38:44.335630: step 195, loss 1.07352, acc 0.578125\n",
      "2020-04-29T11:38:44.511540: step 196, loss 0.564789, acc 0.78125\n",
      "2020-04-29T11:38:44.683403: step 197, loss 1.19963, acc 0.484375\n",
      "2020-04-29T11:38:44.860242: step 198, loss 1.28416, acc 0.546875\n",
      "2020-04-29T11:38:45.016102: step 199, loss 1.3494, acc 0.515625\n",
      "2020-04-29T11:38:45.178589: step 200, loss 0.837051, acc 0.640625\n",
      "\n",
      "Evaluation:\n",
      "2020-04-29T11:38:45.419831: step 200, loss 0.720213, acc 0.582552\n",
      "\n",
      "Saved model checkpoint to E:\\Project\\伯禹自然语言处理\\03基于卷积神经网络的文本分类\\runs\\1588131485\\checkpoints\\model-200\n",
      "\n",
      "2020-04-29T11:38:46.057809: step 201, loss 0.582176, acc 0.75\n",
      "2020-04-29T11:38:46.235256: step 202, loss 0.725237, acc 0.65625\n",
      "2020-04-29T11:38:46.391496: step 203, loss 0.996131, acc 0.59375\n",
      "2020-04-29T11:38:46.565146: step 204, loss 0.924004, acc 0.625\n",
      "2020-04-29T11:38:46.737009: step 205, loss 1.25553, acc 0.46875\n",
      "2020-04-29T11:38:46.912176: step 206, loss 0.96608, acc 0.5625\n",
      "2020-04-29T11:38:47.068415: step 207, loss 0.940511, acc 0.625\n",
      "2020-04-29T11:38:47.245729: step 208, loss 0.96888, acc 0.625\n",
      "2020-04-29T11:38:47.401968: step 209, loss 0.763368, acc 0.671875\n",
      "2020-04-29T11:38:47.582350: step 210, loss 0.826541, acc 0.65625\n",
      "2020-04-29T11:38:47.738589: step 211, loss 1.07467, acc 0.609375\n",
      "2020-04-29T11:38:47.937349: step 212, loss 1.07856, acc 0.59375\n",
      "2020-04-29T11:38:48.109761: step 213, loss 0.96829, acc 0.625\n",
      "2020-04-29T11:38:48.284091: step 214, loss 0.96563, acc 0.5625\n",
      "2020-04-29T11:38:48.440328: step 215, loss 0.837269, acc 0.59375\n",
      "2020-04-29T11:38:48.623272: step 216, loss 0.871583, acc 0.625\n",
      "2020-04-29T11:38:48.779511: step 217, loss 1.01822, acc 0.53125\n",
      "2020-04-29T11:38:48.951675: step 218, loss 1.03612, acc 0.59375\n",
      "2020-04-29T11:38:49.123538: step 219, loss 1.17277, acc 0.484375\n",
      "2020-04-29T11:38:49.298469: step 220, loss 0.700387, acc 0.578125\n",
      "2020-04-29T11:38:49.454709: step 221, loss 0.691417, acc 0.703125\n",
      "2020-04-29T11:38:49.635951: step 222, loss 0.945072, acc 0.640625\n",
      "2020-04-29T11:38:49.792188: step 223, loss 1.01605, acc 0.640625\n",
      "2020-04-29T11:38:49.977844: step 224, loss 0.952936, acc 0.6875\n",
      "2020-04-29T11:38:50.139814: step 225, loss 1.10875, acc 0.546875\n",
      "2020-04-29T11:38:50.301238: step 226, loss 1.08772, acc 0.5625\n",
      "2020-04-29T11:38:50.473101: step 227, loss 0.717719, acc 0.625\n",
      "2020-04-29T11:38:50.649694: step 228, loss 1.12758, acc 0.453125\n",
      "2020-04-29T11:38:50.821557: step 229, loss 0.583683, acc 0.734375\n",
      "2020-04-29T11:38:51.000244: step 230, loss 1.00396, acc 0.546875\n",
      "2020-04-29T11:38:51.156484: step 231, loss 1.05803, acc 0.546875\n",
      "2020-04-29T11:38:51.334551: step 232, loss 0.737127, acc 0.6875\n",
      "2020-04-29T11:38:51.490791: step 233, loss 0.930517, acc 0.671875\n",
      "2020-04-29T11:38:51.667846: step 234, loss 0.754253, acc 0.671875\n",
      "2020-04-29T11:38:51.839710: step 235, loss 0.840218, acc 0.640625\n",
      "2020-04-29T11:38:52.019583: step 236, loss 0.880244, acc 0.53125\n",
      "2020-04-29T11:38:52.188486: step 237, loss 1.13865, acc 0.53125\n",
      "2020-04-29T11:38:52.355006: step 238, loss 1.06762, acc 0.515625\n",
      "2020-04-29T11:38:52.526868: step 239, loss 0.862927, acc 0.609375\n",
      "2020-04-29T11:38:52.702029: step 240, loss 1.12917, acc 0.609375\n",
      "2020-04-29T11:38:52.858268: step 241, loss 0.860895, acc 0.609375\n",
      "2020-04-29T11:38:53.035432: step 242, loss 0.733509, acc 0.671875\n",
      "2020-04-29T11:38:53.191671: step 243, loss 0.744008, acc 0.6875\n",
      "2020-04-29T11:38:53.373641: step 244, loss 0.81418, acc 0.625\n",
      "2020-04-29T11:38:53.545503: step 245, loss 0.720603, acc 0.65625\n",
      "2020-04-29T11:38:53.719714: step 246, loss 0.89041, acc 0.5625\n",
      "2020-04-29T11:38:53.891578: step 247, loss 0.785522, acc 0.640625\n",
      "2020-04-29T11:38:54.054992: step 248, loss 0.821539, acc 0.609375\n",
      "2020-04-29T11:38:54.226855: step 249, loss 0.97619, acc 0.578125\n",
      "2020-04-29T11:38:54.404763: step 250, loss 0.97086, acc 0.578125\n",
      "2020-04-29T11:38:54.576626: step 251, loss 0.618654, acc 0.671875\n",
      "2020-04-29T11:38:54.754693: step 252, loss 0.933248, acc 0.640625\n",
      "2020-04-29T11:38:54.910931: step 253, loss 0.651604, acc 0.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-29T11:38:55.087087: step 254, loss 1.05975, acc 0.578125\n",
      "2020-04-29T11:38:55.258950: step 255, loss 0.528165, acc 0.75\n",
      "2020-04-29T11:38:55.423056: step 256, loss 0.801192, acc 0.6875\n",
      "2020-04-29T11:38:55.594919: step 257, loss 0.874168, acc 0.625\n",
      "2020-04-29T11:38:55.762108: step 258, loss 1.08388, acc 0.515625\n",
      "2020-04-29T11:38:55.918346: step 259, loss 0.939111, acc 0.5\n",
      "2020-04-29T11:38:56.096890: step 260, loss 1.26976, acc 0.53125\n",
      "2020-04-29T11:38:56.253130: step 261, loss 0.626862, acc 0.671875\n",
      "2020-04-29T11:38:56.439763: step 262, loss 0.86539, acc 0.640625\n",
      "2020-04-29T11:38:56.596000: step 263, loss 0.699755, acc 0.671875\n",
      "2020-04-29T11:38:56.775925: step 264, loss 1.09983, acc 0.5\n",
      "2020-04-29T11:38:56.932164: step 265, loss 0.915337, acc 0.546875\n",
      "2020-04-29T11:38:57.120207: step 266, loss 0.854685, acc 0.515625\n",
      "2020-04-29T11:38:57.284502: step 267, loss 0.932655, acc 0.625\n",
      "2020-04-29T11:38:57.457532: step 268, loss 0.704901, acc 0.71875\n",
      "2020-04-29T11:38:57.613771: step 269, loss 0.808439, acc 0.625\n",
      "2020-04-29T11:38:57.794755: step 270, loss 0.642825, acc 0.6875\n",
      "2020-04-29T11:38:57.950995: step 271, loss 0.920971, acc 0.65625\n",
      "2020-04-29T11:38:58.144181: step 272, loss 0.794095, acc 0.609375\n",
      "2020-04-29T11:38:58.300421: step 273, loss 0.91311, acc 0.578125\n",
      "2020-04-29T11:38:58.475437: step 274, loss 0.877632, acc 0.578125\n",
      "2020-04-29T11:38:58.631676: step 275, loss 0.902731, acc 0.59375\n",
      "2020-04-29T11:38:58.811263: step 276, loss 0.749633, acc 0.671875\n",
      "2020-04-29T11:38:58.970184: step 277, loss 0.935504, acc 0.515625\n",
      "2020-04-29T11:38:59.145700: step 278, loss 0.870581, acc 0.609375\n",
      "2020-04-29T11:38:59.317563: step 279, loss 0.862337, acc 0.53125\n",
      "2020-04-29T11:38:59.493660: step 280, loss 0.696456, acc 0.578125\n",
      "2020-04-29T11:38:59.649899: step 281, loss 0.804034, acc 0.640625\n",
      "2020-04-29T11:38:59.830455: step 282, loss 0.937014, acc 0.5625\n",
      "2020-04-29T11:39:00.003980: step 283, loss 0.747442, acc 0.703125\n",
      "2020-04-29T11:39:00.216856: step 284, loss 0.881285, acc 0.609375\n",
      "2020-04-29T11:39:00.415402: step 285, loss 0.909354, acc 0.5625\n",
      "2020-04-29T11:39:00.638325: step 286, loss 0.852048, acc 0.59375\n",
      "2020-04-29T11:39:00.807893: step 287, loss 0.722785, acc 0.640625\n",
      "2020-04-29T11:39:00.990398: step 288, loss 1.09407, acc 0.515625\n",
      "2020-04-29T11:39:01.146639: step 289, loss 0.887576, acc 0.515625\n",
      "2020-04-29T11:39:01.313035: step 290, loss 0.741035, acc 0.578125\n",
      "2020-04-29T11:39:01.484898: step 291, loss 0.864822, acc 0.59375\n",
      "2020-04-29T11:39:01.662008: step 292, loss 1.00617, acc 0.65625\n",
      "2020-04-29T11:39:01.818247: step 293, loss 0.670595, acc 0.734375\n",
      "2020-04-29T11:39:02.002541: step 294, loss 0.946954, acc 0.515625\n",
      "2020-04-29T11:39:02.150971: step 295, loss 0.988445, acc 0.578125\n",
      "2020-04-29T11:39:02.332037: step 296, loss 0.602612, acc 0.75\n",
      "2020-04-29T11:39:02.488277: step 297, loss 0.745095, acc 0.640625\n",
      "2020-04-29T11:39:02.664754: step 298, loss 0.731738, acc 0.71875\n",
      "2020-04-29T11:39:02.820993: step 299, loss 0.68447, acc 0.65625\n",
      "2020-04-29T11:39:02.985113: step 300, loss 0.76392, acc 0.6\n",
      "\n",
      "Evaluation:\n",
      "2020-04-29T11:39:03.230930: step 300, loss 0.643281, acc 0.621951\n",
      "\n",
      "Saved model checkpoint to E:\\Project\\伯禹自然语言处理\\03基于卷积神经网络的文本分类\\runs\\1588131485\\checkpoints\\model-300\n",
      "\n",
      "2020-04-29T11:39:03.860757: step 301, loss 0.704662, acc 0.6875\n",
      "2020-04-29T11:39:04.033993: step 302, loss 0.684202, acc 0.703125\n",
      "2020-04-29T11:39:04.189418: step 303, loss 0.710645, acc 0.703125\n",
      "2020-04-29T11:39:04.368434: step 304, loss 0.673476, acc 0.609375\n",
      "2020-04-29T11:39:04.540297: step 305, loss 0.960307, acc 0.453125\n",
      "2020-04-29T11:39:04.715902: step 306, loss 0.504493, acc 0.765625\n",
      "2020-04-29T11:39:04.872140: step 307, loss 0.609892, acc 0.734375\n",
      "2020-04-29T11:39:05.059209: step 308, loss 0.577918, acc 0.671875\n",
      "2020-04-29T11:39:05.220466: step 309, loss 0.582459, acc 0.765625\n",
      "2020-04-29T11:39:05.390584: step 310, loss 0.57958, acc 0.71875\n",
      "2020-04-29T11:39:05.546823: step 311, loss 0.701865, acc 0.6875\n",
      "2020-04-29T11:39:05.717168: step 312, loss 0.667808, acc 0.71875\n",
      "2020-04-29T11:39:05.889031: step 313, loss 0.593193, acc 0.75\n",
      "2020-04-29T11:39:06.066821: step 314, loss 0.538082, acc 0.703125\n",
      "2020-04-29T11:39:06.223060: step 315, loss 0.627512, acc 0.640625\n",
      "2020-04-29T11:39:06.411642: step 316, loss 0.639662, acc 0.734375\n",
      "2020-04-29T11:39:06.567880: step 317, loss 0.594294, acc 0.71875\n",
      "2020-04-29T11:39:06.736453: step 318, loss 0.611624, acc 0.640625\n",
      "2020-04-29T11:39:06.908316: step 319, loss 0.804089, acc 0.65625\n",
      "2020-04-29T11:39:07.083939: step 320, loss 0.689013, acc 0.703125\n",
      "2020-04-29T11:39:07.247845: step 321, loss 0.623839, acc 0.671875\n",
      "2020-04-29T11:39:07.417971: step 322, loss 0.704965, acc 0.640625\n",
      "2020-04-29T11:39:07.574208: step 323, loss 0.688797, acc 0.671875\n",
      "2020-04-29T11:39:07.755258: step 324, loss 0.727259, acc 0.578125\n",
      "2020-04-29T11:39:07.911497: step 325, loss 0.624758, acc 0.703125\n",
      "2020-04-29T11:39:08.102584: step 326, loss 0.629655, acc 0.703125\n",
      "2020-04-29T11:39:08.258820: step 327, loss 0.731023, acc 0.609375\n",
      "2020-04-29T11:39:08.437967: step 328, loss 0.575713, acc 0.78125\n",
      "2020-04-29T11:39:08.594205: step 329, loss 0.822532, acc 0.5625\n",
      "2020-04-29T11:39:08.769457: step 330, loss 0.614928, acc 0.6875\n",
      "2020-04-29T11:39:08.941318: step 331, loss 0.540216, acc 0.71875\n",
      "2020-04-29T11:39:09.120129: step 332, loss 0.738994, acc 0.625\n",
      "2020-04-29T11:39:09.276368: step 333, loss 0.640948, acc 0.671875\n",
      "2020-04-29T11:39:09.457461: step 334, loss 0.607163, acc 0.6875\n",
      "2020-04-29T11:39:09.613700: step 335, loss 0.790551, acc 0.640625\n",
      "2020-04-29T11:39:09.788465: step 336, loss 0.840137, acc 0.609375\n",
      "2020-04-29T11:39:09.944703: step 337, loss 0.755172, acc 0.671875\n",
      "2020-04-29T11:39:10.122623: step 338, loss 0.90194, acc 0.546875\n",
      "2020-04-29T11:39:10.294487: step 339, loss 0.667994, acc 0.65625\n",
      "2020-04-29T11:39:10.461219: step 340, loss 0.592448, acc 0.6875\n",
      "2020-04-29T11:39:10.617457: step 341, loss 0.754878, acc 0.640625\n",
      "2020-04-29T11:39:10.790605: step 342, loss 0.764687, acc 0.59375\n",
      "2020-04-29T11:39:10.974001: step 343, loss 0.767486, acc 0.59375\n",
      "2020-04-29T11:39:11.139973: step 344, loss 0.632613, acc 0.734375\n",
      "2020-04-29T11:39:11.306532: step 345, loss 0.660517, acc 0.796875\n",
      "2020-04-29T11:39:11.462770: step 346, loss 0.560343, acc 0.71875\n",
      "2020-04-29T11:39:11.644012: step 347, loss 0.977418, acc 0.65625\n",
      "2020-04-29T11:39:11.800250: step 348, loss 0.627181, acc 0.75\n",
      "2020-04-29T11:39:11.982753: step 349, loss 0.587527, acc 0.71875\n",
      "2020-04-29T11:39:12.148658: step 350, loss 0.539464, acc 0.75\n",
      "2020-04-29T11:39:12.310133: step 351, loss 0.677433, acc 0.703125\n",
      "2020-04-29T11:39:12.481995: step 352, loss 0.556357, acc 0.71875\n",
      "2020-04-29T11:39:12.657495: step 353, loss 0.609245, acc 0.671875\n",
      "2020-04-29T11:39:12.813734: step 354, loss 0.941207, acc 0.5\n",
      "2020-04-29T11:39:13.003993: step 355, loss 0.579675, acc 0.6875\n",
      "2020-04-29T11:39:13.171895: step 356, loss 0.518629, acc 0.75\n",
      "2020-04-29T11:39:13.342008: step 357, loss 0.729862, acc 0.640625\n",
      "2020-04-29T11:39:13.513871: step 358, loss 0.618875, acc 0.640625\n",
      "2020-04-29T11:39:13.692200: step 359, loss 0.47073, acc 0.71875\n",
      "2020-04-29T11:39:13.848439: step 360, loss 0.744009, acc 0.671875\n",
      "2020-04-29T11:39:14.037912: step 361, loss 0.554524, acc 0.734375\n",
      "2020-04-29T11:39:14.205816: step 362, loss 0.690382, acc 0.734375\n",
      "2020-04-29T11:39:14.375943: step 363, loss 0.804467, acc 0.5625\n",
      "2020-04-29T11:39:14.547806: step 364, loss 0.661075, acc 0.703125\n",
      "2020-04-29T11:39:14.726844: step 365, loss 0.605669, acc 0.71875\n",
      "2020-04-29T11:39:14.883082: step 366, loss 0.513217, acc 0.765625\n",
      "2020-04-29T11:39:15.061422: step 367, loss 0.791217, acc 0.640625\n",
      "2020-04-29T11:39:15.233285: step 368, loss 0.567824, acc 0.734375\n",
      "2020-04-29T11:39:15.412896: step 369, loss 0.67187, acc 0.671875\n",
      "2020-04-29T11:39:15.584759: step 370, loss 0.644657, acc 0.625\n",
      "2020-04-29T11:39:15.745709: step 371, loss 0.681402, acc 0.75\n",
      "2020-04-29T11:39:15.917572: step 372, loss 0.65313, acc 0.59375\n",
      "2020-04-29T11:39:16.080608: step 373, loss 0.681944, acc 0.640625\n",
      "2020-04-29T11:39:16.252472: step 374, loss 0.697753, acc 0.6875\n",
      "2020-04-29T11:39:16.428272: step 375, loss 0.689841, acc 0.703125\n",
      "2020-04-29T11:39:16.600135: step 376, loss 0.671215, acc 0.671875\n",
      "2020-04-29T11:39:16.763998: step 377, loss 0.762535, acc 0.671875\n",
      "2020-04-29T11:39:16.935861: step 378, loss 0.700232, acc 0.59375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-29T11:39:17.111916: step 379, loss 0.591738, acc 0.6875\n",
      "2020-04-29T11:39:17.283779: step 380, loss 0.525304, acc 0.765625\n",
      "2020-04-29T11:39:17.452597: step 381, loss 0.69345, acc 0.6875\n",
      "2020-04-29T11:39:17.608836: step 382, loss 0.467359, acc 0.796875\n",
      "2020-04-29T11:39:17.781253: step 383, loss 0.738953, acc 0.59375\n",
      "2020-04-29T11:39:17.953117: step 384, loss 0.597852, acc 0.625\n",
      "2020-04-29T11:39:18.114521: step 385, loss 0.654666, acc 0.640625\n",
      "2020-04-29T11:39:18.286385: step 386, loss 0.651089, acc 0.640625\n",
      "2020-04-29T11:39:18.458326: step 387, loss 0.690781, acc 0.671875\n",
      "2020-04-29T11:39:18.614565: step 388, loss 0.716736, acc 0.640625\n",
      "2020-04-29T11:39:18.797641: step 389, loss 0.760537, acc 0.6875\n",
      "2020-04-29T11:39:18.953879: step 390, loss 0.686615, acc 0.6875\n",
      "2020-04-29T11:39:19.131049: step 391, loss 0.59447, acc 0.640625\n",
      "2020-04-29T11:39:19.302911: step 392, loss 0.766798, acc 0.640625\n",
      "2020-04-29T11:39:19.475054: step 393, loss 0.574313, acc 0.703125\n",
      "2020-04-29T11:39:19.631294: step 394, loss 0.613723, acc 0.703125\n",
      "2020-04-29T11:39:19.804965: step 395, loss 0.693336, acc 0.640625\n",
      "2020-04-29T11:39:19.983694: step 396, loss 0.557671, acc 0.671875\n",
      "2020-04-29T11:39:20.157592: step 397, loss 0.751695, acc 0.609375\n",
      "2020-04-29T11:39:20.317097: step 398, loss 0.672609, acc 0.609375\n",
      "2020-04-29T11:39:20.488961: step 399, loss 0.576379, acc 0.734375\n",
      "2020-04-29T11:39:20.655833: step 400, loss 0.738232, acc 0.640625\n",
      "\n",
      "Evaluation:\n",
      "2020-04-29T11:39:20.896865: step 400, loss 0.635272, acc 0.629456\n",
      "\n",
      "Saved model checkpoint to E:\\Project\\伯禹自然语言处理\\03基于卷积神经网络的文本分类\\runs\\1588131485\\checkpoints\\model-400\n",
      "\n",
      "2020-04-29T11:39:21.514673: step 401, loss 0.600227, acc 0.75\n",
      "2020-04-29T11:39:21.690122: step 402, loss 0.634579, acc 0.6875\n",
      "2020-04-29T11:39:21.846360: step 403, loss 0.720721, acc 0.578125\n",
      "2020-04-29T11:39:22.021347: step 404, loss 0.652505, acc 0.65625\n",
      "2020-04-29T11:39:22.193210: step 405, loss 0.794798, acc 0.578125\n",
      "2020-04-29T11:39:22.368126: step 406, loss 0.599486, acc 0.734375\n",
      "2020-04-29T11:39:22.524365: step 407, loss 0.700845, acc 0.65625\n",
      "2020-04-29T11:39:22.702447: step 408, loss 0.611173, acc 0.625\n",
      "2020-04-29T11:39:22.874311: step 409, loss 0.68483, acc 0.671875\n",
      "2020-04-29T11:39:23.036707: step 410, loss 0.749418, acc 0.6875\n",
      "2020-04-29T11:39:23.208570: step 411, loss 0.704084, acc 0.625\n",
      "2020-04-29T11:39:23.389603: step 412, loss 0.572455, acc 0.703125\n",
      "2020-04-29T11:39:23.561466: step 413, loss 0.628114, acc 0.703125\n",
      "2020-04-29T11:39:23.736528: step 414, loss 0.834823, acc 0.625\n",
      "2020-04-29T11:39:23.908391: step 415, loss 0.630886, acc 0.75\n",
      "2020-04-29T11:39:24.071715: step 416, loss 0.545567, acc 0.765625\n",
      "2020-04-29T11:39:24.243578: step 417, loss 0.602924, acc 0.734375\n",
      "2020-04-29T11:39:24.406747: step 418, loss 0.488889, acc 0.78125\n",
      "2020-04-29T11:39:24.594234: step 419, loss 0.65479, acc 0.6875\n",
      "2020-04-29T11:39:24.754076: step 420, loss 0.552516, acc 0.671875\n",
      "2020-04-29T11:39:24.922719: step 421, loss 0.599979, acc 0.703125\n",
      "2020-04-29T11:39:25.094582: step 422, loss 0.700968, acc 0.609375\n",
      "2020-04-29T11:39:25.271827: step 423, loss 0.672536, acc 0.6875\n",
      "2020-04-29T11:39:25.428065: step 424, loss 0.782773, acc 0.640625\n",
      "2020-04-29T11:39:25.607527: step 425, loss 0.781261, acc 0.53125\n",
      "2020-04-29T11:39:25.779389: step 426, loss 0.708046, acc 0.59375\n",
      "2020-04-29T11:39:25.963067: step 427, loss 0.749192, acc 0.59375\n",
      "2020-04-29T11:39:26.129969: step 428, loss 0.570325, acc 0.71875\n",
      "2020-04-29T11:39:26.294775: step 429, loss 0.614333, acc 0.640625\n",
      "2020-04-29T11:39:26.466637: step 430, loss 0.587352, acc 0.6875\n",
      "2020-04-29T11:39:26.639803: step 431, loss 0.648696, acc 0.71875\n",
      "2020-04-29T11:39:26.796042: step 432, loss 0.663399, acc 0.671875\n",
      "2020-04-29T11:39:26.987389: step 433, loss 0.730378, acc 0.546875\n",
      "2020-04-29T11:39:27.151295: step 434, loss 0.762115, acc 0.578125\n",
      "2020-04-29T11:39:27.324411: step 435, loss 0.405623, acc 0.8125\n",
      "2020-04-29T11:39:27.480650: step 436, loss 0.573194, acc 0.71875\n",
      "2020-04-29T11:39:27.659077: step 437, loss 0.669888, acc 0.625\n",
      "2020-04-29T11:39:27.815315: step 438, loss 0.637073, acc 0.625\n",
      "2020-04-29T11:39:28.001184: step 439, loss 0.758185, acc 0.5625\n",
      "2020-04-29T11:39:28.157423: step 440, loss 0.695629, acc 0.625\n",
      "2020-04-29T11:39:28.329467: step 441, loss 0.543568, acc 0.734375\n",
      "2020-04-29T11:39:28.501329: step 442, loss 0.643599, acc 0.671875\n",
      "2020-04-29T11:39:28.675347: step 443, loss 0.717022, acc 0.59375\n",
      "2020-04-29T11:39:28.831585: step 444, loss 0.842181, acc 0.5\n",
      "2020-04-29T11:39:29.016355: step 445, loss 0.631833, acc 0.671875\n",
      "2020-04-29T11:39:29.172594: step 446, loss 0.636446, acc 0.65625\n",
      "2020-04-29T11:39:29.344181: step 447, loss 0.715359, acc 0.609375\n",
      "2020-04-29T11:39:29.516045: step 448, loss 0.634337, acc 0.640625\n",
      "2020-04-29T11:39:29.692969: step 449, loss 0.661962, acc 0.65625\n",
      "2020-04-29T11:39:29.849207: step 450, loss 0.705026, acc 0.616667\n",
      "2020-04-29T11:39:30.031897: step 451, loss 0.68847, acc 0.671875\n",
      "2020-04-29T11:39:30.188135: step 452, loss 0.629523, acc 0.65625\n",
      "2020-04-29T11:39:30.362181: step 453, loss 0.585922, acc 0.671875\n",
      "2020-04-29T11:39:30.534046: step 454, loss 0.519679, acc 0.71875\n",
      "2020-04-29T11:39:30.711181: step 455, loss 0.512083, acc 0.75\n",
      "2020-04-29T11:39:30.867419: step 456, loss 0.529789, acc 0.765625\n",
      "2020-04-29T11:39:31.032745: step 457, loss 0.641486, acc 0.65625\n",
      "2020-04-29T11:39:31.204607: step 458, loss 0.46988, acc 0.734375\n",
      "2020-04-29T11:39:31.393730: step 459, loss 0.595791, acc 0.71875\n",
      "2020-04-29T11:39:31.549969: step 460, loss 0.507004, acc 0.765625\n",
      "2020-04-29T11:39:31.727320: step 461, loss 0.584455, acc 0.625\n",
      "2020-04-29T11:39:31.883558: step 462, loss 0.503559, acc 0.75\n",
      "2020-04-29T11:39:32.070703: step 463, loss 0.494617, acc 0.8125\n",
      "2020-04-29T11:39:32.242567: step 464, loss 0.584267, acc 0.640625\n",
      "2020-04-29T11:39:32.401607: step 465, loss 0.612775, acc 0.65625\n",
      "2020-04-29T11:39:32.573470: step 466, loss 0.572149, acc 0.71875\n",
      "2020-04-29T11:39:32.750189: step 467, loss 0.546633, acc 0.734375\n",
      "2020-04-29T11:39:32.906427: step 468, loss 0.650641, acc 0.671875\n",
      "2020-04-29T11:39:33.081846: step 469, loss 0.703439, acc 0.640625\n",
      "2020-04-29T11:39:33.253709: step 470, loss 0.525013, acc 0.75\n",
      "2020-04-29T11:39:33.430343: step 471, loss 0.558978, acc 0.734375\n",
      "2020-04-29T11:39:33.602207: step 472, loss 0.665647, acc 0.65625\n",
      "2020-04-29T11:39:33.781084: step 473, loss 0.730547, acc 0.640625\n",
      "2020-04-29T11:39:33.952946: step 474, loss 0.564581, acc 0.640625\n",
      "2020-04-29T11:39:34.131789: step 475, loss 0.501857, acc 0.734375\n",
      "2020-04-29T11:39:34.288029: step 476, loss 0.631153, acc 0.671875\n",
      "2020-04-29T11:39:34.470311: step 477, loss 0.723214, acc 0.625\n",
      "2020-04-29T11:39:34.642174: step 478, loss 0.528629, acc 0.765625\n",
      "2020-04-29T11:39:34.815152: step 479, loss 0.715994, acc 0.59375\n",
      "2020-04-29T11:39:34.982312: step 480, loss 0.588838, acc 0.71875\n",
      "2020-04-29T11:39:35.159210: step 481, loss 0.548033, acc 0.78125\n",
      "2020-04-29T11:39:35.321464: step 482, loss 0.630113, acc 0.703125\n",
      "2020-04-29T11:39:35.502838: step 483, loss 0.541307, acc 0.78125\n",
      "2020-04-29T11:39:35.659077: step 484, loss 0.606186, acc 0.71875\n",
      "2020-04-29T11:39:35.834082: step 485, loss 0.50852, acc 0.765625\n",
      "2020-04-29T11:39:36.005643: step 486, loss 0.484617, acc 0.828125\n",
      "2020-04-29T11:39:36.184004: step 487, loss 0.562775, acc 0.71875\n",
      "2020-04-29T11:39:36.340242: step 488, loss 0.505302, acc 0.75\n",
      "2020-04-29T11:39:36.522631: step 489, loss 0.472971, acc 0.734375\n",
      "2020-04-29T11:39:36.694496: step 490, loss 0.657801, acc 0.640625\n",
      "2020-04-29T11:39:36.871644: step 491, loss 0.591876, acc 0.703125\n",
      "2020-04-29T11:39:37.027883: step 492, loss 0.621618, acc 0.703125\n",
      "2020-04-29T11:39:37.202262: step 493, loss 0.656524, acc 0.6875\n",
      "2020-04-29T11:39:37.374124: step 494, loss 0.556498, acc 0.75\n",
      "2020-04-29T11:39:37.551351: step 495, loss 0.481454, acc 0.75\n",
      "2020-04-29T11:39:37.723214: step 496, loss 0.591075, acc 0.671875\n",
      "2020-04-29T11:39:37.902109: step 497, loss 0.640113, acc 0.625\n",
      "2020-04-29T11:39:38.076154: step 498, loss 0.508296, acc 0.734375\n",
      "2020-04-29T11:39:38.253077: step 499, loss 0.622152, acc 0.671875\n",
      "2020-04-29T11:39:38.409316: step 500, loss 0.557711, acc 0.71875\n",
      "\n",
      "Evaluation:\n",
      "2020-04-29T11:39:38.650221: step 500, loss 0.619348, acc 0.659475\n",
      "\n",
      "Saved model checkpoint to E:\\Project\\伯禹自然语言处理\\03基于卷积神经网络的文本分类\\runs\\1588131485\\checkpoints\\model-500\n",
      "\n",
      "2020-04-29T11:39:39.282410: step 501, loss 0.530054, acc 0.765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-29T11:39:39.459084: step 502, loss 0.646045, acc 0.75\n",
      "2020-04-29T11:39:39.630948: step 503, loss 0.633835, acc 0.625\n",
      "2020-04-29T11:39:39.804342: step 504, loss 0.53953, acc 0.703125\n",
      "2020-04-29T11:39:39.982142: step 505, loss 0.487029, acc 0.71875\n",
      "2020-04-29T11:39:40.157041: step 506, loss 0.523434, acc 0.71875\n",
      "2020-04-29T11:39:40.321177: step 507, loss 0.566152, acc 0.6875\n",
      "2020-04-29T11:39:40.493040: step 508, loss 0.40036, acc 0.78125\n",
      "2020-04-29T11:39:40.671536: step 509, loss 0.601104, acc 0.65625\n",
      "2020-04-29T11:39:40.827774: step 510, loss 0.592606, acc 0.734375\n",
      "2020-04-29T11:39:41.009757: step 511, loss 0.604668, acc 0.703125\n",
      "2020-04-29T11:39:41.177659: step 512, loss 0.715723, acc 0.5625\n",
      "2020-04-29T11:39:41.340296: step 513, loss 0.69057, acc 0.609375\n",
      "2020-04-29T11:39:41.512159: step 514, loss 0.667882, acc 0.59375\n",
      "2020-04-29T11:39:41.690177: step 515, loss 0.473406, acc 0.78125\n",
      "2020-04-29T11:39:41.846415: step 516, loss 0.545009, acc 0.75\n",
      "2020-04-29T11:39:42.023274: step 517, loss 0.675949, acc 0.640625\n",
      "2020-04-29T11:39:42.195137: step 518, loss 0.563248, acc 0.703125\n",
      "2020-04-29T11:39:42.374031: step 519, loss 0.576255, acc 0.6875\n",
      "2020-04-29T11:39:42.530269: step 520, loss 0.516971, acc 0.703125\n",
      "2020-04-29T11:39:42.708805: step 521, loss 0.60172, acc 0.671875\n",
      "2020-04-29T11:39:42.880668: step 522, loss 0.507342, acc 0.71875\n",
      "2020-04-29T11:39:43.047831: step 523, loss 0.566512, acc 0.765625\n",
      "2020-04-29T11:39:43.219694: step 524, loss 0.535025, acc 0.703125\n",
      "2020-04-29T11:39:43.391862: step 525, loss 0.560183, acc 0.65625\n",
      "2020-04-29T11:39:43.563725: step 526, loss 0.452917, acc 0.765625\n",
      "2020-04-29T11:39:43.726103: step 527, loss 0.531951, acc 0.6875\n",
      "2020-04-29T11:39:43.897965: step 528, loss 0.591754, acc 0.671875\n",
      "2020-04-29T11:39:44.075144: step 529, loss 0.558459, acc 0.671875\n",
      "2020-04-29T11:39:44.247006: step 530, loss 0.455555, acc 0.828125\n",
      "2020-04-29T11:39:44.416854: step 531, loss 0.525221, acc 0.75\n",
      "2020-04-29T11:39:44.588716: step 532, loss 0.491308, acc 0.75\n",
      "2020-04-29T11:39:44.760065: step 533, loss 0.505708, acc 0.75\n",
      "2020-04-29T11:39:44.916304: step 534, loss 0.574272, acc 0.734375\n",
      "2020-04-29T11:39:45.109912: step 535, loss 0.555545, acc 0.796875\n",
      "2020-04-29T11:39:45.281775: step 536, loss 0.671223, acc 0.671875\n",
      "2020-04-29T11:39:45.459960: step 537, loss 0.463926, acc 0.765625\n",
      "2020-04-29T11:39:45.616199: step 538, loss 0.501029, acc 0.75\n",
      "2020-04-29T11:39:45.794440: step 539, loss 0.610907, acc 0.6875\n",
      "2020-04-29T11:39:45.969873: step 540, loss 0.523325, acc 0.703125\n",
      "2020-04-29T11:39:46.144906: step 541, loss 0.564128, acc 0.71875\n",
      "2020-04-29T11:39:46.316770: step 542, loss 0.544179, acc 0.78125\n",
      "2020-04-29T11:39:46.481907: step 543, loss 0.5943, acc 0.734375\n",
      "2020-04-29T11:39:46.653770: step 544, loss 0.624432, acc 0.6875\n",
      "2020-04-29T11:39:46.828930: step 545, loss 0.549595, acc 0.75\n",
      "2020-04-29T11:39:47.000793: step 546, loss 0.641132, acc 0.6875\n",
      "2020-04-29T11:39:47.179185: step 547, loss 0.492752, acc 0.828125\n",
      "2020-04-29T11:39:47.335424: step 548, loss 0.55156, acc 0.75\n",
      "2020-04-29T11:39:47.513320: step 549, loss 0.698085, acc 0.703125\n",
      "2020-04-29T11:39:47.685181: step 550, loss 0.630644, acc 0.6875\n",
      "2020-04-29T11:39:47.847861: step 551, loss 0.649826, acc 0.65625\n",
      "2020-04-29T11:39:48.033441: step 552, loss 0.699024, acc 0.625\n",
      "2020-04-29T11:39:48.207341: step 553, loss 0.609055, acc 0.671875\n",
      "2020-04-29T11:39:48.365679: step 554, loss 0.662569, acc 0.6875\n",
      "2020-04-29T11:39:48.537541: step 555, loss 0.58422, acc 0.71875\n",
      "2020-04-29T11:39:48.716678: step 556, loss 0.611474, acc 0.734375\n",
      "2020-04-29T11:39:48.872916: step 557, loss 0.456975, acc 0.78125\n",
      "2020-04-29T11:39:49.054444: step 558, loss 0.469409, acc 0.765625\n",
      "2020-04-29T11:39:49.210684: step 559, loss 0.424588, acc 0.796875\n",
      "2020-04-29T11:39:49.398300: step 560, loss 0.526565, acc 0.703125\n",
      "2020-04-29T11:39:49.570162: step 561, loss 0.569211, acc 0.703125\n",
      "2020-04-29T11:39:49.741663: step 562, loss 0.594353, acc 0.640625\n",
      "2020-04-29T11:39:49.897902: step 563, loss 0.375172, acc 0.796875\n",
      "2020-04-29T11:39:50.083421: step 564, loss 0.494219, acc 0.75\n",
      "2020-04-29T11:39:50.239660: step 565, loss 0.685914, acc 0.703125\n",
      "2020-04-29T11:39:50.425351: step 566, loss 0.691667, acc 0.640625\n",
      "2020-04-29T11:39:50.581590: step 567, loss 0.659035, acc 0.703125\n",
      "2020-04-29T11:39:50.751289: step 568, loss 0.559199, acc 0.75\n",
      "2020-04-29T11:39:50.923151: step 569, loss 0.622333, acc 0.65625\n",
      "2020-04-29T11:39:51.100002: step 570, loss 0.459441, acc 0.828125\n",
      "2020-04-29T11:39:51.256241: step 571, loss 0.532879, acc 0.734375\n",
      "2020-04-29T11:39:51.439849: step 572, loss 0.510384, acc 0.734375\n",
      "2020-04-29T11:39:51.611712: step 573, loss 0.473847, acc 0.765625\n",
      "2020-04-29T11:39:51.784801: step 574, loss 0.590885, acc 0.703125\n",
      "2020-04-29T11:39:51.960226: step 575, loss 0.594008, acc 0.6875\n",
      "2020-04-29T11:39:52.137088: step 576, loss 0.448314, acc 0.78125\n",
      "2020-04-29T11:39:52.293327: step 577, loss 0.721352, acc 0.640625\n",
      "2020-04-29T11:39:52.474700: step 578, loss 0.515458, acc 0.75\n",
      "2020-04-29T11:39:52.646562: step 579, loss 0.583405, acc 0.6875\n",
      "2020-04-29T11:39:52.818535: step 580, loss 0.548315, acc 0.75\n",
      "2020-04-29T11:39:52.987642: step 581, loss 0.697171, acc 0.578125\n",
      "2020-04-29T11:39:53.156239: step 582, loss 0.535246, acc 0.71875\n",
      "2020-04-29T11:39:53.328103: step 583, loss 0.461162, acc 0.796875\n",
      "2020-04-29T11:39:53.502417: step 584, loss 0.603399, acc 0.734375\n",
      "2020-04-29T11:39:53.674281: step 585, loss 0.508154, acc 0.765625\n",
      "2020-04-29T11:39:53.853320: step 586, loss 0.487343, acc 0.78125\n",
      "2020-04-29T11:39:54.025183: step 587, loss 0.649577, acc 0.671875\n",
      "2020-04-29T11:39:54.203504: step 588, loss 0.580819, acc 0.703125\n",
      "2020-04-29T11:39:54.359743: step 589, loss 0.571, acc 0.71875\n",
      "2020-04-29T11:39:54.550619: step 590, loss 0.58075, acc 0.703125\n",
      "2020-04-29T11:39:54.706857: step 591, loss 0.47829, acc 0.78125\n",
      "2020-04-29T11:39:54.886815: step 592, loss 0.56885, acc 0.703125\n",
      "2020-04-29T11:39:55.058678: step 593, loss 0.517724, acc 0.6875\n",
      "2020-04-29T11:39:55.237095: step 594, loss 0.591436, acc 0.703125\n",
      "2020-04-29T11:39:55.393334: step 595, loss 0.646473, acc 0.6875\n",
      "2020-04-29T11:39:55.573606: step 596, loss 0.573003, acc 0.65625\n",
      "2020-04-29T11:39:55.745468: step 597, loss 0.498511, acc 0.765625\n",
      "2020-04-29T11:39:55.921738: step 598, loss 0.54866, acc 0.671875\n",
      "2020-04-29T11:39:56.077978: step 599, loss 0.555771, acc 0.703125\n",
      "2020-04-29T11:39:56.255772: step 600, loss 0.517669, acc 0.733333\n",
      "\n",
      "Evaluation:\n",
      "2020-04-29T11:39:56.500027: step 600, loss 0.647344, acc 0.611632\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda3\\envs\\tensorflow1.15-cpu\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0429 11:39:56.855234  8284 deprecation.py:323] From D:\\anaconda3\\envs\\tensorflow1.15-cpu\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model checkpoint to E:\\Project\\伯禹自然语言处理\\03基于卷积神经网络的文本分类\\runs\\1588131485\\checkpoints\\model-600\n",
      "\n",
      "2020-04-29T11:39:57.143908: step 601, loss 0.667614, acc 0.671875\n",
      "2020-04-29T11:39:57.330561: step 602, loss 0.547117, acc 0.703125\n",
      "2020-04-29T11:39:57.490376: step 603, loss 0.507832, acc 0.71875\n",
      "2020-04-29T11:39:57.660314: step 604, loss 0.553227, acc 0.671875\n",
      "2020-04-29T11:39:57.832176: step 605, loss 0.589016, acc 0.703125\n",
      "2020-04-29T11:39:58.014733: step 606, loss 0.527682, acc 0.734375\n",
      "2020-04-29T11:39:58.164803: step 607, loss 0.494944, acc 0.75\n",
      "2020-04-29T11:39:58.343197: step 608, loss 0.500427, acc 0.71875\n",
      "2020-04-29T11:39:58.515059: step 609, loss 0.501485, acc 0.75\n",
      "2020-04-29T11:39:58.675943: step 610, loss 0.437731, acc 0.734375\n",
      "2020-04-29T11:39:58.847806: step 611, loss 0.562526, acc 0.703125\n",
      "2020-04-29T11:39:59.021345: step 612, loss 0.44873, acc 0.84375\n",
      "2020-04-29T11:39:59.186121: step 613, loss 0.572331, acc 0.6875\n",
      "2020-04-29T11:39:59.343478: step 614, loss 0.496111, acc 0.765625\n",
      "2020-04-29T11:39:59.515340: step 615, loss 0.50005, acc 0.765625\n",
      "2020-04-29T11:39:59.679160: step 616, loss 0.546903, acc 0.71875\n",
      "2020-04-29T11:39:59.851020: step 617, loss 0.531981, acc 0.765625\n",
      "2020-04-29T11:40:00.026222: step 618, loss 0.468354, acc 0.796875\n",
      "2020-04-29T11:40:00.198083: step 619, loss 0.420913, acc 0.8125\n",
      "2020-04-29T11:40:00.377330: step 620, loss 0.523405, acc 0.734375\n",
      "2020-04-29T11:40:00.533568: step 621, loss 0.444169, acc 0.828125\n",
      "2020-04-29T11:40:00.710519: step 622, loss 0.475053, acc 0.796875\n",
      "2020-04-29T11:40:00.866757: step 623, loss 0.429375, acc 0.796875\n",
      "2020-04-29T11:40:01.051134: step 624, loss 0.572231, acc 0.6875\n",
      "2020-04-29T11:40:01.221371: step 625, loss 0.419656, acc 0.84375\n",
      "2020-04-29T11:40:01.395234: step 626, loss 0.415909, acc 0.8125\n",
      "2020-04-29T11:40:01.551474: step 627, loss 0.429925, acc 0.828125\n",
      "2020-04-29T11:40:01.727899: step 628, loss 0.506249, acc 0.75\n",
      "2020-04-29T11:40:01.899762: step 629, loss 0.567509, acc 0.796875\n",
      "2020-04-29T11:40:02.067236: step 630, loss 0.62365, acc 0.71875\n",
      "2020-04-29T11:40:02.239100: step 631, loss 0.461248, acc 0.796875\n",
      "2020-04-29T11:40:02.398739: step 632, loss 0.589112, acc 0.75\n",
      "2020-04-29T11:40:02.570603: step 633, loss 0.579712, acc 0.71875\n",
      "2020-04-29T11:40:02.730340: step 634, loss 0.557893, acc 0.703125\n",
      "2020-04-29T11:40:02.902202: step 635, loss 0.534148, acc 0.78125\n",
      "2020-04-29T11:40:03.074096: step 636, loss 0.564628, acc 0.75\n",
      "2020-04-29T11:40:03.240003: step 637, loss 0.451429, acc 0.765625\n",
      "2020-04-29T11:40:03.400217: step 638, loss 0.463308, acc 0.796875\n",
      "2020-04-29T11:40:03.572080: step 639, loss 0.573502, acc 0.78125\n",
      "2020-04-29T11:40:03.746157: step 640, loss 0.638502, acc 0.6875\n",
      "2020-04-29T11:40:03.902396: step 641, loss 0.50868, acc 0.734375\n",
      "2020-04-29T11:40:04.084684: step 642, loss 0.530029, acc 0.71875\n",
      "2020-04-29T11:40:04.240922: step 643, loss 0.532875, acc 0.71875\n",
      "2020-04-29T11:40:04.416102: step 644, loss 0.474539, acc 0.796875\n",
      "2020-04-29T11:40:04.587965: step 645, loss 0.536044, acc 0.71875\n",
      "2020-04-29T11:40:04.764630: step 646, loss 0.514864, acc 0.765625\n",
      "2020-04-29T11:40:04.936495: step 647, loss 0.608382, acc 0.703125\n",
      "2020-04-29T11:40:05.103510: step 648, loss 0.549408, acc 0.75\n",
      "2020-04-29T11:40:05.259749: step 649, loss 0.534209, acc 0.765625\n",
      "2020-04-29T11:40:05.440597: step 650, loss 0.462198, acc 0.8125\n",
      "2020-04-29T11:40:05.596837: step 651, loss 0.511385, acc 0.78125\n",
      "2020-04-29T11:40:05.775211: step 652, loss 0.400383, acc 0.796875\n",
      "2020-04-29T11:40:05.947072: step 653, loss 0.384779, acc 0.859375\n",
      "2020-04-29T11:40:06.116697: step 654, loss 0.529333, acc 0.6875\n",
      "2020-04-29T11:40:06.288563: step 655, loss 0.477466, acc 0.75\n",
      "2020-04-29T11:40:06.454849: step 656, loss 0.52616, acc 0.78125\n",
      "2020-04-29T11:40:06.626712: step 657, loss 0.533882, acc 0.78125\n",
      "2020-04-29T11:40:06.785278: step 658, loss 0.540112, acc 0.765625\n",
      "2020-04-29T11:40:06.964665: step 659, loss 0.41417, acc 0.796875\n",
      "2020-04-29T11:40:07.133821: step 660, loss 0.560084, acc 0.703125\n",
      "2020-04-29T11:40:07.305155: step 661, loss 0.582807, acc 0.71875\n",
      "2020-04-29T11:40:07.461390: step 662, loss 0.375827, acc 0.8125\n",
      "2020-04-29T11:40:07.628213: step 663, loss 0.506359, acc 0.734375\n",
      "2020-04-29T11:40:07.800074: step 664, loss 0.604442, acc 0.640625\n",
      "2020-04-29T11:40:08.036029: step 665, loss 0.432396, acc 0.78125\n",
      "2020-04-29T11:40:08.207893: step 666, loss 0.506525, acc 0.78125\n",
      "2020-04-29T11:40:08.372459: step 667, loss 0.581614, acc 0.75\n",
      "2020-04-29T11:40:08.544321: step 668, loss 0.432389, acc 0.8125\n",
      "2020-04-29T11:40:08.703640: step 669, loss 0.560917, acc 0.6875\n",
      "2020-04-29T11:40:08.875502: step 670, loss 0.560264, acc 0.734375\n",
      "2020-04-29T11:40:09.053441: step 671, loss 0.498864, acc 0.78125\n",
      "2020-04-29T11:40:09.225305: step 672, loss 0.51522, acc 0.703125\n",
      "2020-04-29T11:40:09.388743: step 673, loss 0.524175, acc 0.78125\n",
      "2020-04-29T11:40:09.560606: step 674, loss 0.488362, acc 0.734375\n",
      "2020-04-29T11:40:09.736789: step 675, loss 0.493756, acc 0.765625\n",
      "2020-04-29T11:40:09.893029: step 676, loss 0.655583, acc 0.6875\n",
      "2020-04-29T11:40:10.079124: step 677, loss 0.505812, acc 0.71875\n",
      "2020-04-29T11:40:10.245029: step 678, loss 0.512163, acc 0.71875\n",
      "2020-04-29T11:40:10.405522: step 679, loss 0.558544, acc 0.6875\n",
      "2020-04-29T11:40:10.577384: step 680, loss 0.427868, acc 0.78125\n",
      "2020-04-29T11:40:10.754949: step 681, loss 0.507421, acc 0.8125\n",
      "2020-04-29T11:40:10.911186: step 682, loss 0.56993, acc 0.703125\n",
      "2020-04-29T11:40:11.080039: step 683, loss 0.55033, acc 0.796875\n",
      "2020-04-29T11:40:11.251902: step 684, loss 0.525679, acc 0.703125\n",
      "2020-04-29T11:40:11.424952: step 685, loss 0.563378, acc 0.71875\n",
      "2020-04-29T11:40:11.596815: step 686, loss 0.618236, acc 0.625\n",
      "2020-04-29T11:40:11.772310: step 687, loss 0.513102, acc 0.71875\n",
      "2020-04-29T11:40:11.928546: step 688, loss 0.522989, acc 0.765625\n",
      "2020-04-29T11:40:12.108420: step 689, loss 0.464577, acc 0.78125\n",
      "2020-04-29T11:40:12.264659: step 690, loss 0.530004, acc 0.734375\n",
      "2020-04-29T11:40:12.446200: step 691, loss 0.433502, acc 0.828125\n",
      "2020-04-29T11:40:12.602439: step 692, loss 0.559669, acc 0.703125\n",
      "2020-04-29T11:40:12.776092: step 693, loss 0.521161, acc 0.734375\n",
      "2020-04-29T11:40:12.932330: step 694, loss 0.457625, acc 0.84375\n",
      "2020-04-29T11:40:13.112678: step 695, loss 0.507896, acc 0.8125\n",
      "2020-04-29T11:40:13.268917: step 696, loss 0.410816, acc 0.8125\n",
      "2020-04-29T11:40:13.443469: step 697, loss 0.516956, acc 0.75\n",
      "2020-04-29T11:40:13.615332: step 698, loss 0.517085, acc 0.78125\n",
      "2020-04-29T11:40:13.791263: step 699, loss 0.379314, acc 0.796875\n",
      "2020-04-29T11:40:13.947501: step 700, loss 0.438442, acc 0.828125\n",
      "\n",
      "Evaluation:\n",
      "2020-04-29T11:40:14.208000: step 700, loss 0.601253, acc 0.663227\n",
      "\n",
      "Saved model checkpoint to E:\\Project\\伯禹自然语言处理\\03基于卷积神经网络的文本分类\\runs\\1588131485\\checkpoints\\model-700\n",
      "\n",
      "2020-04-29T11:40:14.838346: step 701, loss 0.603553, acc 0.75\n",
      "2020-04-29T11:40:15.001611: step 702, loss 0.641493, acc 0.671875\n",
      "2020-04-29T11:40:15.173474: step 703, loss 0.470675, acc 0.78125\n",
      "2020-04-29T11:40:15.349992: step 704, loss 0.41408, acc 0.78125\n",
      "2020-04-29T11:40:15.506230: step 705, loss 0.485011, acc 0.703125\n",
      "2020-04-29T11:40:15.684358: step 706, loss 0.48899, acc 0.75\n",
      "2020-04-29T11:40:15.856223: step 707, loss 0.508976, acc 0.765625\n",
      "2020-04-29T11:40:16.030539: step 708, loss 0.359235, acc 0.875\n",
      "2020-04-29T11:40:16.186779: step 709, loss 0.580952, acc 0.6875\n",
      "2020-04-29T11:40:16.363347: step 710, loss 0.497842, acc 0.734375\n",
      "2020-04-29T11:40:16.535212: step 711, loss 0.615199, acc 0.6875\n",
      "2020-04-29T11:40:16.696072: step 712, loss 0.456131, acc 0.734375\n",
      "2020-04-29T11:40:16.867935: step 713, loss 0.462702, acc 0.796875\n",
      "2020-04-29T11:40:17.045550: step 714, loss 0.516208, acc 0.734375\n",
      "2020-04-29T11:40:17.212454: step 715, loss 0.603655, acc 0.734375\n",
      "2020-04-29T11:40:17.378736: step 716, loss 0.53401, acc 0.78125\n",
      "2020-04-29T11:40:17.550598: step 717, loss 0.514968, acc 0.734375\n",
      "2020-04-29T11:40:17.723416: step 718, loss 0.55684, acc 0.703125\n",
      "2020-04-29T11:40:17.879654: step 719, loss 0.537105, acc 0.734375\n",
      "2020-04-29T11:40:18.063842: step 720, loss 0.573205, acc 0.75\n",
      "2020-04-29T11:40:18.235705: step 721, loss 0.487064, acc 0.765625\n",
      "2020-04-29T11:40:18.398109: step 722, loss 0.470377, acc 0.796875\n",
      "2020-04-29T11:40:18.569971: step 723, loss 0.413575, acc 0.828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-29T11:40:18.731781: step 724, loss 0.566594, acc 0.703125\n",
      "2020-04-29T11:40:18.903644: step 725, loss 0.496566, acc 0.796875\n",
      "2020-04-29T11:40:19.071282: step 726, loss 0.507369, acc 0.71875\n",
      "2020-04-29T11:40:19.227521: step 727, loss 0.475415, acc 0.78125\n",
      "2020-04-29T11:40:19.399134: step 728, loss 0.477194, acc 0.765625\n",
      "2020-04-29T11:40:19.570997: step 729, loss 0.521888, acc 0.71875\n",
      "2020-04-29T11:40:19.747837: step 730, loss 0.36037, acc 0.859375\n",
      "2020-04-29T11:40:19.904076: step 731, loss 0.515189, acc 0.8125\n",
      "2020-04-29T11:40:20.084878: step 732, loss 0.563586, acc 0.703125\n",
      "2020-04-29T11:40:20.256740: step 733, loss 0.624741, acc 0.6875\n",
      "2020-04-29T11:40:20.419300: step 734, loss 0.633417, acc 0.625\n",
      "2020-04-29T11:40:20.591163: step 735, loss 0.452829, acc 0.796875\n",
      "2020-04-29T11:40:20.765879: step 736, loss 0.475649, acc 0.765625\n",
      "2020-04-29T11:40:20.922117: step 737, loss 0.532808, acc 0.734375\n",
      "2020-04-29T11:40:21.105950: step 738, loss 0.419881, acc 0.84375\n",
      "2020-04-29T11:40:21.252771: step 739, loss 0.336266, acc 0.875\n",
      "2020-04-29T11:40:21.435408: step 740, loss 0.309175, acc 0.859375\n",
      "2020-04-29T11:40:21.591647: step 741, loss 0.322012, acc 0.90625\n",
      "2020-04-29T11:40:21.772030: step 742, loss 0.623675, acc 0.703125\n",
      "2020-04-29T11:40:21.928267: step 743, loss 0.372537, acc 0.8125\n",
      "2020-04-29T11:40:22.105639: step 744, loss 0.681938, acc 0.703125\n",
      "2020-04-29T11:40:22.269696: step 745, loss 0.587399, acc 0.71875\n",
      "2020-04-29T11:40:22.437908: step 746, loss 0.512611, acc 0.75\n",
      "2020-04-29T11:40:22.594147: step 747, loss 0.508788, acc 0.84375\n",
      "2020-04-29T11:40:22.768616: step 748, loss 0.445642, acc 0.796875\n",
      "2020-04-29T11:40:22.924856: step 749, loss 0.47708, acc 0.75\n",
      "2020-04-29T11:40:23.100631: step 750, loss 0.486638, acc 0.766667\n",
      "2020-04-29T11:40:23.256243: step 751, loss 0.361954, acc 0.875\n",
      "2020-04-29T11:40:23.435200: step 752, loss 0.388761, acc 0.828125\n",
      "2020-04-29T11:40:23.607061: step 753, loss 0.406588, acc 0.859375\n",
      "2020-04-29T11:40:23.770760: step 754, loss 0.44862, acc 0.765625\n",
      "2020-04-29T11:40:23.942622: step 755, loss 0.415475, acc 0.796875\n",
      "2020-04-29T11:40:24.119227: step 756, loss 0.527684, acc 0.734375\n",
      "2020-04-29T11:40:24.275465: step 757, loss 0.403574, acc 0.859375\n",
      "2020-04-29T11:40:24.453069: step 758, loss 0.467063, acc 0.796875\n",
      "2020-04-29T11:40:24.624932: step 759, loss 0.586044, acc 0.671875\n",
      "2020-04-29T11:40:24.788999: step 760, loss 0.511848, acc 0.78125\n",
      "2020-04-29T11:40:24.968402: step 761, loss 0.385201, acc 0.875\n",
      "2020-04-29T11:40:25.123665: step 762, loss 0.427118, acc 0.78125\n",
      "2020-04-29T11:40:25.304404: step 763, loss 0.414792, acc 0.78125\n",
      "2020-04-29T11:40:25.460642: step 764, loss 0.436718, acc 0.78125\n",
      "2020-04-29T11:40:25.641696: step 765, loss 0.38451, acc 0.84375\n",
      "2020-04-29T11:40:25.813558: step 766, loss 0.378369, acc 0.890625\n",
      "2020-04-29T11:40:25.988570: step 767, loss 0.458727, acc 0.765625\n",
      "2020-04-29T11:40:26.153443: step 768, loss 0.372409, acc 0.828125\n",
      "2020-04-29T11:40:26.321775: step 769, loss 0.266182, acc 0.90625\n",
      "2020-04-29T11:40:26.478014: step 770, loss 0.412378, acc 0.8125\n",
      "2020-04-29T11:40:26.659253: step 771, loss 0.375606, acc 0.796875\n",
      "2020-04-29T11:40:26.815492: step 772, loss 0.660972, acc 0.75\n",
      "2020-04-29T11:40:27.000946: step 773, loss 0.560117, acc 0.703125\n",
      "2020-04-29T11:40:27.172808: step 774, loss 0.335979, acc 0.890625\n",
      "2020-04-29T11:40:27.344215: step 775, loss 0.486953, acc 0.765625\n",
      "2020-04-29T11:40:27.500455: step 776, loss 0.416071, acc 0.734375\n",
      "2020-04-29T11:40:27.676705: step 777, loss 0.427576, acc 0.765625\n",
      "2020-04-29T11:40:27.832944: step 778, loss 0.36019, acc 0.875\n",
      "2020-04-29T11:40:28.023788: step 779, loss 0.442739, acc 0.796875\n",
      "2020-04-29T11:40:28.186705: step 780, loss 0.41576, acc 0.796875\n",
      "2020-04-29T11:40:28.357639: step 781, loss 0.507125, acc 0.8125\n",
      "2020-04-29T11:40:28.513877: step 782, loss 0.444432, acc 0.765625\n",
      "2020-04-29T11:40:28.696656: step 783, loss 0.509251, acc 0.71875\n",
      "2020-04-29T11:40:28.852895: step 784, loss 0.440921, acc 0.78125\n",
      "2020-04-29T11:40:29.040139: step 785, loss 0.389258, acc 0.84375\n",
      "2020-04-29T11:40:29.189125: step 786, loss 0.457693, acc 0.796875\n",
      "2020-04-29T11:40:29.359653: step 787, loss 0.394364, acc 0.828125\n",
      "2020-04-29T11:40:29.531516: step 788, loss 0.511848, acc 0.75\n",
      "2020-04-29T11:40:29.708435: step 789, loss 0.457369, acc 0.734375\n",
      "2020-04-29T11:40:29.864673: step 790, loss 0.487253, acc 0.8125\n",
      "2020-04-29T11:40:30.052587: step 791, loss 0.311084, acc 0.890625\n",
      "2020-04-29T11:40:30.219493: step 792, loss 0.343671, acc 0.90625\n",
      "2020-04-29T11:40:30.377646: step 793, loss 0.510062, acc 0.765625\n",
      "2020-04-29T11:40:30.549507: step 794, loss 0.547071, acc 0.703125\n",
      "2020-04-29T11:40:30.710946: step 795, loss 0.516653, acc 0.734375\n",
      "2020-04-29T11:40:30.882808: step 796, loss 0.551797, acc 0.703125\n",
      "2020-04-29T11:40:31.056236: step 797, loss 0.488659, acc 0.71875\n",
      "2020-04-29T11:40:31.221141: step 798, loss 0.445451, acc 0.78125\n",
      "2020-04-29T11:40:31.378794: step 799, loss 0.400748, acc 0.8125\n",
      "2020-04-29T11:40:31.550657: step 800, loss 0.44943, acc 0.828125\n",
      "\n",
      "Evaluation:\n",
      "2020-04-29T11:40:31.790539: step 800, loss 0.593096, acc 0.67636\n",
      "\n",
      "Saved model checkpoint to E:\\Project\\伯禹自然语言处理\\03基于卷积神经网络的文本分类\\runs\\1588131485\\checkpoints\\model-800\n",
      "\n",
      "2020-04-29T11:40:32.424275: step 801, loss 0.443727, acc 0.796875\n",
      "2020-04-29T11:40:32.600001: step 802, loss 0.490577, acc 0.75\n",
      "2020-04-29T11:40:32.771865: step 803, loss 0.398778, acc 0.828125\n",
      "2020-04-29T11:40:32.945728: step 804, loss 0.503003, acc 0.75\n",
      "2020-04-29T11:40:33.117591: step 805, loss 0.484127, acc 0.78125\n",
      "2020-04-29T11:40:33.269642: step 806, loss 0.533028, acc 0.734375\n",
      "2020-04-29T11:40:33.441505: step 807, loss 0.389096, acc 0.765625\n",
      "2020-04-29T11:40:33.618678: step 808, loss 0.384001, acc 0.875\n",
      "2020-04-29T11:40:33.790540: step 809, loss 0.394156, acc 0.78125\n",
      "2020-04-29T11:40:33.968478: step 810, loss 0.480763, acc 0.71875\n",
      "2020-04-29T11:40:34.124717: step 811, loss 0.436587, acc 0.828125\n",
      "2020-04-29T11:40:34.301955: step 812, loss 0.459536, acc 0.75\n",
      "2020-04-29T11:40:34.473820: step 813, loss 0.4147, acc 0.828125\n",
      "2020-04-29T11:40:34.647610: step 814, loss 0.396663, acc 0.8125\n",
      "2020-04-29T11:40:34.819474: step 815, loss 0.59719, acc 0.71875\n",
      "2020-04-29T11:40:34.992784: step 816, loss 0.429662, acc 0.8125\n",
      "2020-04-29T11:40:35.155384: step 817, loss 0.344109, acc 0.828125\n",
      "2020-04-29T11:40:35.319256: step 818, loss 0.276818, acc 0.875\n",
      "2020-04-29T11:40:35.491118: step 819, loss 0.480521, acc 0.8125\n",
      "2020-04-29T11:40:35.665790: step 820, loss 0.570006, acc 0.734375\n",
      "2020-04-29T11:40:35.822028: step 821, loss 0.388197, acc 0.828125\n",
      "2020-04-29T11:40:36.027454: step 822, loss 0.502903, acc 0.71875\n",
      "2020-04-29T11:40:36.219343: step 823, loss 0.428771, acc 0.84375\n",
      "2020-04-29T11:40:36.385554: step 824, loss 0.311475, acc 0.875\n",
      "2020-04-29T11:40:36.566059: step 825, loss 0.443246, acc 0.71875\n",
      "2020-04-29T11:40:36.722299: step 826, loss 0.364034, acc 0.828125\n",
      "2020-04-29T11:40:36.897703: step 827, loss 0.51297, acc 0.734375\n",
      "2020-04-29T11:40:37.069568: step 828, loss 0.501787, acc 0.71875\n",
      "2020-04-29T11:40:37.250774: step 829, loss 0.420984, acc 0.78125\n",
      "2020-04-29T11:40:37.433910: step 830, loss 0.388406, acc 0.8125\n",
      "2020-04-29T11:40:37.590149: step 831, loss 0.468882, acc 0.75\n",
      "2020-04-29T11:40:37.771432: step 832, loss 0.380615, acc 0.875\n",
      "2020-04-29T11:40:37.943295: step 833, loss 0.329704, acc 0.890625\n",
      "2020-04-29T11:40:38.103242: step 834, loss 0.415323, acc 0.8125\n",
      "2020-04-29T11:40:38.287758: step 835, loss 0.605653, acc 0.703125\n",
      "2020-04-29T11:40:38.457684: step 836, loss 0.562078, acc 0.6875\n",
      "2020-04-29T11:40:38.637003: step 837, loss 0.554875, acc 0.71875\n",
      "2020-04-29T11:40:38.808868: step 838, loss 0.416409, acc 0.828125\n",
      "2020-04-29T11:40:38.986067: step 839, loss 0.344052, acc 0.828125\n",
      "2020-04-29T11:40:39.148561: step 840, loss 0.558602, acc 0.71875\n",
      "2020-04-29T11:40:39.319944: step 841, loss 0.596914, acc 0.703125\n",
      "2020-04-29T11:40:39.476183: step 842, loss 0.50648, acc 0.75\n",
      "2020-04-29T11:40:39.659647: step 843, loss 0.584273, acc 0.75\n",
      "2020-04-29T11:40:39.815886: step 844, loss 0.415005, acc 0.75\n",
      "2020-04-29T11:40:40.010288: step 845, loss 0.439472, acc 0.796875\n",
      "2020-04-29T11:40:40.159030: step 846, loss 0.386136, acc 0.8125\n",
      "2020-04-29T11:40:40.339731: step 847, loss 0.619015, acc 0.625\n",
      "2020-04-29T11:40:40.495970: step 848, loss 0.448381, acc 0.78125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-29T11:40:40.672665: step 849, loss 0.453237, acc 0.84375\n",
      "2020-04-29T11:40:40.844528: step 850, loss 0.475455, acc 0.71875\n",
      "2020-04-29T11:40:41.024596: step 851, loss 0.337746, acc 0.84375\n",
      "2020-04-29T11:40:41.174917: step 852, loss 0.52733, acc 0.71875\n",
      "2020-04-29T11:40:41.355224: step 853, loss 0.472772, acc 0.78125\n",
      "2020-04-29T11:40:41.511464: step 854, loss 0.600945, acc 0.671875\n",
      "2020-04-29T11:40:41.688567: step 855, loss 0.476468, acc 0.796875\n",
      "2020-04-29T11:40:41.844806: step 856, loss 0.604312, acc 0.71875\n",
      "2020-04-29T11:40:42.025426: step 857, loss 0.454237, acc 0.8125\n",
      "2020-04-29T11:40:42.181665: step 858, loss 0.353017, acc 0.828125\n",
      "2020-04-29T11:40:42.363317: step 859, loss 0.50278, acc 0.75\n",
      "2020-04-29T11:40:42.519557: step 860, loss 0.356971, acc 0.828125\n",
      "2020-04-29T11:40:42.691268: step 861, loss 0.435626, acc 0.828125\n",
      "2020-04-29T11:40:42.847508: step 862, loss 0.408143, acc 0.84375\n",
      "2020-04-29T11:40:43.024114: step 863, loss 0.516518, acc 0.75\n",
      "2020-04-29T11:40:43.180354: step 864, loss 0.525749, acc 0.703125\n",
      "2020-04-29T11:40:43.356472: step 865, loss 0.383893, acc 0.796875\n",
      "2020-04-29T11:40:43.528334: step 866, loss 0.436805, acc 0.8125\n",
      "2020-04-29T11:40:43.707382: step 867, loss 0.461939, acc 0.75\n",
      "2020-04-29T11:40:43.863620: step 868, loss 0.496667, acc 0.734375\n",
      "2020-04-29T11:40:44.047037: step 869, loss 0.542664, acc 0.75\n",
      "2020-04-29T11:40:44.214940: step 870, loss 0.352077, acc 0.859375\n",
      "2020-04-29T11:40:44.382648: step 871, loss 0.41607, acc 0.84375\n",
      "2020-04-29T11:40:44.538886: step 872, loss 0.317102, acc 0.875\n",
      "2020-04-29T11:40:44.712166: step 873, loss 0.388636, acc 0.828125\n",
      "2020-04-29T11:40:44.884028: step 874, loss 0.479842, acc 0.78125\n",
      "2020-04-29T11:40:45.043619: step 875, loss 0.496475, acc 0.734375\n",
      "2020-04-29T11:40:45.215483: step 876, loss 0.506707, acc 0.78125\n",
      "2020-04-29T11:40:45.377519: step 877, loss 0.490221, acc 0.734375\n",
      "2020-04-29T11:40:45.549384: step 878, loss 0.425136, acc 0.8125\n",
      "2020-04-29T11:40:45.710864: step 879, loss 0.521894, acc 0.796875\n",
      "2020-04-29T11:40:45.882726: step 880, loss 0.421144, acc 0.859375\n",
      "2020-04-29T11:40:46.060799: step 881, loss 0.438682, acc 0.84375\n",
      "2020-04-29T11:40:46.217038: step 882, loss 0.442161, acc 0.8125\n",
      "2020-04-29T11:40:46.393310: step 883, loss 0.474755, acc 0.765625\n",
      "2020-04-29T11:40:46.549550: step 884, loss 0.441291, acc 0.78125\n",
      "2020-04-29T11:40:46.728020: step 885, loss 0.401735, acc 0.828125\n",
      "2020-04-29T11:40:46.899884: step 886, loss 0.501091, acc 0.78125\n",
      "2020-04-29T11:40:47.062833: step 887, loss 0.381743, acc 0.828125\n",
      "2020-04-29T11:40:47.234695: step 888, loss 0.448545, acc 0.78125\n",
      "2020-04-29T11:40:47.412137: step 889, loss 0.448311, acc 0.765625\n",
      "2020-04-29T11:40:47.583998: step 890, loss 0.44492, acc 0.796875\n",
      "2020-04-29T11:40:47.747800: step 891, loss 0.420798, acc 0.8125\n",
      "2020-04-29T11:40:47.919664: step 892, loss 0.52623, acc 0.765625\n",
      "2020-04-29T11:40:48.096558: step 893, loss 0.37887, acc 0.796875\n",
      "2020-04-29T11:40:48.268422: step 894, loss 0.528725, acc 0.65625\n",
      "2020-04-29T11:40:48.446067: step 895, loss 0.505831, acc 0.734375\n",
      "2020-04-29T11:40:48.602307: step 896, loss 0.369372, acc 0.828125\n",
      "2020-04-29T11:40:48.779457: step 897, loss 0.55901, acc 0.734375\n",
      "2020-04-29T11:40:48.935698: step 898, loss 0.45104, acc 0.859375\n",
      "2020-04-29T11:40:49.115702: step 899, loss 0.502168, acc 0.796875\n",
      "2020-04-29T11:40:49.271941: step 900, loss 0.499623, acc 0.733333\n",
      "\n",
      "Evaluation:\n",
      "2020-04-29T11:40:49.509737: step 900, loss 0.578593, acc 0.697936\n",
      "\n",
      "Saved model checkpoint to E:\\Project\\伯禹自然语言处理\\03基于卷积神经网络的文本分类\\runs\\1588131485\\checkpoints\\model-900\n",
      "\n",
      "2020-04-29T11:40:50.147399: step 901, loss 0.353394, acc 0.890625\n",
      "2020-04-29T11:40:50.315993: step 902, loss 0.436936, acc 0.75\n",
      "2020-04-29T11:40:50.472230: step 903, loss 0.438602, acc 0.84375\n",
      "2020-04-29T11:40:50.636974: step 904, loss 0.382364, acc 0.828125\n",
      "2020-04-29T11:40:50.808836: step 905, loss 0.395706, acc 0.8125\n",
      "2020-04-29T11:40:50.987810: step 906, loss 0.408027, acc 0.78125\n",
      "2020-04-29T11:40:51.156712: step 907, loss 0.428095, acc 0.8125\n",
      "2020-04-29T11:40:51.317209: step 908, loss 0.37279, acc 0.828125\n",
      "2020-04-29T11:40:51.489071: step 909, loss 0.408997, acc 0.796875\n",
      "2020-04-29T11:40:51.666812: step 910, loss 0.395702, acc 0.828125\n",
      "2020-04-29T11:40:51.823050: step 911, loss 0.378462, acc 0.859375\n",
      "2020-04-29T11:40:52.007272: step 912, loss 0.469832, acc 0.765625\n",
      "2020-04-29T11:40:52.172177: step 913, loss 0.404676, acc 0.8125\n",
      "2020-04-29T11:40:52.337241: step 914, loss 0.500713, acc 0.734375\n",
      "2020-04-29T11:40:52.493479: step 915, loss 0.353409, acc 0.90625\n",
      "2020-04-29T11:40:52.675387: step 916, loss 0.337863, acc 0.8125\n",
      "2020-04-29T11:40:52.831626: step 917, loss 0.388286, acc 0.84375\n",
      "2020-04-29T11:40:53.006270: step 918, loss 0.347518, acc 0.8125\n",
      "2020-04-29T11:40:53.178133: step 919, loss 0.323027, acc 0.84375\n",
      "2020-04-29T11:40:53.351547: step 920, loss 0.480344, acc 0.765625\n",
      "2020-04-29T11:40:53.523409: step 921, loss 0.40127, acc 0.796875\n",
      "2020-04-29T11:40:53.701457: step 922, loss 0.302605, acc 0.890625\n",
      "2020-04-29T11:40:53.873320: step 923, loss 0.383276, acc 0.84375\n",
      "2020-04-29T11:40:54.040170: step 924, loss 0.300934, acc 0.859375\n",
      "2020-04-29T11:40:54.196410: step 925, loss 0.39892, acc 0.84375\n",
      "2020-04-29T11:40:54.370574: step 926, loss 0.49124, acc 0.828125\n",
      "2020-04-29T11:40:54.542437: step 927, loss 0.341065, acc 0.828125\n",
      "2020-04-29T11:40:54.719876: step 928, loss 0.38536, acc 0.828125\n",
      "2020-04-29T11:40:54.891739: step 929, loss 0.337294, acc 0.90625\n",
      "2020-04-29T11:40:55.069896: step 930, loss 0.385817, acc 0.78125\n",
      "2020-04-29T11:40:55.226135: step 931, loss 0.404834, acc 0.8125\n",
      "2020-04-29T11:40:55.404294: step 932, loss 0.385134, acc 0.8125\n",
      "2020-04-29T11:40:55.560531: step 933, loss 0.390969, acc 0.84375\n",
      "2020-04-29T11:40:55.736997: step 934, loss 0.44344, acc 0.78125\n",
      "2020-04-29T11:40:55.893235: step 935, loss 0.305921, acc 0.8125\n",
      "2020-04-29T11:40:56.077687: step 936, loss 0.406522, acc 0.828125\n",
      "2020-04-29T11:40:56.233926: step 937, loss 0.252809, acc 0.9375\n",
      "2020-04-29T11:40:56.412231: step 938, loss 0.389808, acc 0.84375\n",
      "2020-04-29T11:40:56.568471: step 939, loss 0.299509, acc 0.84375\n",
      "2020-04-29T11:40:56.755725: step 940, loss 0.373226, acc 0.828125\n",
      "2020-04-29T11:40:56.911963: step 941, loss 0.392823, acc 0.859375\n",
      "2020-04-29T11:40:57.094005: step 942, loss 0.373415, acc 0.765625\n",
      "2020-04-29T11:40:57.265868: step 943, loss 0.349761, acc 0.828125\n",
      "2020-04-29T11:40:57.441588: step 944, loss 0.238672, acc 0.9375\n",
      "2020-04-29T11:40:57.597829: step 945, loss 0.297776, acc 0.875\n",
      "2020-04-29T11:40:57.782876: step 946, loss 0.424038, acc 0.828125\n",
      "2020-04-29T11:40:57.955357: step 947, loss 0.321535, acc 0.890625\n",
      "2020-04-29T11:40:58.135253: step 948, loss 0.362862, acc 0.796875\n",
      "2020-04-29T11:40:58.289740: step 949, loss 0.323095, acc 0.859375\n",
      "2020-04-29T11:40:58.460143: step 950, loss 0.387674, acc 0.796875\n",
      "2020-04-29T11:40:58.632007: step 951, loss 0.304785, acc 0.859375\n",
      "2020-04-29T11:40:58.793397: step 952, loss 0.33809, acc 0.859375\n",
      "2020-04-29T11:40:58.976869: step 953, loss 0.43446, acc 0.75\n",
      "2020-04-29T11:40:59.150770: step 954, loss 0.363445, acc 0.796875\n",
      "2020-04-29T11:40:59.305386: step 955, loss 0.428911, acc 0.828125\n",
      "2020-04-29T11:40:59.478085: step 956, loss 0.333892, acc 0.90625\n",
      "2020-04-29T11:40:59.649947: step 957, loss 0.429258, acc 0.78125\n",
      "2020-04-29T11:40:59.827004: step 958, loss 0.293149, acc 0.875\n",
      "2020-04-29T11:40:59.985121: step 959, loss 0.481814, acc 0.75\n",
      "2020-04-29T11:41:00.163597: step 960, loss 0.425008, acc 0.8125\n",
      "2020-04-29T11:41:00.335461: step 961, loss 0.425018, acc 0.796875\n",
      "2020-04-29T11:41:00.496987: step 962, loss 0.3123, acc 0.875\n",
      "2020-04-29T11:41:00.668849: step 963, loss 0.367928, acc 0.8125\n",
      "2020-04-29T11:41:00.849806: step 964, loss 0.314142, acc 0.875\n",
      "2020-04-29T11:41:01.018080: step 965, loss 0.380022, acc 0.84375\n",
      "2020-04-29T11:41:01.178411: step 966, loss 0.380043, acc 0.828125\n",
      "2020-04-29T11:41:01.350273: step 967, loss 0.451598, acc 0.828125\n",
      "2020-04-29T11:41:01.530641: step 968, loss 0.455672, acc 0.75\n",
      "2020-04-29T11:41:01.686879: step 969, loss 0.386724, acc 0.859375\n",
      "2020-04-29T11:41:01.865178: step 970, loss 0.4034, acc 0.796875\n",
      "2020-04-29T11:41:02.021415: step 971, loss 0.41042, acc 0.78125\n",
      "2020-04-29T11:41:02.201139: step 972, loss 0.364961, acc 0.796875\n",
      "2020-04-29T11:41:02.357378: step 973, loss 0.306094, acc 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-29T11:41:02.532894: step 974, loss 0.429268, acc 0.78125\n",
      "2020-04-29T11:41:02.704756: step 975, loss 0.359502, acc 0.859375\n",
      "2020-04-29T11:41:02.878692: step 976, loss 0.311603, acc 0.875\n",
      "2020-04-29T11:41:03.033003: step 977, loss 0.369748, acc 0.765625\n",
      "2020-04-29T11:41:03.212267: step 978, loss 0.424658, acc 0.796875\n",
      "2020-04-29T11:41:03.368506: step 979, loss 0.476071, acc 0.78125\n",
      "2020-04-29T11:41:03.546797: step 980, loss 0.413209, acc 0.828125\n",
      "2020-04-29T11:41:03.718661: step 981, loss 0.29993, acc 0.890625\n",
      "2020-04-29T11:41:03.897003: step 982, loss 0.419236, acc 0.78125\n",
      "2020-04-29T11:41:04.053242: step 983, loss 0.305517, acc 0.90625\n",
      "2020-04-29T11:41:04.230311: step 984, loss 0.280582, acc 0.875\n",
      "2020-04-29T11:41:04.386549: step 985, loss 0.424689, acc 0.8125\n",
      "2020-04-29T11:41:04.564514: step 986, loss 0.368776, acc 0.84375\n",
      "2020-04-29T11:41:04.736376: step 987, loss 0.289971, acc 0.875\n",
      "2020-04-29T11:41:04.899086: step 988, loss 0.328377, acc 0.875\n",
      "2020-04-29T11:41:05.070949: step 989, loss 0.312787, acc 0.875\n",
      "2020-04-29T11:41:05.232552: step 990, loss 0.376545, acc 0.84375\n",
      "2020-04-29T11:41:05.404414: step 991, loss 0.369818, acc 0.875\n",
      "2020-04-29T11:41:05.566010: step 992, loss 0.276138, acc 0.890625\n",
      "2020-04-29T11:41:05.737875: step 993, loss 0.359121, acc 0.859375\n",
      "2020-04-29T11:41:05.908406: step 994, loss 0.396324, acc 0.828125\n",
      "2020-04-29T11:41:06.060096: step 995, loss 0.435446, acc 0.78125\n",
      "2020-04-29T11:41:06.248604: step 996, loss 0.315892, acc 0.90625\n",
      "2020-04-29T11:41:06.404844: step 997, loss 0.37073, acc 0.859375\n",
      "2020-04-29T11:41:06.582867: step 998, loss 0.414591, acc 0.78125\n",
      "2020-04-29T11:41:06.739106: step 999, loss 0.379778, acc 0.796875\n",
      "2020-04-29T11:41:06.916361: step 1000, loss 0.367119, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2020-04-29T11:41:07.155481: step 1000, loss 0.592286, acc 0.703565\n",
      "\n",
      "Saved model checkpoint to E:\\Project\\伯禹自然语言处理\\03基于卷积神经网络的文本分类\\runs\\1588131485\\checkpoints\\model-1000\n",
      "\n",
      "2020-04-29T11:41:07.811504: step 1001, loss 0.313287, acc 0.859375\n",
      "2020-04-29T11:41:08.000063: step 1002, loss 0.442178, acc 0.796875\n",
      "2020-04-29T11:41:08.149836: step 1003, loss 0.377574, acc 0.78125\n",
      "2020-04-29T11:41:08.336120: step 1004, loss 0.463429, acc 0.765625\n",
      "2020-04-29T11:41:08.492358: step 1005, loss 0.43811, acc 0.8125\n",
      "2020-04-29T11:41:08.671207: step 1006, loss 0.446592, acc 0.8125\n",
      "2020-04-29T11:41:08.827446: step 1007, loss 0.35606, acc 0.84375\n",
      "2020-04-29T11:41:09.007305: step 1008, loss 0.508429, acc 0.828125\n",
      "2020-04-29T11:41:09.179168: step 1009, loss 0.339301, acc 0.828125\n",
      "2020-04-29T11:41:09.352474: step 1010, loss 0.576287, acc 0.71875\n",
      "2020-04-29T11:41:09.508713: step 1011, loss 0.388719, acc 0.84375\n",
      "2020-04-29T11:41:09.688295: step 1012, loss 0.330034, acc 0.84375\n",
      "2020-04-29T11:41:09.844533: step 1013, loss 0.415035, acc 0.828125\n",
      "2020-04-29T11:41:10.031977: step 1014, loss 0.486896, acc 0.78125\n",
      "2020-04-29T11:41:10.185877: step 1015, loss 0.385561, acc 0.8125\n",
      "2020-04-29T11:41:10.370763: step 1016, loss 0.374321, acc 0.84375\n",
      "2020-04-29T11:41:10.527002: step 1017, loss 0.39662, acc 0.734375\n",
      "2020-04-29T11:41:10.707332: step 1018, loss 0.456495, acc 0.796875\n",
      "2020-04-29T11:41:10.863571: step 1019, loss 0.545104, acc 0.75\n",
      "2020-04-29T11:41:11.050657: step 1020, loss 0.371475, acc 0.78125\n",
      "2020-04-29T11:41:11.205274: step 1021, loss 0.496085, acc 0.78125\n",
      "2020-04-29T11:41:11.373145: step 1022, loss 0.457857, acc 0.828125\n",
      "2020-04-29T11:41:11.545008: step 1023, loss 0.370072, acc 0.84375\n",
      "2020-04-29T11:41:11.706121: step 1024, loss 0.396418, acc 0.796875\n",
      "2020-04-29T11:41:11.877983: step 1025, loss 0.384708, acc 0.8125\n",
      "2020-04-29T11:41:12.056157: step 1026, loss 0.524494, acc 0.765625\n",
      "2020-04-29T11:41:12.225060: step 1027, loss 0.453162, acc 0.8125\n",
      "2020-04-29T11:41:12.391102: step 1028, loss 0.365956, acc 0.8125\n",
      "2020-04-29T11:41:12.547341: step 1029, loss 0.501766, acc 0.734375\n",
      "2020-04-29T11:41:12.739060: step 1030, loss 0.328083, acc 0.828125\n",
      "2020-04-29T11:41:12.910919: step 1031, loss 0.453887, acc 0.796875\n",
      "2020-04-29T11:41:13.091797: step 1032, loss 0.424598, acc 0.765625\n",
      "2020-04-29T11:41:13.255703: step 1033, loss 0.370109, acc 0.796875\n",
      "2020-04-29T11:41:13.425634: step 1034, loss 0.457912, acc 0.859375\n",
      "2020-04-29T11:41:13.581873: step 1035, loss 0.485861, acc 0.78125\n",
      "2020-04-29T11:41:13.772083: step 1036, loss 0.277582, acc 0.875\n",
      "2020-04-29T11:41:13.943945: step 1037, loss 0.510403, acc 0.71875\n",
      "2020-04-29T11:41:14.112750: step 1038, loss 0.37298, acc 0.84375\n",
      "2020-04-29T11:41:14.284612: step 1039, loss 0.410504, acc 0.875\n",
      "2020-04-29T11:41:14.442816: step 1040, loss 0.465944, acc 0.796875\n",
      "2020-04-29T11:41:14.614677: step 1041, loss 0.432344, acc 0.8125\n",
      "2020-04-29T11:41:14.791294: step 1042, loss 0.392001, acc 0.828125\n",
      "2020-04-29T11:41:14.969662: step 1043, loss 0.307864, acc 0.875\n",
      "2020-04-29T11:41:15.142775: step 1044, loss 0.555724, acc 0.734375\n",
      "2020-04-29T11:41:15.310995: step 1045, loss 0.275104, acc 0.890625\n",
      "2020-04-29T11:41:15.467234: step 1046, loss 0.450127, acc 0.796875\n",
      "2020-04-29T11:41:15.648203: step 1047, loss 0.377193, acc 0.78125\n",
      "2020-04-29T11:41:15.804443: step 1048, loss 0.412394, acc 0.859375\n",
      "2020-04-29T11:41:15.991419: step 1049, loss 0.463094, acc 0.828125\n",
      "2020-04-29T11:41:16.140732: step 1050, loss 0.378241, acc 0.783333\n",
      "2020-04-29T11:41:16.327059: step 1051, loss 0.236732, acc 0.875\n",
      "2020-04-29T11:41:16.483296: step 1052, loss 0.283242, acc 0.875\n",
      "2020-04-29T11:41:16.664736: step 1053, loss 0.354005, acc 0.828125\n",
      "2020-04-29T11:41:16.820975: step 1054, loss 0.285758, acc 0.859375\n",
      "2020-04-29T11:41:17.001500: step 1055, loss 0.325406, acc 0.859375\n",
      "2020-04-29T11:41:17.173362: step 1056, loss 0.287821, acc 0.828125\n",
      "2020-04-29T11:41:17.345919: step 1057, loss 0.23354, acc 0.9375\n",
      "2020-04-29T11:41:17.502158: step 1058, loss 0.387451, acc 0.8125\n",
      "2020-04-29T11:41:17.684118: step 1059, loss 0.252984, acc 0.890625\n",
      "2020-04-29T11:41:17.855979: step 1060, loss 0.325346, acc 0.890625\n",
      "2020-04-29T11:41:18.033424: step 1061, loss 0.382757, acc 0.828125\n",
      "2020-04-29T11:41:18.205286: step 1062, loss 0.360088, acc 0.84375\n",
      "2020-04-29T11:41:18.380382: step 1063, loss 0.359677, acc 0.828125\n",
      "2020-04-29T11:41:18.536620: step 1064, loss 0.410947, acc 0.84375\n",
      "2020-04-29T11:41:18.721340: step 1065, loss 0.289094, acc 0.859375\n",
      "2020-04-29T11:41:18.877579: step 1066, loss 0.226376, acc 0.953125\n",
      "2020-04-29T11:41:19.063020: step 1067, loss 0.332131, acc 0.78125\n",
      "2020-04-29T11:41:19.219259: step 1068, loss 0.250423, acc 0.90625\n",
      "2020-04-29T11:41:19.398087: step 1069, loss 0.430821, acc 0.765625\n",
      "2020-04-29T11:41:19.554325: step 1070, loss 0.363604, acc 0.8125\n",
      "2020-04-29T11:41:19.736943: step 1071, loss 0.297854, acc 0.828125\n",
      "2020-04-29T11:41:19.893182: step 1072, loss 0.354801, acc 0.84375\n",
      "2020-04-29T11:41:20.084036: step 1073, loss 0.329719, acc 0.90625\n",
      "2020-04-29T11:41:20.252939: step 1074, loss 0.356751, acc 0.84375\n",
      "2020-04-29T11:41:20.415366: step 1075, loss 0.366792, acc 0.8125\n",
      "2020-04-29T11:41:20.587229: step 1076, loss 0.332597, acc 0.875\n",
      "2020-04-29T11:41:20.765152: step 1077, loss 0.296884, acc 0.859375\n",
      "2020-04-29T11:41:20.921392: step 1078, loss 0.336762, acc 0.859375\n",
      "2020-04-29T11:41:21.100645: step 1079, loss 0.304953, acc 0.828125\n",
      "2020-04-29T11:41:21.256883: step 1080, loss 0.347765, acc 0.859375\n",
      "2020-04-29T11:41:21.437138: step 1081, loss 0.422818, acc 0.828125\n",
      "2020-04-29T11:41:21.593377: step 1082, loss 0.369277, acc 0.828125\n",
      "2020-04-29T11:41:21.769613: step 1083, loss 0.314656, acc 0.84375\n",
      "2020-04-29T11:41:21.941475: step 1084, loss 0.267536, acc 0.90625\n",
      "2020-04-29T11:41:22.103751: step 1085, loss 0.479145, acc 0.8125\n",
      "2020-04-29T11:41:22.275614: step 1086, loss 0.24129, acc 0.875\n",
      "2020-04-29T11:41:22.450592: step 1087, loss 0.354891, acc 0.84375\n",
      "2020-04-29T11:41:22.622455: step 1088, loss 0.251284, acc 0.90625\n",
      "2020-04-29T11:41:22.800991: step 1089, loss 0.216103, acc 0.90625\n",
      "2020-04-29T11:41:22.969771: step 1090, loss 0.266551, acc 0.921875\n",
      "2020-04-29T11:41:23.137363: step 1091, loss 0.371208, acc 0.859375\n",
      "2020-04-29T11:41:23.309224: step 1092, loss 0.236618, acc 0.890625\n",
      "2020-04-29T11:41:23.484312: step 1093, loss 0.204407, acc 0.9375\n",
      "2020-04-29T11:41:23.656175: step 1094, loss 0.20533, acc 0.921875\n",
      "2020-04-29T11:41:23.835104: step 1095, loss 0.358087, acc 0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-29T11:41:24.013940: step 1096, loss 0.272651, acc 0.90625\n",
      "2020-04-29T11:41:24.186925: step 1097, loss 0.180317, acc 0.921875\n",
      "2020-04-29T11:41:24.353609: step 1098, loss 0.27081, acc 0.890625\n",
      "2020-04-29T11:41:24.541096: step 1099, loss 0.421057, acc 0.796875\n",
      "2020-04-29T11:41:24.719478: step 1100, loss 0.26492, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2020-04-29T11:41:24.969098: step 1100, loss 0.574256, acc 0.710131\n",
      "\n",
      "Saved model checkpoint to E:\\Project\\伯禹自然语言处理\\03基于卷积神经网络的文本分类\\runs\\1588131485\\checkpoints\\model-1100\n",
      "\n",
      "2020-04-29T11:41:25.615782: step 1101, loss 0.2598, acc 0.84375\n",
      "2020-04-29T11:41:25.789109: step 1102, loss 0.298336, acc 0.859375\n",
      "2020-04-29T11:41:25.972559: step 1103, loss 0.3936, acc 0.828125\n",
      "2020-04-29T11:41:26.156332: step 1104, loss 0.440188, acc 0.75\n",
      "2020-04-29T11:41:26.336680: step 1105, loss 0.298369, acc 0.890625\n",
      "2020-04-29T11:41:26.505650: step 1106, loss 0.259052, acc 0.890625\n",
      "2020-04-29T11:41:26.677513: step 1107, loss 0.309287, acc 0.828125\n",
      "2020-04-29T11:41:26.866684: step 1108, loss 0.522326, acc 0.796875\n",
      "2020-04-29T11:41:27.034578: step 1109, loss 0.249828, acc 0.890625\n",
      "2020-04-29T11:41:27.210476: step 1110, loss 0.441147, acc 0.859375\n",
      "2020-04-29T11:41:27.379438: step 1111, loss 0.229838, acc 0.875\n",
      "2020-04-29T11:41:27.556584: step 1112, loss 0.270492, acc 0.921875\n",
      "2020-04-29T11:41:27.728448: step 1113, loss 0.251586, acc 0.953125\n",
      "2020-04-29T11:41:27.906630: step 1114, loss 0.276249, acc 0.875\n",
      "2020-04-29T11:41:28.094117: step 1115, loss 0.44463, acc 0.8125\n",
      "2020-04-29T11:41:28.256565: step 1116, loss 0.273075, acc 0.890625\n",
      "2020-04-29T11:41:28.447562: step 1117, loss 0.352277, acc 0.859375\n",
      "2020-04-29T11:41:28.619426: step 1118, loss 0.366627, acc 0.78125\n",
      "2020-04-29T11:41:28.790937: step 1119, loss 0.15088, acc 0.953125\n",
      "2020-04-29T11:41:28.964364: step 1120, loss 0.341631, acc 0.859375\n",
      "2020-04-29T11:41:29.140163: step 1121, loss 0.41857, acc 0.75\n",
      "2020-04-29T11:41:29.308924: step 1122, loss 0.346759, acc 0.84375\n",
      "2020-04-29T11:41:29.480787: step 1123, loss 0.293768, acc 0.84375\n",
      "2020-04-29T11:41:29.657888: step 1124, loss 0.335441, acc 0.859375\n",
      "2020-04-29T11:41:29.829751: step 1125, loss 0.252664, acc 0.875\n",
      "2020-04-29T11:41:30.010881: step 1126, loss 0.227254, acc 0.921875\n",
      "2020-04-29T11:41:30.169061: step 1127, loss 0.307739, acc 0.859375\n",
      "2020-04-29T11:41:30.358713: step 1128, loss 0.30077, acc 0.875\n",
      "2020-04-29T11:41:30.530576: step 1129, loss 0.349624, acc 0.859375\n",
      "2020-04-29T11:41:30.700943: step 1130, loss 0.287903, acc 0.859375\n",
      "2020-04-29T11:41:30.857182: step 1131, loss 0.253325, acc 0.875\n",
      "2020-04-29T11:41:31.048590: step 1132, loss 0.511394, acc 0.75\n",
      "2020-04-29T11:41:31.202143: step 1133, loss 0.191332, acc 0.90625\n",
      "2020-04-29T11:41:31.383362: step 1134, loss 0.26197, acc 0.9375\n",
      "2020-04-29T11:41:31.555226: step 1135, loss 0.323794, acc 0.828125\n",
      "2020-04-29T11:41:31.727255: step 1136, loss 0.276669, acc 0.859375\n",
      "2020-04-29T11:41:31.914742: step 1137, loss 0.231754, acc 0.90625\n",
      "2020-04-29T11:41:32.093765: step 1138, loss 0.288562, acc 0.875\n",
      "2020-04-29T11:41:32.265628: step 1139, loss 0.34439, acc 0.78125\n",
      "2020-04-29T11:41:32.430018: step 1140, loss 0.229436, acc 0.953125\n",
      "2020-04-29T11:41:32.601880: step 1141, loss 0.296071, acc 0.90625\n",
      "2020-04-29T11:41:32.778048: step 1142, loss 0.29012, acc 0.890625\n",
      "2020-04-29T11:41:32.934288: step 1143, loss 0.350984, acc 0.796875\n",
      "2020-04-29T11:41:33.117391: step 1144, loss 0.345084, acc 0.84375\n",
      "2020-04-29T11:41:33.289254: step 1145, loss 0.278111, acc 0.875\n",
      "2020-04-29T11:41:33.462603: step 1146, loss 0.259971, acc 0.921875\n",
      "2020-04-29T11:41:33.634466: step 1147, loss 0.211012, acc 0.9375\n",
      "2020-04-29T11:41:33.812622: step 1148, loss 0.367964, acc 0.828125\n",
      "2020-04-29T11:41:33.984485: step 1149, loss 0.360802, acc 0.875\n",
      "2020-04-29T11:41:34.162793: step 1150, loss 0.21748, acc 0.9375\n",
      "2020-04-29T11:41:34.334657: step 1151, loss 0.367369, acc 0.828125\n",
      "2020-04-29T11:41:34.513427: step 1152, loss 0.348506, acc 0.84375\n",
      "2020-04-29T11:41:34.685287: step 1153, loss 0.415138, acc 0.8125\n",
      "2020-04-29T11:41:34.870384: step 1154, loss 0.302985, acc 0.84375\n",
      "2020-04-29T11:41:35.037034: step 1155, loss 0.398354, acc 0.828125\n",
      "2020-04-29T11:41:35.201607: step 1156, loss 0.18769, acc 0.953125\n",
      "2020-04-29T11:41:35.373470: step 1157, loss 0.328767, acc 0.84375\n",
      "2020-04-29T11:41:35.549164: step 1158, loss 0.343061, acc 0.859375\n",
      "2020-04-29T11:41:35.721026: step 1159, loss 0.239152, acc 0.90625\n",
      "2020-04-29T11:41:35.898902: step 1160, loss 0.303637, acc 0.859375\n",
      "2020-04-29T11:41:36.071568: step 1161, loss 0.294725, acc 0.875\n",
      "2020-04-29T11:41:36.248935: step 1162, loss 0.302766, acc 0.859375\n",
      "2020-04-29T11:41:36.420799: step 1163, loss 0.384076, acc 0.828125\n",
      "2020-04-29T11:41:36.598984: step 1164, loss 0.405547, acc 0.875\n",
      "2020-04-29T11:41:36.770847: step 1165, loss 0.329567, acc 0.875\n",
      "2020-04-29T11:41:36.934498: step 1166, loss 0.41598, acc 0.84375\n",
      "2020-04-29T11:41:37.113604: step 1167, loss 0.30199, acc 0.875\n",
      "2020-04-29T11:41:37.289118: step 1168, loss 0.432015, acc 0.84375\n",
      "2020-04-29T11:41:37.460981: step 1169, loss 0.291988, acc 0.828125\n",
      "2020-04-29T11:41:37.633855: step 1170, loss 0.420734, acc 0.84375\n",
      "2020-04-29T11:41:37.805720: step 1171, loss 0.294535, acc 0.859375\n",
      "2020-04-29T11:41:37.983800: step 1172, loss 0.445037, acc 0.78125\n",
      "2020-04-29T11:41:38.140039: step 1173, loss 0.313749, acc 0.859375\n",
      "2020-04-29T11:41:38.324782: step 1174, loss 0.261574, acc 0.875\n",
      "2020-04-29T11:41:38.496644: step 1175, loss 0.304029, acc 0.875\n",
      "2020-04-29T11:41:38.670171: step 1176, loss 0.286023, acc 0.90625\n",
      "2020-04-29T11:41:38.842036: step 1177, loss 0.371144, acc 0.8125\n",
      "2020-04-29T11:41:39.018026: step 1178, loss 0.31018, acc 0.890625\n",
      "2020-04-29T11:41:39.189888: step 1179, loss 0.306751, acc 0.890625\n",
      "2020-04-29T11:41:39.384484: step 1180, loss 0.507307, acc 0.75\n",
      "2020-04-29T11:41:39.540723: step 1181, loss 0.406272, acc 0.8125\n",
      "2020-04-29T11:41:39.725373: step 1182, loss 0.50517, acc 0.796875\n",
      "2020-04-29T11:41:39.881612: step 1183, loss 0.175835, acc 0.921875\n",
      "2020-04-29T11:41:40.071500: step 1184, loss 0.221008, acc 0.921875\n",
      "2020-04-29T11:41:40.243363: step 1185, loss 0.345956, acc 0.859375\n",
      "2020-04-29T11:41:40.418899: step 1186, loss 0.327571, acc 0.875\n",
      "2020-04-29T11:41:40.590763: step 1187, loss 0.416096, acc 0.8125\n",
      "2020-04-29T11:41:40.770480: step 1188, loss 0.407188, acc 0.875\n",
      "2020-04-29T11:41:40.942343: step 1189, loss 0.298284, acc 0.890625\n",
      "2020-04-29T11:41:41.106513: step 1190, loss 0.271884, acc 0.84375\n",
      "2020-04-29T11:41:41.278376: step 1191, loss 0.201227, acc 0.921875\n",
      "2020-04-29T11:41:41.454619: step 1192, loss 0.397539, acc 0.828125\n",
      "2020-04-29T11:41:41.626482: step 1193, loss 0.261779, acc 0.890625\n",
      "2020-04-29T11:41:41.821168: step 1194, loss 0.358428, acc 0.859375\n",
      "2020-04-29T11:41:41.990334: step 1195, loss 0.216399, acc 0.9375\n",
      "2020-04-29T11:41:42.156530: step 1196, loss 0.528088, acc 0.796875\n",
      "2020-04-29T11:41:42.328392: step 1197, loss 0.289271, acc 0.84375\n",
      "2020-04-29T11:41:42.512851: step 1198, loss 0.359989, acc 0.875\n",
      "2020-04-29T11:41:42.684715: step 1199, loss 0.403142, acc 0.84375\n",
      "2020-04-29T11:41:42.845161: step 1200, loss 0.314377, acc 0.85\n",
      "\n",
      "Evaluation:\n",
      "2020-04-29T11:41:43.101296: step 1200, loss 0.589374, acc 0.699812\n",
      "\n",
      "Saved model checkpoint to E:\\Project\\伯禹自然语言处理\\03基于卷积神经网络的文本分类\\runs\\1588131485\\checkpoints\\model-1200\n",
      "\n",
      "2020-04-29T11:41:43.784220: step 1201, loss 0.242503, acc 0.890625\n",
      "2020-04-29T11:41:43.965967: step 1202, loss 0.14508, acc 0.96875\n",
      "2020-04-29T11:41:44.121231: step 1203, loss 0.27351, acc 0.875\n",
      "2020-04-29T11:41:44.340812: step 1204, loss 0.216957, acc 0.875\n",
      "2020-04-29T11:41:44.512675: step 1205, loss 0.236888, acc 0.890625\n",
      "2020-04-29T11:41:44.691343: step 1206, loss 0.266559, acc 0.875\n",
      "2020-04-29T11:41:44.863206: step 1207, loss 0.169568, acc 0.953125\n",
      "2020-04-29T11:41:45.047414: step 1208, loss 0.356134, acc 0.8125\n",
      "2020-04-29T11:41:45.202844: step 1209, loss 0.296947, acc 0.890625\n",
      "2020-04-29T11:41:45.381312: step 1210, loss 0.307017, acc 0.859375\n",
      "2020-04-29T11:41:45.537552: step 1211, loss 0.365028, acc 0.8125\n",
      "2020-04-29T11:41:45.725241: step 1212, loss 0.355434, acc 0.828125\n",
      "2020-04-29T11:41:45.881480: step 1213, loss 0.175634, acc 0.953125\n",
      "2020-04-29T11:41:46.063546: step 1214, loss 0.213222, acc 0.921875\n",
      "2020-04-29T11:41:46.219785: step 1215, loss 0.192084, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-29T11:41:46.399013: step 1216, loss 0.305799, acc 0.859375\n",
      "2020-04-29T11:41:46.555253: step 1217, loss 0.240863, acc 0.890625\n",
      "2020-04-29T11:41:46.726829: step 1218, loss 0.238439, acc 0.890625\n",
      "2020-04-29T11:41:46.898691: step 1219, loss 0.266401, acc 0.90625\n",
      "2020-04-29T11:41:47.078249: step 1220, loss 0.359175, acc 0.84375\n",
      "2020-04-29T11:41:47.239232: step 1221, loss 0.173819, acc 0.953125\n",
      "2020-04-29T11:41:47.413287: step 1222, loss 0.36401, acc 0.8125\n",
      "2020-04-29T11:41:47.569525: step 1223, loss 0.283761, acc 0.859375\n",
      "2020-04-29T11:41:47.748071: step 1224, loss 0.356567, acc 0.84375\n",
      "2020-04-29T11:41:47.919933: step 1225, loss 0.27158, acc 0.921875\n",
      "2020-04-29T11:41:48.095128: step 1226, loss 0.26024, acc 0.890625\n",
      "2020-04-29T11:41:48.266992: step 1227, loss 0.216648, acc 0.890625\n",
      "2020-04-29T11:41:48.429391: step 1228, loss 0.370069, acc 0.796875\n",
      "2020-04-29T11:41:48.601252: step 1229, loss 0.187618, acc 0.953125\n",
      "2020-04-29T11:41:48.764563: step 1230, loss 0.198312, acc 0.953125\n",
      "2020-04-29T11:41:48.936426: step 1231, loss 0.246352, acc 0.890625\n",
      "2020-04-29T11:41:49.097002: step 1232, loss 0.365642, acc 0.90625\n",
      "2020-04-29T11:41:49.268865: step 1233, loss 0.301537, acc 0.859375\n",
      "2020-04-29T11:41:49.445533: step 1234, loss 0.214451, acc 0.9375\n",
      "2020-04-29T11:41:49.601772: step 1235, loss 0.309729, acc 0.90625\n",
      "2020-04-29T11:41:49.780000: step 1236, loss 0.35176, acc 0.84375\n",
      "2020-04-29T11:41:49.951862: step 1237, loss 0.299964, acc 0.875\n",
      "2020-04-29T11:41:50.130932: step 1238, loss 0.259721, acc 0.875\n",
      "2020-04-29T11:41:50.287171: step 1239, loss 0.237422, acc 0.921875\n",
      "2020-04-29T11:41:50.465066: step 1240, loss 0.271246, acc 0.90625\n",
      "2020-04-29T11:41:50.636926: step 1241, loss 0.222577, acc 0.890625\n",
      "2020-04-29T11:41:50.805454: step 1242, loss 0.249236, acc 0.90625\n",
      "2020-04-29T11:41:50.977212: step 1243, loss 0.247751, acc 0.921875\n",
      "2020-04-29T11:41:51.141889: step 1244, loss 0.259156, acc 0.90625\n",
      "2020-04-29T11:41:51.313752: step 1245, loss 0.139346, acc 0.984375\n",
      "2020-04-29T11:41:51.497700: step 1246, loss 0.411349, acc 0.8125\n",
      "2020-04-29T11:41:51.653938: step 1247, loss 0.169297, acc 0.953125\n",
      "2020-04-29T11:41:51.834511: step 1248, loss 0.248545, acc 0.890625\n",
      "2020-04-29T11:41:52.007104: step 1249, loss 0.273548, acc 0.90625\n",
      "2020-04-29T11:41:52.187674: step 1250, loss 0.174452, acc 0.953125\n",
      "2020-04-29T11:41:52.343914: step 1251, loss 0.258077, acc 0.921875\n",
      "2020-04-29T11:41:52.523744: step 1252, loss 0.315393, acc 0.859375\n",
      "2020-04-29T11:41:52.679983: step 1253, loss 0.271033, acc 0.890625\n",
      "2020-04-29T11:41:52.851587: step 1254, loss 0.259719, acc 0.875\n",
      "2020-04-29T11:41:53.023450: step 1255, loss 0.290988, acc 0.875\n",
      "2020-04-29T11:41:53.200778: step 1256, loss 0.213984, acc 0.953125\n",
      "2020-04-29T11:41:53.357016: step 1257, loss 0.203934, acc 0.921875\n",
      "2020-04-29T11:41:53.533915: step 1258, loss 0.378441, acc 0.828125\n",
      "2020-04-29T11:41:53.705779: step 1259, loss 0.255636, acc 0.890625\n",
      "2020-04-29T11:41:53.884884: step 1260, loss 0.27095, acc 0.90625\n",
      "2020-04-29T11:41:54.056746: step 1261, loss 0.191635, acc 0.9375\n",
      "2020-04-29T11:41:54.219589: step 1262, loss 0.278352, acc 0.84375\n",
      "2020-04-29T11:41:54.391450: step 1263, loss 0.295564, acc 0.859375\n",
      "2020-04-29T11:41:54.568961: step 1264, loss 0.264216, acc 0.90625\n",
      "2020-04-29T11:41:54.725201: step 1265, loss 0.278584, acc 0.875\n",
      "2020-04-29T11:41:54.903174: step 1266, loss 0.250695, acc 0.890625\n",
      "2020-04-29T11:41:55.076902: step 1267, loss 0.3598, acc 0.84375\n",
      "2020-04-29T11:41:55.253122: step 1268, loss 0.283534, acc 0.890625\n",
      "2020-04-29T11:41:55.409361: step 1269, loss 0.167556, acc 0.9375\n",
      "2020-04-29T11:41:55.588868: step 1270, loss 0.155946, acc 0.953125\n",
      "2020-04-29T11:41:55.745107: step 1271, loss 0.199719, acc 0.921875\n",
      "2020-04-29T11:41:55.924058: step 1272, loss 0.26066, acc 0.921875\n",
      "2020-04-29T11:41:56.080297: step 1273, loss 0.310586, acc 0.859375\n",
      "2020-04-29T11:41:56.254503: step 1274, loss 0.279181, acc 0.875\n",
      "2020-04-29T11:41:56.410741: step 1275, loss 0.246894, acc 0.90625\n",
      "2020-04-29T11:41:56.593528: step 1276, loss 0.330543, acc 0.796875\n",
      "2020-04-29T11:41:56.765391: step 1277, loss 0.217468, acc 0.890625\n",
      "2020-04-29T11:41:56.925057: step 1278, loss 0.307602, acc 0.890625\n",
      "2020-04-29T11:41:57.096920: step 1279, loss 0.225262, acc 0.90625\n",
      "2020-04-29T11:41:57.257295: step 1280, loss 0.280019, acc 0.875\n",
      "2020-04-29T11:41:57.429158: step 1281, loss 0.279853, acc 0.875\n",
      "2020-04-29T11:41:57.605317: step 1282, loss 0.184013, acc 0.953125\n",
      "2020-04-29T11:41:57.761558: step 1283, loss 0.235323, acc 0.859375\n",
      "2020-04-29T11:41:57.954911: step 1284, loss 0.384724, acc 0.828125\n",
      "2020-04-29T11:41:58.111150: step 1285, loss 0.40223, acc 0.765625\n",
      "2020-04-29T11:41:58.293712: step 1286, loss 0.159018, acc 0.96875\n",
      "2020-04-29T11:41:58.465574: step 1287, loss 0.324456, acc 0.84375\n",
      "2020-04-29T11:41:58.627810: step 1288, loss 0.266601, acc 0.9375\n",
      "2020-04-29T11:41:58.799674: step 1289, loss 0.252232, acc 0.875\n",
      "2020-04-29T11:41:58.973088: step 1290, loss 0.172219, acc 0.9375\n",
      "2020-04-29T11:41:59.136993: step 1291, loss 0.313182, acc 0.84375\n",
      "2020-04-29T11:41:59.294668: step 1292, loss 0.282588, acc 0.890625\n",
      "2020-04-29T11:41:59.466531: step 1293, loss 0.229427, acc 0.90625\n",
      "2020-04-29T11:41:59.626072: step 1294, loss 0.229319, acc 0.875\n",
      "2020-04-29T11:41:59.797935: step 1295, loss 0.258147, acc 0.890625\n",
      "2020-04-29T11:41:59.974928: step 1296, loss 0.168931, acc 0.9375\n",
      "2020-04-29T11:42:00.149827: step 1297, loss 0.262195, acc 0.859375\n",
      "2020-04-29T11:42:00.308964: step 1298, loss 0.251766, acc 0.890625\n",
      "2020-04-29T11:42:00.492750: step 1299, loss 0.222089, acc 0.953125\n",
      "2020-04-29T11:42:00.648988: step 1300, loss 0.258755, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2020-04-29T11:42:00.889228: step 1300, loss 0.586789, acc 0.725141\n",
      "\n",
      "Saved model checkpoint to E:\\Project\\伯禹自然语言处理\\03基于卷积神经网络的文本分类\\runs\\1588131485\\checkpoints\\model-1300\n",
      "\n",
      "2020-04-29T11:42:01.554292: step 1301, loss 0.270394, acc 0.84375\n",
      "2020-04-29T11:42:01.730326: step 1302, loss 0.152956, acc 0.96875\n",
      "2020-04-29T11:42:01.902188: step 1303, loss 0.207365, acc 0.921875\n",
      "2020-04-29T11:42:02.065488: step 1304, loss 0.169924, acc 0.921875\n",
      "2020-04-29T11:42:02.237352: step 1305, loss 0.224965, acc 0.890625\n",
      "2020-04-29T11:42:02.414882: step 1306, loss 0.310458, acc 0.859375\n",
      "2020-04-29T11:42:02.571120: step 1307, loss 0.212887, acc 0.9375\n",
      "2020-04-29T11:42:02.740215: step 1308, loss 0.236368, acc 0.9375\n",
      "2020-04-29T11:42:02.912077: step 1309, loss 0.354468, acc 0.875\n",
      "2020-04-29T11:42:03.083893: step 1310, loss 0.23751, acc 0.90625\n",
      "2020-04-29T11:42:03.240132: step 1311, loss 0.267341, acc 0.921875\n",
      "2020-04-29T11:42:03.417701: step 1312, loss 0.160682, acc 0.96875\n",
      "2020-04-29T11:42:03.573939: step 1313, loss 0.200877, acc 0.9375\n",
      "2020-04-29T11:42:03.747665: step 1314, loss 0.251018, acc 0.890625\n",
      "2020-04-29T11:42:03.919528: step 1315, loss 0.205627, acc 0.90625\n",
      "2020-04-29T11:42:04.098620: step 1316, loss 0.273171, acc 0.90625\n",
      "2020-04-29T11:42:04.279560: step 1317, loss 0.351162, acc 0.84375\n",
      "2020-04-29T11:42:04.451421: step 1318, loss 0.222585, acc 0.9375\n",
      "2020-04-29T11:42:04.614670: step 1319, loss 0.276775, acc 0.90625\n",
      "2020-04-29T11:42:04.786533: step 1320, loss 0.389204, acc 0.859375\n",
      "2020-04-29T11:42:04.970110: step 1321, loss 0.26931, acc 0.90625\n",
      "2020-04-29T11:42:05.141974: step 1322, loss 0.267175, acc 0.90625\n",
      "2020-04-29T11:42:05.314396: step 1323, loss 0.248914, acc 0.875\n",
      "2020-04-29T11:42:05.470635: step 1324, loss 0.289537, acc 0.875\n",
      "2020-04-29T11:42:05.635282: step 1325, loss 0.210184, acc 0.90625\n",
      "2020-04-29T11:42:05.807145: step 1326, loss 0.235701, acc 0.921875\n",
      "2020-04-29T11:42:05.991558: step 1327, loss 0.300021, acc 0.875\n",
      "2020-04-29T11:42:06.140548: step 1328, loss 0.286723, acc 0.890625\n",
      "2020-04-29T11:42:06.317365: step 1329, loss 0.511061, acc 0.796875\n",
      "2020-04-29T11:42:06.489230: step 1330, loss 0.249345, acc 0.875\n",
      "2020-04-29T11:42:06.655690: step 1331, loss 0.245515, acc 0.90625\n",
      "2020-04-29T11:42:06.827554: step 1332, loss 0.375215, acc 0.84375\n",
      "2020-04-29T11:42:07.001405: step 1333, loss 0.189249, acc 0.921875\n",
      "2020-04-29T11:42:07.157643: step 1334, loss 0.281798, acc 0.890625\n",
      "2020-04-29T11:42:07.334553: step 1335, loss 0.213084, acc 0.875\n",
      "2020-04-29T11:42:07.490793: step 1336, loss 0.382712, acc 0.875\n",
      "2020-04-29T11:42:07.668431: step 1337, loss 0.162185, acc 0.9375\n",
      "2020-04-29T11:42:07.824670: step 1338, loss 0.23219, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-29T11:42:08.086911: step 1339, loss 0.204827, acc 0.9375\n",
      "2020-04-29T11:42:08.238892: step 1340, loss 0.204056, acc 0.921875\n",
      "2020-04-29T11:42:08.417885: step 1341, loss 0.182868, acc 0.9375\n",
      "2020-04-29T11:42:08.574124: step 1342, loss 0.255924, acc 0.890625\n",
      "2020-04-29T11:42:08.754825: step 1343, loss 0.241062, acc 0.875\n",
      "2020-04-29T11:42:08.926689: step 1344, loss 0.293536, acc 0.859375\n",
      "2020-04-29T11:42:09.085013: step 1345, loss 0.408377, acc 0.890625\n",
      "2020-04-29T11:42:09.256876: step 1346, loss 0.240697, acc 0.859375\n",
      "2020-04-29T11:42:09.424198: step 1347, loss 0.218262, acc 0.9375\n",
      "2020-04-29T11:42:09.596061: step 1348, loss 0.339352, acc 0.828125\n",
      "2020-04-29T11:42:09.753378: step 1349, loss 0.196757, acc 0.90625\n",
      "2020-04-29T11:42:09.925241: step 1350, loss 0.252263, acc 0.866667\n",
      "2020-04-29T11:42:10.087277: step 1351, loss 0.175206, acc 0.90625\n",
      "2020-04-29T11:42:10.259140: step 1352, loss 0.245507, acc 0.875\n",
      "2020-04-29T11:42:10.420639: step 1353, loss 0.122607, acc 0.96875\n",
      "2020-04-29T11:42:10.592501: step 1354, loss 0.229841, acc 0.921875\n",
      "2020-04-29T11:42:10.754156: step 1355, loss 0.212746, acc 0.921875\n",
      "2020-04-29T11:42:10.926018: step 1356, loss 0.20029, acc 0.921875\n",
      "2020-04-29T11:42:11.088542: step 1357, loss 0.254708, acc 0.875\n",
      "2020-04-29T11:42:11.260406: step 1358, loss 0.214592, acc 0.90625\n",
      "2020-04-29T11:42:11.427562: step 1359, loss 0.176558, acc 0.90625\n",
      "2020-04-29T11:42:11.583801: step 1360, loss 0.20814, acc 0.9375\n",
      "2020-04-29T11:42:11.770782: step 1361, loss 0.188071, acc 0.953125\n",
      "2020-04-29T11:42:11.927018: step 1362, loss 0.211373, acc 0.90625\n",
      "2020-04-29T11:42:12.106234: step 1363, loss 0.157822, acc 0.984375\n",
      "2020-04-29T11:42:12.262474: step 1364, loss 0.196386, acc 0.90625\n",
      "2020-04-29T11:42:12.438667: step 1365, loss 0.165971, acc 0.9375\n",
      "2020-04-29T11:42:12.594905: step 1366, loss 0.229741, acc 0.9375\n",
      "2020-04-29T11:42:12.773835: step 1367, loss 0.138446, acc 0.953125\n",
      "2020-04-29T11:42:12.930073: step 1368, loss 0.214853, acc 0.859375\n",
      "2020-04-29T11:42:13.113515: step 1369, loss 0.154782, acc 0.921875\n",
      "2020-04-29T11:42:13.269755: step 1370, loss 0.168794, acc 0.921875\n",
      "2020-04-29T11:42:13.442610: step 1371, loss 0.237048, acc 0.90625\n",
      "2020-04-29T11:42:13.598848: step 1372, loss 0.214797, acc 0.9375\n",
      "2020-04-29T11:42:13.775482: step 1373, loss 0.187939, acc 0.921875\n",
      "2020-04-29T11:42:13.947343: step 1374, loss 0.170305, acc 0.9375\n",
      "2020-04-29T11:42:14.123898: step 1375, loss 0.203988, acc 0.921875\n",
      "2020-04-29T11:42:14.280136: step 1376, loss 0.186507, acc 0.890625\n",
      "2020-04-29T11:42:14.463293: step 1377, loss 0.144343, acc 0.953125\n",
      "2020-04-29T11:42:14.635156: step 1378, loss 0.262913, acc 0.859375\n",
      "2020-04-29T11:42:14.807419: step 1379, loss 0.156606, acc 0.953125\n",
      "2020-04-29T11:42:14.982214: step 1380, loss 0.104782, acc 0.96875\n",
      "2020-04-29T11:42:15.154115: step 1381, loss 0.218785, acc 0.9375\n",
      "2020-04-29T11:42:15.302686: step 1382, loss 0.263397, acc 0.859375\n",
      "2020-04-29T11:42:15.477089: step 1383, loss 0.166295, acc 0.9375\n",
      "2020-04-29T11:42:15.633328: step 1384, loss 0.346229, acc 0.875\n",
      "2020-04-29T11:42:15.815094: step 1385, loss 0.173702, acc 0.9375\n",
      "2020-04-29T11:42:15.988262: step 1386, loss 0.182011, acc 0.953125\n",
      "2020-04-29T11:42:16.160163: step 1387, loss 0.233909, acc 0.90625\n",
      "2020-04-29T11:42:16.321409: step 1388, loss 0.14907, acc 0.921875\n",
      "2020-04-29T11:42:16.481859: step 1389, loss 0.21942, acc 0.90625\n",
      "2020-04-29T11:42:16.653722: step 1390, loss 0.119171, acc 0.9375\n",
      "2020-04-29T11:42:16.826758: step 1391, loss 0.177141, acc 0.953125\n",
      "2020-04-29T11:42:16.985637: step 1392, loss 0.222635, acc 0.921875\n",
      "2020-04-29T11:42:17.164620: step 1393, loss 0.151057, acc 0.9375\n",
      "2020-04-29T11:42:17.320859: step 1394, loss 0.343218, acc 0.84375\n",
      "2020-04-29T11:42:17.495409: step 1395, loss 0.275087, acc 0.875\n",
      "2020-04-29T11:42:17.667273: step 1396, loss 0.125504, acc 0.96875\n",
      "2020-04-29T11:42:17.844481: step 1397, loss 0.180807, acc 0.9375\n",
      "2020-04-29T11:42:18.016344: step 1398, loss 0.104722, acc 0.984375\n",
      "2020-04-29T11:42:18.179696: step 1399, loss 0.245258, acc 0.890625\n",
      "2020-04-29T11:42:18.351558: step 1400, loss 0.184529, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2020-04-29T11:42:18.591287: step 1400, loss 0.604437, acc 0.71576\n",
      "\n",
      "Saved model checkpoint to E:\\Project\\伯禹自然语言处理\\03基于卷积神经网络的文本分类\\runs\\1588131485\\checkpoints\\model-1400\n",
      "\n",
      "2020-04-29T11:42:19.277012: step 1401, loss 0.161186, acc 0.9375\n",
      "2020-04-29T11:42:19.444121: step 1402, loss 0.293165, acc 0.84375\n",
      "2020-04-29T11:42:19.615984: step 1403, loss 0.205865, acc 0.890625\n",
      "2020-04-29T11:42:19.796871: step 1404, loss 0.222301, acc 0.9375\n",
      "2020-04-29T11:42:19.953109: step 1405, loss 0.281051, acc 0.90625\n",
      "2020-04-29T11:42:20.130534: step 1406, loss 0.25771, acc 0.890625\n",
      "2020-04-29T11:42:20.286772: step 1407, loss 0.148045, acc 0.921875\n",
      "2020-04-29T11:42:20.463959: step 1408, loss 0.168724, acc 0.9375\n",
      "2020-04-29T11:42:20.635821: step 1409, loss 0.204417, acc 0.90625\n",
      "2020-04-29T11:42:20.805340: step 1410, loss 0.182203, acc 0.921875\n",
      "2020-04-29T11:42:20.978038: step 1411, loss 0.14657, acc 0.953125\n",
      "2020-04-29T11:42:21.153936: step 1412, loss 0.255448, acc 0.828125\n",
      "2020-04-29T11:42:21.302570: step 1413, loss 0.192418, acc 0.953125\n",
      "2020-04-29T11:42:21.484431: step 1414, loss 0.151566, acc 0.953125\n",
      "2020-04-29T11:42:21.656295: step 1415, loss 0.217553, acc 0.921875\n",
      "2020-04-29T11:42:21.832467: step 1416, loss 0.206826, acc 0.921875\n",
      "2020-04-29T11:42:21.988706: step 1417, loss 0.160937, acc 0.9375\n",
      "2020-04-29T11:42:22.167724: step 1418, loss 0.248797, acc 0.90625\n",
      "2020-04-29T11:42:22.323963: step 1419, loss 0.24838, acc 0.890625\n",
      "2020-04-29T11:42:22.501789: step 1420, loss 0.155349, acc 0.9375\n",
      "2020-04-29T11:42:22.673652: step 1421, loss 0.219411, acc 0.90625\n",
      "2020-04-29T11:42:22.849957: step 1422, loss 0.15859, acc 0.953125\n",
      "2020-04-29T11:42:23.014447: step 1423, loss 0.168112, acc 0.921875\n",
      "2020-04-29T11:42:23.195343: step 1424, loss 0.185151, acc 0.90625\n",
      "2020-04-29T11:42:23.348335: step 1425, loss 0.240034, acc 0.890625\n",
      "2020-04-29T11:42:23.537584: step 1426, loss 0.189772, acc 0.921875\n",
      "2020-04-29T11:42:23.693822: step 1427, loss 0.33334, acc 0.859375\n",
      "2020-04-29T11:42:23.869302: step 1428, loss 0.123319, acc 0.96875\n",
      "2020-04-29T11:42:24.037220: step 1429, loss 0.192892, acc 0.921875\n",
      "2020-04-29T11:42:24.202719: step 1430, loss 0.116361, acc 0.96875\n",
      "2020-04-29T11:42:24.374581: step 1431, loss 0.249125, acc 0.875\n",
      "2020-04-29T11:42:24.551702: step 1432, loss 0.245507, acc 0.921875\n",
      "2020-04-29T11:42:24.723565: step 1433, loss 0.10606, acc 0.96875\n",
      "2020-04-29T11:42:24.902625: step 1434, loss 0.19774, acc 0.90625\n",
      "2020-04-29T11:42:25.058861: step 1435, loss 0.144316, acc 0.921875\n",
      "2020-04-29T11:42:25.244165: step 1436, loss 0.269301, acc 0.875\n",
      "2020-04-29T11:42:25.400404: step 1437, loss 0.154878, acc 0.921875\n",
      "2020-04-29T11:42:25.586614: step 1438, loss 0.146354, acc 0.953125\n",
      "2020-04-29T11:42:25.742852: step 1439, loss 0.248141, acc 0.84375\n",
      "2020-04-29T11:42:25.906999: step 1440, loss 0.270023, acc 0.90625\n",
      "2020-04-29T11:42:26.078861: step 1441, loss 0.142742, acc 0.9375\n",
      "2020-04-29T11:42:26.253506: step 1442, loss 0.179445, acc 0.953125\n",
      "2020-04-29T11:42:26.425368: step 1443, loss 0.394403, acc 0.828125\n",
      "2020-04-29T11:42:26.588369: step 1444, loss 0.276429, acc 0.859375\n",
      "2020-04-29T11:42:26.760231: step 1445, loss 0.128081, acc 0.96875\n",
      "2020-04-29T11:42:26.937975: step 1446, loss 0.200768, acc 0.921875\n",
      "2020-04-29T11:42:27.094214: step 1447, loss 0.243746, acc 0.859375\n",
      "2020-04-29T11:42:27.274512: step 1448, loss 0.238958, acc 0.90625\n",
      "2020-04-29T11:42:27.430750: step 1449, loss 0.188648, acc 0.90625\n",
      "2020-04-29T11:42:27.609371: step 1450, loss 0.0938959, acc 0.96875\n",
      "2020-04-29T11:42:27.765611: step 1451, loss 0.195106, acc 0.9375\n",
      "2020-04-29T11:42:27.940537: step 1452, loss 0.280127, acc 0.890625\n",
      "2020-04-29T11:42:28.107189: step 1453, loss 0.254411, acc 0.90625\n",
      "2020-04-29T11:42:28.275493: step 1454, loss 0.248088, acc 0.90625\n",
      "2020-04-29T11:42:28.447354: step 1455, loss 0.193142, acc 0.921875\n",
      "2020-04-29T11:42:28.608345: step 1456, loss 0.26237, acc 0.890625\n",
      "2020-04-29T11:42:28.780206: step 1457, loss 0.181786, acc 0.921875\n",
      "2020-04-29T11:42:28.961587: step 1458, loss 0.213933, acc 0.90625\n",
      "2020-04-29T11:42:29.124493: step 1459, loss 0.233566, acc 0.921875\n",
      "2020-04-29T11:42:29.287441: step 1460, loss 0.273486, acc 0.90625\n",
      "2020-04-29T11:42:29.459305: step 1461, loss 0.192842, acc 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-29T11:42:29.631386: step 1462, loss 0.138867, acc 0.9375\n",
      "2020-04-29T11:42:29.787626: step 1463, loss 0.139913, acc 0.9375\n",
      "2020-04-29T11:42:29.979272: step 1464, loss 0.238542, acc 0.890625\n",
      "2020-04-29T11:42:30.143178: step 1465, loss 0.194014, acc 0.90625\n",
      "2020-04-29T11:42:30.305786: step 1466, loss 0.156031, acc 0.953125\n",
      "2020-04-29T11:42:30.462026: step 1467, loss 0.244314, acc 0.9375\n",
      "2020-04-29T11:42:30.642119: step 1468, loss 0.32085, acc 0.890625\n",
      "2020-04-29T11:42:30.813981: step 1469, loss 0.129247, acc 0.96875\n",
      "2020-04-29T11:42:30.990109: step 1470, loss 0.177657, acc 0.953125\n",
      "2020-04-29T11:42:31.146349: step 1471, loss 0.222289, acc 0.90625\n",
      "2020-04-29T11:42:31.311726: step 1472, loss 0.212656, acc 0.875\n",
      "2020-04-29T11:42:31.483590: step 1473, loss 0.147164, acc 0.96875\n",
      "2020-04-29T11:42:31.652244: step 1474, loss 0.140648, acc 0.953125\n",
      "2020-04-29T11:42:31.808482: step 1475, loss 0.191085, acc 0.90625\n",
      "2020-04-29T11:42:31.990843: step 1476, loss 0.167113, acc 0.921875\n",
      "2020-04-29T11:42:32.150174: step 1477, loss 0.136542, acc 0.90625\n",
      "2020-04-29T11:42:32.311690: step 1478, loss 0.114075, acc 0.953125\n",
      "2020-04-29T11:42:32.483552: step 1479, loss 0.317276, acc 0.875\n",
      "2020-04-29T11:42:32.662971: step 1480, loss 0.21489, acc 0.890625\n",
      "2020-04-29T11:42:32.819209: step 1481, loss 0.13051, acc 0.953125\n",
      "2020-04-29T11:42:33.001093: step 1482, loss 0.186795, acc 0.90625\n",
      "2020-04-29T11:42:33.157333: step 1483, loss 0.1695, acc 0.9375\n",
      "2020-04-29T11:42:33.335735: step 1484, loss 0.0833355, acc 1\n",
      "2020-04-29T11:42:33.491974: step 1485, loss 0.193357, acc 0.9375\n",
      "2020-04-29T11:42:33.663386: step 1486, loss 0.297397, acc 0.90625\n",
      "2020-04-29T11:42:33.835249: step 1487, loss 0.230055, acc 0.9375\n",
      "2020-04-29T11:42:34.021994: step 1488, loss 0.124129, acc 0.984375\n",
      "2020-04-29T11:42:34.186875: step 1489, loss 0.197904, acc 0.9375\n",
      "2020-04-29T11:42:34.347483: step 1490, loss 0.163056, acc 0.953125\n",
      "2020-04-29T11:42:34.519349: step 1491, loss 0.171233, acc 0.90625\n",
      "2020-04-29T11:42:34.681001: step 1492, loss 0.223235, acc 0.90625\n",
      "2020-04-29T11:42:34.852864: step 1493, loss 0.243324, acc 0.890625\n",
      "2020-04-29T11:42:35.030330: step 1494, loss 0.135216, acc 0.9375\n",
      "2020-04-29T11:42:35.186569: step 1495, loss 0.185079, acc 0.90625\n",
      "2020-04-29T11:42:35.368862: step 1496, loss 0.20921, acc 0.921875\n",
      "2020-04-29T11:42:35.525099: step 1497, loss 0.307852, acc 0.84375\n",
      "2020-04-29T11:42:35.713998: step 1498, loss 0.172608, acc 0.9375\n",
      "2020-04-29T11:42:35.886812: step 1499, loss 0.332906, acc 0.890625\n",
      "2020-04-29T11:42:36.076215: step 1500, loss 0.112024, acc 0.95\n",
      "\n",
      "Evaluation:\n",
      "2020-04-29T11:42:36.332607: step 1500, loss 0.621293, acc 0.728893\n",
      "\n",
      "Saved model checkpoint to E:\\Project\\伯禹自然语言处理\\03基于卷积神经网络的文本分类\\runs\\1588131485\\checkpoints\\model-1500\n",
      "\n",
      "2020-04-29T11:42:37.003916: step 1501, loss 0.107366, acc 0.953125\n",
      "2020-04-29T11:42:37.175818: step 1502, loss 0.191726, acc 0.96875\n",
      "2020-04-29T11:42:37.337033: step 1503, loss 0.0903499, acc 0.984375\n",
      "2020-04-29T11:42:37.508897: step 1504, loss 0.120401, acc 0.96875\n",
      "2020-04-29T11:42:37.683656: step 1505, loss 0.174422, acc 0.953125\n",
      "2020-04-29T11:42:37.855519: step 1506, loss 0.116346, acc 0.96875\n",
      "2020-04-29T11:42:38.020304: step 1507, loss 0.122172, acc 0.953125\n",
      "2020-04-29T11:42:38.226460: step 1508, loss 0.222526, acc 0.921875\n",
      "2020-04-29T11:42:38.384983: step 1509, loss 0.16997, acc 0.9375\n",
      "2020-04-29T11:42:38.568897: step 1510, loss 0.0883631, acc 0.96875\n",
      "2020-04-29T11:42:38.725137: step 1511, loss 0.157514, acc 0.921875\n",
      "2020-04-29T11:42:38.897115: step 1512, loss 0.165602, acc 0.921875\n",
      "2020-04-29T11:42:39.068978: step 1513, loss 0.142909, acc 0.953125\n",
      "2020-04-29T11:42:39.251233: step 1514, loss 0.123075, acc 0.96875\n",
      "2020-04-29T11:42:39.407473: step 1515, loss 0.130389, acc 0.96875\n",
      "2020-04-29T11:42:39.573605: step 1516, loss 0.164266, acc 0.9375\n",
      "2020-04-29T11:42:39.745469: step 1517, loss 0.17002, acc 0.90625\n",
      "2020-04-29T11:42:39.918488: step 1518, loss 0.142407, acc 0.921875\n",
      "2020-04-29T11:42:40.090349: step 1519, loss 0.194107, acc 0.921875\n",
      "2020-04-29T11:42:40.260046: step 1520, loss 0.158284, acc 0.9375\n",
      "2020-04-29T11:42:40.416284: step 1521, loss 0.0989883, acc 0.96875\n",
      "2020-04-29T11:42:40.649968: step 1522, loss 0.0967024, acc 0.953125\n",
      "2020-04-29T11:42:40.858999: step 1523, loss 0.265101, acc 0.890625\n",
      "2020-04-29T11:42:41.070957: step 1524, loss 0.140695, acc 0.984375\n",
      "2020-04-29T11:42:41.261681: step 1525, loss 0.0691377, acc 0.984375\n",
      "2020-04-29T11:42:41.437239: step 1526, loss 0.12382, acc 0.9375\n",
      "2020-04-29T11:42:41.602252: step 1527, loss 0.10766, acc 0.96875\n",
      "2020-04-29T11:42:41.774115: step 1528, loss 0.159561, acc 0.953125\n",
      "2020-04-29T11:42:41.954102: step 1529, loss 0.259798, acc 0.90625\n",
      "2020-04-29T11:42:42.110341: step 1530, loss 0.203323, acc 0.890625\n",
      "2020-04-29T11:42:42.290604: step 1531, loss 0.179911, acc 0.9375\n",
      "2020-04-29T11:42:42.446843: step 1532, loss 0.119844, acc 0.96875\n",
      "2020-04-29T11:42:42.625648: step 1533, loss 0.156322, acc 0.9375\n",
      "2020-04-29T11:42:42.781887: step 1534, loss 0.278514, acc 0.890625\n",
      "2020-04-29T11:42:42.965106: step 1535, loss 0.072883, acc 0.984375\n",
      "2020-04-29T11:42:43.121345: step 1536, loss 0.238357, acc 0.90625\n",
      "2020-04-29T11:42:43.297387: step 1537, loss 0.289779, acc 0.921875\n",
      "2020-04-29T11:42:43.469251: step 1538, loss 0.134186, acc 0.921875\n",
      "2020-04-29T11:42:43.639521: step 1539, loss 0.10105, acc 0.953125\n",
      "2020-04-29T11:42:43.795761: step 1540, loss 0.183617, acc 0.9375\n",
      "2020-04-29T11:42:43.984792: step 1541, loss 0.0890176, acc 0.96875\n",
      "2020-04-29T11:42:44.154697: step 1542, loss 0.0828015, acc 0.984375\n",
      "2020-04-29T11:42:44.320951: step 1543, loss 0.200086, acc 0.890625\n",
      "2020-04-29T11:42:44.492815: step 1544, loss 0.0809744, acc 0.953125\n",
      "2020-04-29T11:42:44.673400: step 1545, loss 0.189569, acc 0.90625\n",
      "2020-04-29T11:42:44.829639: step 1546, loss 0.13531, acc 0.921875\n",
      "2020-04-29T11:42:45.005843: step 1547, loss 0.176514, acc 0.90625\n",
      "2020-04-29T11:42:45.177706: step 1548, loss 0.163308, acc 0.9375\n",
      "2020-04-29T11:42:45.357774: step 1549, loss 0.17141, acc 0.9375\n",
      "2020-04-29T11:42:45.514012: step 1550, loss 0.231413, acc 0.859375\n",
      "2020-04-29T11:42:45.681518: step 1551, loss 0.0611526, acc 0.984375\n",
      "2020-04-29T11:42:45.853382: step 1552, loss 0.0793121, acc 0.984375\n",
      "2020-04-29T11:42:46.024935: step 1553, loss 0.179651, acc 0.953125\n",
      "2020-04-29T11:42:46.196800: step 1554, loss 0.183725, acc 0.921875\n",
      "2020-04-29T11:42:46.365406: step 1555, loss 0.170041, acc 0.921875\n",
      "2020-04-29T11:42:46.537270: step 1556, loss 0.0943504, acc 0.984375\n",
      "2020-04-29T11:42:46.709350: step 1557, loss 0.206887, acc 0.9375\n",
      "2020-04-29T11:42:46.881214: step 1558, loss 0.171309, acc 0.921875\n",
      "2020-04-29T11:42:47.058606: step 1559, loss 0.0791307, acc 0.984375\n",
      "2020-04-29T11:42:47.220699: step 1560, loss 0.163759, acc 0.9375\n",
      "2020-04-29T11:42:47.395503: step 1561, loss 0.138414, acc 0.9375\n",
      "2020-04-29T11:42:47.551743: step 1562, loss 0.0780146, acc 0.984375\n",
      "2020-04-29T11:42:47.717003: step 1563, loss 0.140977, acc 0.953125\n",
      "2020-04-29T11:42:47.888867: step 1564, loss 0.141492, acc 0.96875\n",
      "2020-04-29T11:42:48.076297: step 1565, loss 0.102247, acc 0.984375\n",
      "2020-04-29T11:42:48.232536: step 1566, loss 0.228576, acc 0.9375\n",
      "2020-04-29T11:42:48.398421: step 1567, loss 0.150648, acc 0.953125\n",
      "2020-04-29T11:42:48.554659: step 1568, loss 0.0872896, acc 0.953125\n",
      "2020-04-29T11:42:48.731143: step 1569, loss 0.103357, acc 0.984375\n",
      "2020-04-29T11:42:48.887382: step 1570, loss 0.0885264, acc 0.953125\n",
      "2020-04-29T11:42:49.080835: step 1571, loss 0.150051, acc 0.921875\n",
      "2020-04-29T11:42:49.237074: step 1572, loss 0.0880885, acc 1\n",
      "2020-04-29T11:42:49.414618: step 1573, loss 0.142756, acc 0.921875\n",
      "2020-04-29T11:42:49.570857: step 1574, loss 0.0914927, acc 0.984375\n",
      "2020-04-29T11:42:49.747414: step 1575, loss 0.128283, acc 0.9375\n",
      "2020-04-29T11:42:49.903653: step 1576, loss 0.207871, acc 0.921875\n",
      "2020-04-29T11:42:50.080958: step 1577, loss 0.118767, acc 0.953125\n",
      "2020-04-29T11:42:50.237197: step 1578, loss 0.302636, acc 0.890625\n",
      "2020-04-29T11:42:50.415747: step 1579, loss 0.11627, acc 0.953125\n",
      "2020-04-29T11:42:50.571986: step 1580, loss 0.175539, acc 0.953125\n",
      "2020-04-29T11:42:50.749521: step 1581, loss 0.152251, acc 0.9375\n",
      "2020-04-29T11:42:50.905761: step 1582, loss 0.238406, acc 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-29T11:42:51.090775: step 1583, loss 0.123316, acc 0.953125\n",
      "2020-04-29T11:42:51.254680: step 1584, loss 0.139423, acc 0.9375\n",
      "2020-04-29T11:42:51.417737: step 1585, loss 0.166593, acc 0.921875\n",
      "2020-04-29T11:42:51.589600: step 1586, loss 0.150543, acc 0.953125\n",
      "2020-04-29T11:42:51.749978: step 1587, loss 0.151224, acc 0.9375\n",
      "2020-04-29T11:42:51.921841: step 1588, loss 0.0897073, acc 0.96875\n",
      "2020-04-29T11:42:52.099346: step 1589, loss 0.114576, acc 0.96875\n",
      "2020-04-29T11:42:52.271210: step 1590, loss 0.104905, acc 0.96875\n",
      "2020-04-29T11:42:52.438468: step 1591, loss 0.159054, acc 0.953125\n",
      "2020-04-29T11:42:52.594708: step 1592, loss 0.172379, acc 0.90625\n",
      "2020-04-29T11:42:52.772998: step 1593, loss 0.110001, acc 0.953125\n",
      "2020-04-29T11:42:52.929237: step 1594, loss 0.102174, acc 0.953125\n",
      "2020-04-29T11:42:53.096528: step 1595, loss 0.208384, acc 0.890625\n",
      "2020-04-29T11:42:53.268391: step 1596, loss 0.14349, acc 0.921875\n",
      "2020-04-29T11:42:53.440972: step 1597, loss 0.110716, acc 0.96875\n",
      "2020-04-29T11:42:53.612835: step 1598, loss 0.166765, acc 0.96875\n",
      "2020-04-29T11:42:53.783826: step 1599, loss 0.183811, acc 0.921875\n",
      "2020-04-29T11:42:53.962233: step 1600, loss 0.128209, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2020-04-29T11:42:54.202460: step 1600, loss 0.619713, acc 0.745779\n",
      "\n",
      "Saved model checkpoint to E:\\Project\\伯禹自然语言处理\\03基于卷积神经网络的文本分类\\runs\\1588131485\\checkpoints\\model-1600\n",
      "\n",
      "2020-04-29T11:42:54.862258: step 1601, loss 0.21527, acc 0.921875\n",
      "2020-04-29T11:42:55.051754: step 1602, loss 0.182333, acc 0.90625\n",
      "2020-04-29T11:42:55.202283: step 1603, loss 0.120502, acc 0.96875\n",
      "2020-04-29T11:42:55.377730: step 1604, loss 0.153912, acc 0.90625\n",
      "2020-04-29T11:42:55.549591: step 1605, loss 0.0952926, acc 0.953125\n",
      "2020-04-29T11:42:55.718777: step 1606, loss 0.249081, acc 0.890625\n",
      "2020-04-29T11:42:55.890639: step 1607, loss 0.195429, acc 0.90625\n",
      "2020-04-29T11:42:56.069832: step 1608, loss 0.198845, acc 0.921875\n",
      "2020-04-29T11:42:56.226070: step 1609, loss 0.095115, acc 0.953125\n",
      "2020-04-29T11:42:56.410118: step 1610, loss 0.14633, acc 0.9375\n",
      "2020-04-29T11:42:56.566357: step 1611, loss 0.223566, acc 0.921875\n",
      "2020-04-29T11:42:56.738818: step 1612, loss 0.236176, acc 0.921875\n",
      "2020-04-29T11:42:56.910680: step 1613, loss 0.190462, acc 0.921875\n",
      "2020-04-29T11:42:57.076863: step 1614, loss 0.123397, acc 0.984375\n",
      "2020-04-29T11:42:57.248725: step 1615, loss 0.161901, acc 0.9375\n",
      "2020-04-29T11:42:57.405518: step 1616, loss 0.172513, acc 0.921875\n",
      "2020-04-29T11:42:57.577382: step 1617, loss 0.308987, acc 0.859375\n",
      "2020-04-29T11:42:57.740076: step 1618, loss 0.141233, acc 0.953125\n",
      "2020-04-29T11:42:57.911939: step 1619, loss 0.16065, acc 0.953125\n",
      "2020-04-29T11:42:58.095279: step 1620, loss 0.161187, acc 0.9375\n",
      "2020-04-29T11:42:58.267142: step 1621, loss 0.068743, acc 0.984375\n",
      "2020-04-29T11:42:58.423851: step 1622, loss 0.143551, acc 0.953125\n",
      "2020-04-29T11:42:58.595714: step 1623, loss 0.121196, acc 0.953125\n",
      "2020-04-29T11:42:58.756672: step 1624, loss 0.319697, acc 0.84375\n",
      "2020-04-29T11:42:58.928535: step 1625, loss 0.138793, acc 0.921875\n",
      "2020-04-29T11:42:59.097135: step 1626, loss 0.110344, acc 0.953125\n",
      "2020-04-29T11:42:59.268997: step 1627, loss 0.234862, acc 0.859375\n",
      "2020-04-29T11:42:59.440940: step 1628, loss 0.183801, acc 0.9375\n",
      "2020-04-29T11:42:59.597180: step 1629, loss 0.158633, acc 0.921875\n",
      "2020-04-29T11:42:59.774439: step 1630, loss 0.150259, acc 0.921875\n",
      "2020-04-29T11:42:59.946302: step 1631, loss 0.214811, acc 0.90625\n",
      "2020-04-29T11:43:00.109038: step 1632, loss 0.139539, acc 0.96875\n",
      "2020-04-29T11:43:00.280900: step 1633, loss 0.152124, acc 0.9375\n",
      "2020-04-29T11:43:00.458266: step 1634, loss 0.176214, acc 0.9375\n",
      "2020-04-29T11:43:00.614505: step 1635, loss 0.20276, acc 0.90625\n",
      "2020-04-29T11:43:00.796887: step 1636, loss 0.293509, acc 0.875\n",
      "2020-04-29T11:43:00.953125: step 1637, loss 0.178062, acc 0.90625\n",
      "2020-04-29T11:43:01.129960: step 1638, loss 0.187282, acc 0.890625\n",
      "2020-04-29T11:43:01.354757: step 1639, loss 0.226792, acc 0.90625\n",
      "2020-04-29T11:43:01.523611: step 1640, loss 0.207797, acc 0.90625\n",
      "2020-04-29T11:43:01.697179: step 1641, loss 0.149352, acc 0.953125\n",
      "2020-04-29T11:43:01.869041: step 1642, loss 0.158059, acc 0.9375\n",
      "2020-04-29T11:43:02.043837: step 1643, loss 0.197374, acc 0.96875\n",
      "2020-04-29T11:43:02.215401: step 1644, loss 0.168548, acc 0.921875\n",
      "2020-04-29T11:43:02.384456: step 1645, loss 0.111436, acc 0.96875\n",
      "2020-04-29T11:43:02.540695: step 1646, loss 0.13524, acc 0.9375\n",
      "2020-04-29T11:43:02.727387: step 1647, loss 0.248991, acc 0.9375\n",
      "2020-04-29T11:43:02.883626: step 1648, loss 0.262171, acc 0.890625\n",
      "2020-04-29T11:43:03.060849: step 1649, loss 0.177405, acc 0.953125\n",
      "2020-04-29T11:43:03.217089: step 1650, loss 0.166387, acc 0.916667\n",
      "2020-04-29T11:43:03.394543: step 1651, loss 0.0791657, acc 0.984375\n",
      "2020-04-29T11:43:03.550782: step 1652, loss 0.143978, acc 0.953125\n",
      "2020-04-29T11:43:03.742449: step 1653, loss 0.0758912, acc 0.984375\n",
      "2020-04-29T11:43:03.898688: step 1654, loss 0.142095, acc 0.921875\n",
      "2020-04-29T11:43:04.095012: step 1655, loss 0.0843556, acc 0.984375\n",
      "2020-04-29T11:43:04.251250: step 1656, loss 0.0920027, acc 0.984375\n",
      "2020-04-29T11:43:04.429705: step 1657, loss 0.168955, acc 0.90625\n",
      "2020-04-29T11:43:04.601567: step 1658, loss 0.0746701, acc 0.96875\n",
      "2020-04-29T11:43:04.771373: step 1659, loss 0.172001, acc 0.953125\n",
      "2020-04-29T11:43:04.943234: step 1660, loss 0.0586478, acc 0.984375\n",
      "2020-04-29T11:43:05.113580: step 1661, loss 0.0740177, acc 0.96875\n",
      "2020-04-29T11:43:05.285443: step 1662, loss 0.179916, acc 0.9375\n",
      "2020-04-29T11:43:05.447584: step 1663, loss 0.107901, acc 0.96875\n",
      "2020-04-29T11:43:05.619447: step 1664, loss 0.126212, acc 0.9375\n",
      "2020-04-29T11:43:05.796577: step 1665, loss 0.0814152, acc 0.984375\n",
      "2020-04-29T11:43:05.968439: step 1666, loss 0.15156, acc 0.90625\n",
      "2020-04-29T11:43:06.148163: step 1667, loss 0.139388, acc 0.9375\n",
      "2020-04-29T11:43:06.304401: step 1668, loss 0.0928021, acc 0.953125\n",
      "2020-04-29T11:43:06.485791: step 1669, loss 0.141983, acc 0.9375\n",
      "2020-04-29T11:43:06.657653: step 1670, loss 0.236926, acc 0.90625\n",
      "2020-04-29T11:43:06.831592: step 1671, loss 0.138779, acc 0.984375\n",
      "2020-04-29T11:43:07.003299: step 1672, loss 0.15294, acc 0.921875\n",
      "2020-04-29T11:43:07.166680: step 1673, loss 0.120565, acc 0.96875\n",
      "2020-04-29T11:43:07.338544: step 1674, loss 0.100999, acc 0.96875\n",
      "2020-04-29T11:43:07.500137: step 1675, loss 0.0732837, acc 0.984375\n",
      "2020-04-29T11:43:07.672000: step 1676, loss 0.232403, acc 0.890625\n",
      "2020-04-29T11:43:07.854960: step 1677, loss 0.0815919, acc 0.96875\n",
      "2020-04-29T11:43:08.026824: step 1678, loss 0.0851237, acc 0.984375\n",
      "2020-04-29T11:43:08.184250: step 1679, loss 0.0801188, acc 0.96875\n",
      "2020-04-29T11:43:08.356113: step 1680, loss 0.283469, acc 0.890625\n",
      "2020-04-29T11:43:08.517469: step 1681, loss 0.221876, acc 0.9375\n",
      "2020-04-29T11:43:08.689332: step 1682, loss 0.104016, acc 0.984375\n",
      "2020-04-29T11:43:08.867594: step 1683, loss 0.113039, acc 0.96875\n",
      "2020-04-29T11:43:09.023832: step 1684, loss 0.114367, acc 0.96875\n",
      "2020-04-29T11:43:09.201915: step 1685, loss 0.200089, acc 0.921875\n",
      "2020-04-29T11:43:09.373778: step 1686, loss 0.120674, acc 0.953125\n",
      "2020-04-29T11:43:09.554985: step 1687, loss 0.0740068, acc 0.984375\n",
      "2020-04-29T11:43:09.726849: step 1688, loss 0.037593, acc 1\n",
      "2020-04-29T11:43:09.901184: step 1689, loss 0.179096, acc 0.9375\n",
      "2020-04-29T11:43:10.073048: step 1690, loss 0.0580631, acc 1\n",
      "2020-04-29T11:43:10.252530: step 1691, loss 0.0824246, acc 0.984375\n",
      "2020-04-29T11:43:10.408767: step 1692, loss 0.100444, acc 0.953125\n",
      "2020-04-29T11:43:10.587680: step 1693, loss 0.103617, acc 0.96875\n",
      "2020-04-29T11:43:10.759544: step 1694, loss 0.153069, acc 0.921875\n",
      "2020-04-29T11:43:10.938200: step 1695, loss 0.0627575, acc 0.984375\n",
      "2020-04-29T11:43:11.094438: step 1696, loss 0.16432, acc 0.90625\n",
      "2020-04-29T11:43:11.271238: step 1697, loss 0.166539, acc 0.984375\n",
      "2020-04-29T11:43:11.443101: step 1698, loss 0.102924, acc 0.953125\n",
      "2020-04-29T11:43:11.621675: step 1699, loss 0.153632, acc 0.921875\n",
      "2020-04-29T11:43:11.777915: step 1700, loss 0.175202, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2020-04-29T11:43:12.017988: step 1700, loss 0.688932, acc 0.711069\n",
      "\n",
      "Saved model checkpoint to E:\\Project\\伯禹自然语言处理\\03基于卷积神经网络的文本分类\\runs\\1588131485\\checkpoints\\model-1700\n",
      "\n",
      "2020-04-29T11:43:12.698020: step 1701, loss 0.134623, acc 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-29T11:43:12.887135: step 1702, loss 0.0868087, acc 0.96875\n",
      "2020-04-29T11:43:13.058998: step 1703, loss 0.173511, acc 0.953125\n",
      "2020-04-29T11:43:13.223987: step 1704, loss 0.154938, acc 0.9375\n",
      "2020-04-29T11:43:13.395849: step 1705, loss 0.129652, acc 0.953125\n",
      "2020-04-29T11:43:13.573577: step 1706, loss 0.127126, acc 0.953125\n",
      "2020-04-29T11:43:13.745441: step 1707, loss 0.143436, acc 0.921875\n",
      "2020-04-29T11:43:13.922780: step 1708, loss 0.0617736, acc 0.984375\n",
      "2020-04-29T11:43:14.094642: step 1709, loss 0.154607, acc 0.9375\n",
      "2020-04-29T11:43:14.273083: step 1710, loss 0.177947, acc 0.921875\n",
      "2020-04-29T11:43:14.444947: step 1711, loss 0.16413, acc 0.96875\n",
      "2020-04-29T11:43:14.623866: step 1712, loss 0.114483, acc 0.953125\n",
      "2020-04-29T11:43:14.795729: step 1713, loss 0.145192, acc 0.953125\n",
      "2020-04-29T11:43:14.977471: step 1714, loss 0.22124, acc 0.875\n",
      "2020-04-29T11:43:15.142056: step 1715, loss 0.16917, acc 0.953125\n",
      "2020-04-29T11:43:15.318333: step 1716, loss 0.164669, acc 0.9375\n",
      "2020-04-29T11:43:15.490197: step 1717, loss 0.152252, acc 0.9375\n",
      "2020-04-29T11:43:15.662672: step 1718, loss 0.0881913, acc 0.953125\n",
      "2020-04-29T11:43:15.834536: step 1719, loss 0.209055, acc 0.890625\n",
      "2020-04-29T11:43:16.019512: step 1720, loss 0.0997377, acc 0.96875\n",
      "2020-04-29T11:43:16.171820: step 1721, loss 0.051917, acc 0.984375\n",
      "2020-04-29T11:43:16.359170: step 1722, loss 0.0900041, acc 0.96875\n",
      "2020-04-29T11:43:16.515409: step 1723, loss 0.0940157, acc 0.953125\n",
      "2020-04-29T11:43:16.693013: step 1724, loss 0.189987, acc 0.90625\n",
      "2020-04-29T11:43:16.864877: step 1725, loss 0.0853178, acc 0.984375\n",
      "2020-04-29T11:43:17.032374: step 1726, loss 0.245951, acc 0.921875\n",
      "2020-04-29T11:43:17.204236: step 1727, loss 0.121598, acc 0.953125\n",
      "2020-04-29T11:43:17.392068: step 1728, loss 0.0815856, acc 0.984375\n",
      "2020-04-29T11:43:17.548307: step 1729, loss 0.0550878, acc 1\n",
      "2020-04-29T11:43:17.727498: step 1730, loss 0.20576, acc 0.96875\n",
      "2020-04-29T11:43:17.899362: step 1731, loss 0.144307, acc 0.96875\n",
      "2020-04-29T11:43:18.094677: step 1732, loss 0.0949386, acc 0.984375\n",
      "2020-04-29T11:43:18.255286: step 1733, loss 0.199188, acc 0.90625\n",
      "2020-04-29T11:43:18.433313: step 1734, loss 0.11766, acc 0.953125\n",
      "2020-04-29T11:43:18.605176: step 1735, loss 0.116889, acc 0.96875\n",
      "2020-04-29T11:43:18.778541: step 1736, loss 0.217375, acc 0.890625\n",
      "2020-04-29T11:43:18.950404: step 1737, loss 0.101238, acc 0.96875\n",
      "2020-04-29T11:43:19.128662: step 1738, loss 0.0991972, acc 0.96875\n",
      "2020-04-29T11:43:19.300525: step 1739, loss 0.0742895, acc 0.984375\n",
      "2020-04-29T11:43:19.478570: step 1740, loss 0.117562, acc 0.953125\n",
      "2020-04-29T11:43:19.634810: step 1741, loss 0.163706, acc 0.953125\n",
      "2020-04-29T11:43:19.821097: step 1742, loss 0.188236, acc 0.921875\n",
      "2020-04-29T11:43:19.990310: step 1743, loss 0.0695467, acc 0.984375\n",
      "2020-04-29T11:43:20.164407: step 1744, loss 0.243338, acc 0.90625\n",
      "2020-04-29T11:43:20.336269: step 1745, loss 0.109451, acc 0.953125\n",
      "2020-04-29T11:43:20.513630: step 1746, loss 0.176072, acc 0.90625\n",
      "2020-04-29T11:43:20.669867: step 1747, loss 0.101974, acc 0.953125\n",
      "2020-04-29T11:43:20.847926: step 1748, loss 0.132847, acc 0.9375\n",
      "2020-04-29T11:43:21.025451: step 1749, loss 0.173346, acc 0.953125\n",
      "2020-04-29T11:43:21.196233: step 1750, loss 0.123485, acc 0.984375\n",
      "2020-04-29T11:43:21.366811: step 1751, loss 0.199756, acc 0.9375\n",
      "2020-04-29T11:43:21.538674: step 1752, loss 0.21942, acc 0.90625\n",
      "2020-04-29T11:43:21.730162: step 1753, loss 0.117344, acc 0.921875\n",
      "2020-04-29T11:43:21.886402: step 1754, loss 0.199069, acc 0.9375\n",
      "2020-04-29T11:43:22.077405: step 1755, loss 0.0496433, acc 0.984375\n",
      "2020-04-29T11:43:22.240766: step 1756, loss 0.107867, acc 0.953125\n",
      "2020-04-29T11:43:22.416221: step 1757, loss 0.0893518, acc 0.984375\n",
      "2020-04-29T11:43:22.572460: step 1758, loss 0.0755169, acc 0.96875\n",
      "2020-04-29T11:43:22.750530: step 1759, loss 0.0893005, acc 0.984375\n",
      "2020-04-29T11:43:22.922394: step 1760, loss 0.104367, acc 0.96875\n",
      "2020-04-29T11:43:23.100074: step 1761, loss 0.155814, acc 0.9375\n",
      "2020-04-29T11:43:23.256312: step 1762, loss 0.0614907, acc 0.984375\n",
      "2020-04-29T11:43:23.450484: step 1763, loss 0.209956, acc 0.953125\n",
      "2020-04-29T11:43:23.606724: step 1764, loss 0.103415, acc 0.96875\n",
      "2020-04-29T11:43:23.788816: step 1765, loss 0.133586, acc 0.921875\n",
      "2020-04-29T11:43:23.963182: step 1766, loss 0.0824229, acc 0.96875\n",
      "2020-04-29T11:43:24.153072: step 1767, loss 0.0716107, acc 0.96875\n",
      "2020-04-29T11:43:24.318205: step 1768, loss 0.109794, acc 0.9375\n",
      "2020-04-29T11:43:24.501729: step 1769, loss 0.156657, acc 0.9375\n",
      "2020-04-29T11:43:24.673591: step 1770, loss 0.153175, acc 0.921875\n",
      "2020-04-29T11:43:24.836094: step 1771, loss 0.21115, acc 0.90625\n",
      "2020-04-29T11:43:25.019270: step 1772, loss 0.114143, acc 0.9375\n",
      "2020-04-29T11:43:25.203165: step 1773, loss 0.152031, acc 0.90625\n",
      "2020-04-29T11:43:25.368259: step 1774, loss 0.120644, acc 0.9375\n",
      "2020-04-29T11:43:25.537374: step 1775, loss 0.087571, acc 0.9375\n",
      "2020-04-29T11:43:25.709236: step 1776, loss 0.142084, acc 0.953125\n",
      "2020-04-29T11:43:25.892197: step 1777, loss 0.112003, acc 0.953125\n",
      "2020-04-29T11:43:26.065933: step 1778, loss 0.0468942, acc 1\n",
      "2020-04-29T11:43:26.243829: step 1779, loss 0.13373, acc 0.953125\n",
      "2020-04-29T11:43:26.409813: step 1780, loss 0.14467, acc 0.921875\n",
      "2020-04-29T11:43:26.588268: step 1781, loss 0.0997557, acc 0.96875\n",
      "2020-04-29T11:43:26.760131: step 1782, loss 0.1453, acc 0.953125\n",
      "2020-04-29T11:43:26.921992: step 1783, loss 0.164743, acc 0.953125\n",
      "2020-04-29T11:43:27.093855: step 1784, loss 0.105269, acc 0.984375\n",
      "2020-04-29T11:43:27.270754: step 1785, loss 0.0907968, acc 0.96875\n",
      "2020-04-29T11:43:27.426993: step 1786, loss 0.132741, acc 0.9375\n",
      "2020-04-29T11:43:27.605398: step 1787, loss 0.160783, acc 0.953125\n",
      "2020-04-29T11:43:27.777262: step 1788, loss 0.12897, acc 0.9375\n",
      "2020-04-29T11:43:27.973874: step 1789, loss 0.0574294, acc 0.96875\n",
      "2020-04-29T11:43:28.139708: step 1790, loss 0.112073, acc 0.96875\n",
      "2020-04-29T11:43:28.313946: step 1791, loss 0.0429822, acc 0.984375\n",
      "2020-04-29T11:43:28.485810: step 1792, loss 0.132161, acc 0.96875\n",
      "2020-04-29T11:43:28.660286: step 1793, loss 0.17346, acc 0.96875\n",
      "2020-04-29T11:43:28.832150: step 1794, loss 0.167916, acc 0.9375\n",
      "2020-04-29T11:43:29.014124: step 1795, loss 0.147246, acc 0.9375\n",
      "2020-04-29T11:43:29.166143: step 1796, loss 0.132011, acc 0.953125\n",
      "2020-04-29T11:43:29.343553: step 1797, loss 0.157873, acc 0.9375\n",
      "2020-04-29T11:43:29.515415: step 1798, loss 0.142903, acc 0.921875\n",
      "2020-04-29T11:43:29.690516: step 1799, loss 0.203675, acc 0.890625\n",
      "2020-04-29T11:43:29.862379: step 1800, loss 0.191398, acc 0.916667\n",
      "\n",
      "Evaluation:\n",
      "2020-04-29T11:43:30.105173: step 1800, loss 0.659389, acc 0.742964\n",
      "\n",
      "Saved model checkpoint to E:\\Project\\伯禹自然语言处理\\03基于卷积神经网络的文本分类\\runs\\1588131485\\checkpoints\\model-1800\n",
      "\n",
      "2020-04-29T11:43:30.752801: step 1801, loss 0.110657, acc 0.96875\n",
      "2020-04-29T11:43:30.942642: step 1802, loss 0.092206, acc 0.96875\n",
      "2020-04-29T11:43:31.108353: step 1803, loss 0.0713118, acc 0.984375\n",
      "2020-04-29T11:43:31.277776: step 1804, loss 0.0849922, acc 1\n",
      "2020-04-29T11:43:31.449640: step 1805, loss 0.0718471, acc 0.96875\n",
      "2020-04-29T11:43:31.624036: step 1806, loss 0.166969, acc 0.953125\n",
      "2020-04-29T11:43:31.780275: step 1807, loss 0.137132, acc 0.953125\n",
      "2020-04-29T11:43:31.968512: step 1808, loss 0.101385, acc 0.96875\n",
      "2020-04-29T11:43:32.133416: step 1809, loss 0.132396, acc 0.90625\n",
      "2020-04-29T11:43:32.296405: step 1810, loss 0.127301, acc 0.953125\n",
      "2020-04-29T11:43:32.468268: step 1811, loss 0.094363, acc 0.953125\n",
      "2020-04-29T11:43:32.629431: step 1812, loss 0.104511, acc 0.9375\n",
      "2020-04-29T11:43:32.801293: step 1813, loss 0.0931069, acc 0.984375\n",
      "2020-04-29T11:43:32.983190: step 1814, loss 0.112435, acc 0.9375\n",
      "2020-04-29T11:43:33.147097: step 1815, loss 0.123979, acc 0.953125\n",
      "2020-04-29T11:43:33.305787: step 1816, loss 0.0412336, acc 1\n",
      "2020-04-29T11:43:33.477651: step 1817, loss 0.124631, acc 0.953125\n",
      "2020-04-29T11:43:33.659558: step 1818, loss 0.18643, acc 0.9375\n",
      "2020-04-29T11:43:33.815797: step 1819, loss 0.119638, acc 0.96875\n",
      "2020-04-29T11:43:33.990525: step 1820, loss 0.148347, acc 0.9375\n",
      "2020-04-29T11:43:34.162390: step 1821, loss 0.0821697, acc 0.96875\n",
      "2020-04-29T11:43:34.344802: step 1822, loss 0.0655604, acc 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-29T11:43:34.532289: step 1823, loss 0.0758401, acc 0.953125\n",
      "2020-04-29T11:43:34.697111: step 1824, loss 0.0686773, acc 0.96875\n",
      "2020-04-29T11:43:34.880672: step 1825, loss 0.087252, acc 0.96875\n",
      "2020-04-29T11:43:35.036911: step 1826, loss 0.0605189, acc 0.984375\n",
      "2020-04-29T11:43:35.212978: step 1827, loss 0.122352, acc 0.96875\n",
      "2020-04-29T11:43:35.384842: step 1828, loss 0.0600028, acc 0.984375\n",
      "2020-04-29T11:43:35.562009: step 1829, loss 0.0994095, acc 0.96875\n",
      "2020-04-29T11:43:35.718248: step 1830, loss 0.128123, acc 0.953125\n",
      "2020-04-29T11:43:35.905637: step 1831, loss 0.0571886, acc 0.984375\n",
      "2020-04-29T11:43:36.061877: step 1832, loss 0.076395, acc 0.96875\n",
      "2020-04-29T11:43:36.235057: step 1833, loss 0.0871811, acc 0.984375\n",
      "2020-04-29T11:43:36.406921: step 1834, loss 0.145182, acc 0.921875\n",
      "2020-04-29T11:43:36.565175: step 1835, loss 0.095164, acc 0.96875\n",
      "2020-04-29T11:43:36.737038: step 1836, loss 0.0883035, acc 0.96875\n",
      "2020-04-29T11:43:36.914654: step 1837, loss 0.116251, acc 0.953125\n",
      "2020-04-29T11:43:37.088607: step 1838, loss 0.0719716, acc 0.96875\n",
      "2020-04-29T11:43:37.264368: step 1839, loss 0.183256, acc 0.921875\n",
      "2020-04-29T11:43:37.436469: step 1840, loss 0.112905, acc 0.953125\n",
      "2020-04-29T11:43:37.592709: step 1841, loss 0.0861341, acc 0.96875\n",
      "2020-04-29T11:43:37.770094: step 1842, loss 0.0835158, acc 0.984375\n",
      "2020-04-29T11:43:37.926333: step 1843, loss 0.0620036, acc 1\n",
      "2020-04-29T11:43:38.110397: step 1844, loss 0.0961779, acc 0.953125\n",
      "2020-04-29T11:43:38.276873: step 1845, loss 0.112054, acc 0.96875\n",
      "2020-04-29T11:43:38.449714: step 1846, loss 0.0402206, acc 1\n",
      "2020-04-29T11:43:38.605952: step 1847, loss 0.0995706, acc 0.953125\n",
      "2020-04-29T11:43:38.785657: step 1848, loss 0.0907457, acc 0.96875\n",
      "2020-04-29T11:43:38.941898: step 1849, loss 0.155535, acc 0.90625\n",
      "2020-04-29T11:43:39.126874: step 1850, loss 0.096907, acc 0.953125\n",
      "2020-04-29T11:43:39.298738: step 1851, loss 0.0591314, acc 0.984375\n",
      "2020-04-29T11:43:39.467182: step 1852, loss 0.0918574, acc 0.96875\n",
      "2020-04-29T11:43:39.623420: step 1853, loss 0.0662778, acc 0.96875\n",
      "2020-04-29T11:43:39.808150: step 1854, loss 0.0734916, acc 0.984375\n",
      "2020-04-29T11:43:39.981942: step 1855, loss 0.0620606, acc 0.984375\n",
      "2020-04-29T11:43:40.158839: step 1856, loss 0.0991392, acc 0.953125\n",
      "2020-04-29T11:43:40.321098: step 1857, loss 0.132038, acc 0.984375\n",
      "2020-04-29T11:43:40.489374: step 1858, loss 0.09137, acc 0.96875\n",
      "2020-04-29T11:43:40.645612: step 1859, loss 0.0633953, acc 0.984375\n",
      "2020-04-29T11:43:40.819190: step 1860, loss 0.127241, acc 0.96875\n",
      "2020-04-29T11:43:40.990419: step 1861, loss 0.0546799, acc 0.984375\n",
      "2020-04-29T11:43:41.154227: step 1862, loss 0.0686732, acc 0.984375\n",
      "2020-04-29T11:43:41.326090: step 1863, loss 0.0503424, acc 0.984375\n",
      "2020-04-29T11:43:41.502978: step 1864, loss 0.0649477, acc 0.96875\n",
      "2020-04-29T11:43:41.659216: step 1865, loss 0.0701904, acc 1\n",
      "2020-04-29T11:43:41.836702: step 1866, loss 0.0931125, acc 0.96875\n",
      "2020-04-29T11:43:42.011265: step 1867, loss 0.0664657, acc 0.96875\n",
      "2020-04-29T11:43:42.170385: step 1868, loss 0.0768132, acc 0.96875\n",
      "2020-04-29T11:43:42.338569: step 1869, loss 0.0449084, acc 1\n",
      "2020-04-29T11:43:42.510431: step 1870, loss 0.0923349, acc 0.96875\n",
      "2020-04-29T11:43:42.687408: step 1871, loss 0.211273, acc 0.9375\n",
      "2020-04-29T11:43:42.843646: step 1872, loss 0.0874862, acc 0.96875\n",
      "2020-04-29T11:43:43.021129: step 1873, loss 0.162895, acc 0.9375\n",
      "2020-04-29T11:43:43.177369: step 1874, loss 0.0880398, acc 0.953125\n",
      "2020-04-29T11:43:43.356903: step 1875, loss 0.0621828, acc 0.984375\n",
      "2020-04-29T11:43:43.513142: step 1876, loss 0.113862, acc 0.96875\n",
      "2020-04-29T11:43:43.694983: step 1877, loss 0.120539, acc 0.96875\n",
      "2020-04-29T11:43:43.851222: step 1878, loss 0.208367, acc 0.9375\n",
      "2020-04-29T11:43:44.032080: step 1879, loss 0.0716471, acc 0.953125\n",
      "2020-04-29T11:43:44.205925: step 1880, loss 0.0422748, acc 1\n",
      "2020-04-29T11:43:44.379583: step 1881, loss 0.0450086, acc 0.984375\n",
      "2020-04-29T11:43:44.551446: step 1882, loss 0.188245, acc 0.90625\n",
      "2020-04-29T11:43:44.722923: step 1883, loss 0.141197, acc 0.921875\n",
      "2020-04-29T11:43:44.894786: step 1884, loss 0.162521, acc 0.9375\n",
      "2020-04-29T11:43:45.074750: step 1885, loss 0.142769, acc 0.953125\n",
      "2020-04-29T11:43:45.230987: step 1886, loss 0.0735404, acc 0.984375\n",
      "2020-04-29T11:43:45.410814: step 1887, loss 0.0570629, acc 0.96875\n",
      "2020-04-29T11:43:45.567053: step 1888, loss 0.0501858, acc 1\n",
      "2020-04-29T11:43:45.757694: step 1889, loss 0.159293, acc 0.96875\n",
      "2020-04-29T11:43:45.913933: step 1890, loss 0.0890597, acc 0.953125\n",
      "2020-04-29T11:43:46.090829: step 1891, loss 0.0918942, acc 0.984375\n",
      "2020-04-29T11:43:46.262693: step 1892, loss 0.0903485, acc 0.953125\n",
      "2020-04-29T11:43:46.431818: step 1893, loss 0.0866756, acc 0.9375\n",
      "2020-04-29T11:43:46.603680: step 1894, loss 0.11265, acc 0.953125\n",
      "2020-04-29T11:43:46.764217: step 1895, loss 0.086404, acc 0.96875\n",
      "2020-04-29T11:43:46.936080: step 1896, loss 0.207564, acc 0.921875\n",
      "2020-04-29T11:43:47.111071: step 1897, loss 0.154056, acc 0.953125\n",
      "2020-04-29T11:43:47.282934: step 1898, loss 0.122049, acc 0.953125\n",
      "2020-04-29T11:43:47.444198: step 1899, loss 0.0871047, acc 0.984375\n",
      "2020-04-29T11:43:47.616061: step 1900, loss 0.0607579, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2020-04-29T11:43:47.871369: step 1900, loss 0.692572, acc 0.734522\n",
      "\n",
      "Saved model checkpoint to E:\\Project\\伯禹自然语言处理\\03基于卷积神经网络的文本分类\\runs\\1588131485\\checkpoints\\model-1900\n",
      "\n",
      "2020-04-29T11:43:48.554158: step 1901, loss 0.040275, acc 0.984375\n",
      "2020-04-29T11:43:48.713626: step 1902, loss 0.0930502, acc 0.953125\n",
      "2020-04-29T11:43:48.885491: step 1903, loss 0.207954, acc 0.921875\n",
      "2020-04-29T11:43:49.063089: step 1904, loss 0.0615001, acc 0.984375\n",
      "2020-04-29T11:43:49.219326: step 1905, loss 0.0783027, acc 1\n",
      "2020-04-29T11:43:49.382681: step 1906, loss 0.176138, acc 0.953125\n",
      "2020-04-29T11:43:49.554543: step 1907, loss 0.144304, acc 0.953125\n",
      "2020-04-29T11:43:49.731734: step 1908, loss 0.109236, acc 0.953125\n",
      "2020-04-29T11:43:49.903596: step 1909, loss 0.127831, acc 0.96875\n",
      "2020-04-29T11:43:50.066652: step 1910, loss 0.0686801, acc 0.984375\n",
      "2020-04-29T11:43:50.238515: step 1911, loss 0.059761, acc 0.953125\n",
      "2020-04-29T11:43:50.419905: step 1912, loss 0.0536674, acc 0.96875\n",
      "2020-04-29T11:43:50.591768: step 1913, loss 0.0719391, acc 0.984375\n",
      "2020-04-29T11:43:50.763310: step 1914, loss 0.0941642, acc 0.921875\n",
      "2020-04-29T11:43:50.919549: step 1915, loss 0.0590205, acc 1\n",
      "2020-04-29T11:43:51.104970: step 1916, loss 0.0952305, acc 0.953125\n",
      "2020-04-29T11:43:51.261209: step 1917, loss 0.151266, acc 0.9375\n",
      "2020-04-29T11:43:51.431658: step 1918, loss 0.023975, acc 1\n",
      "2020-04-29T11:43:51.603519: step 1919, loss 0.101104, acc 0.953125\n",
      "2020-04-29T11:43:51.780666: step 1920, loss 0.0721948, acc 0.984375\n",
      "2020-04-29T11:43:51.936903: step 1921, loss 0.0385578, acc 1\n",
      "2020-04-29T11:43:52.122587: step 1922, loss 0.0950813, acc 0.96875\n",
      "2020-04-29T11:43:52.278826: step 1923, loss 0.0637095, acc 1\n",
      "2020-04-29T11:43:52.451616: step 1924, loss 0.0828165, acc 0.96875\n",
      "2020-04-29T11:43:52.623479: step 1925, loss 0.111351, acc 0.953125\n",
      "2020-04-29T11:43:52.799239: step 1926, loss 0.105235, acc 0.953125\n",
      "2020-04-29T11:43:52.973922: step 1927, loss 0.163533, acc 0.921875\n",
      "2020-04-29T11:43:53.150820: step 1928, loss 0.081978, acc 0.953125\n",
      "2020-04-29T11:43:53.302849: step 1929, loss 0.0632353, acc 0.984375\n",
      "2020-04-29T11:43:53.485299: step 1930, loss 0.125468, acc 0.96875\n",
      "2020-04-29T11:43:53.657161: step 1931, loss 0.0885562, acc 0.953125\n",
      "2020-04-29T11:43:53.835201: step 1932, loss 0.0824865, acc 0.96875\n",
      "2020-04-29T11:43:54.006706: step 1933, loss 0.100589, acc 0.96875\n",
      "2020-04-29T11:43:54.194597: step 1934, loss 0.0678512, acc 0.953125\n",
      "2020-04-29T11:43:54.351833: step 1935, loss 0.0773593, acc 0.96875\n",
      "2020-04-29T11:43:54.534036: step 1936, loss 0.0935444, acc 0.96875\n",
      "2020-04-29T11:43:54.705898: step 1937, loss 0.0663579, acc 0.953125\n",
      "2020-04-29T11:43:54.884695: step 1938, loss 0.0839569, acc 0.96875\n",
      "2020-04-29T11:43:55.056558: step 1939, loss 0.0782859, acc 0.96875\n",
      "2020-04-29T11:43:55.234837: step 1940, loss 0.0587697, acc 0.984375\n",
      "2020-04-29T11:43:55.391076: step 1941, loss 0.085208, acc 0.96875\n",
      "2020-04-29T11:43:55.570922: step 1942, loss 0.128038, acc 0.9375\n",
      "2020-04-29T11:43:55.727161: step 1943, loss 0.154526, acc 0.953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-29T11:43:55.905459: step 1944, loss 0.117891, acc 0.96875\n",
      "2020-04-29T11:43:56.077324: step 1945, loss 0.144808, acc 0.921875\n",
      "2020-04-29T11:43:56.237519: step 1946, loss 0.213489, acc 0.9375\n",
      "2020-04-29T11:43:56.409381: step 1947, loss 0.0765585, acc 0.984375\n",
      "2020-04-29T11:43:56.586667: step 1948, loss 0.0610182, acc 0.96875\n",
      "2020-04-29T11:43:56.758528: step 1949, loss 0.121488, acc 0.96875\n",
      "2020-04-29T11:43:56.925968: step 1950, loss 0.146656, acc 0.916667\n",
      "2020-04-29T11:43:57.105336: step 1951, loss 0.104415, acc 0.96875\n",
      "2020-04-29T11:43:57.269326: step 1952, loss 0.0752396, acc 0.96875\n",
      "2020-04-29T11:43:57.454200: step 1953, loss 0.0841416, acc 0.96875\n",
      "2020-04-29T11:43:57.610438: step 1954, loss 0.0589986, acc 0.96875\n",
      "2020-04-29T11:43:57.787627: step 1955, loss 0.0283533, acc 1\n",
      "2020-04-29T11:43:57.959490: step 1956, loss 0.0487189, acc 0.984375\n",
      "2020-04-29T11:43:58.137052: step 1957, loss 0.0685343, acc 0.96875\n",
      "2020-04-29T11:43:58.296491: step 1958, loss 0.0431954, acc 0.984375\n",
      "2020-04-29T11:43:58.460474: step 1959, loss 0.0407065, acc 0.984375\n",
      "2020-04-29T11:43:58.632336: step 1960, loss 0.087545, acc 0.96875\n",
      "2020-04-29T11:43:58.806238: step 1961, loss 0.0664716, acc 0.96875\n",
      "2020-04-29T11:43:58.977952: step 1962, loss 0.029988, acc 1\n",
      "2020-04-29T11:43:59.150855: step 1963, loss 0.0715602, acc 0.96875\n",
      "2020-04-29T11:43:59.307353: step 1964, loss 0.0284365, acc 1\n",
      "2020-04-29T11:43:59.479215: step 1965, loss 0.0654809, acc 0.984375\n",
      "2020-04-29T11:43:59.656385: step 1966, loss 0.0765673, acc 0.96875\n",
      "2020-04-29T11:43:59.828249: step 1967, loss 0.0714646, acc 0.953125\n",
      "2020-04-29T11:43:59.997943: step 1968, loss 0.0650544, acc 0.953125\n",
      "2020-04-29T11:44:00.174841: step 1969, loss 0.0483643, acc 0.96875\n",
      "2020-04-29T11:44:00.339791: step 1970, loss 0.0823623, acc 0.984375\n",
      "2020-04-29T11:44:00.496029: step 1971, loss 0.154856, acc 0.921875\n",
      "2020-04-29T11:44:00.674946: step 1972, loss 0.0297329, acc 1\n",
      "2020-04-29T11:44:00.846808: step 1973, loss 0.11485, acc 0.953125\n",
      "2020-04-29T11:44:01.015095: step 1974, loss 0.0714398, acc 0.984375\n",
      "2020-04-29T11:44:01.171334: step 1975, loss 0.0948544, acc 0.984375\n",
      "2020-04-29T11:44:01.359231: step 1976, loss 0.0730462, acc 0.984375\n",
      "2020-04-29T11:44:01.515468: step 1977, loss 0.0603827, acc 0.96875\n",
      "2020-04-29T11:44:01.691515: step 1978, loss 0.175434, acc 0.953125\n",
      "2020-04-29T11:44:01.863379: step 1979, loss 0.128795, acc 0.96875\n",
      "2020-04-29T11:44:02.020535: step 1980, loss 0.0782409, acc 0.96875\n",
      "2020-04-29T11:44:02.192397: step 1981, loss 0.15763, acc 0.953125\n",
      "2020-04-29T11:44:02.359270: step 1982, loss 0.0563911, acc 0.984375\n",
      "2020-04-29T11:44:02.531132: step 1983, loss 0.0394939, acc 1\n",
      "2020-04-29T11:44:02.709848: step 1984, loss 0.076667, acc 0.984375\n",
      "2020-04-29T11:44:02.881710: step 1985, loss 0.0312096, acc 1\n",
      "2020-04-29T11:44:03.054893: step 1986, loss 0.0422673, acc 1\n",
      "2020-04-29T11:44:03.226757: step 1987, loss 0.0523588, acc 0.984375\n",
      "2020-04-29T11:44:03.401535: step 1988, loss 0.0333709, acc 1\n",
      "2020-04-29T11:44:03.557774: step 1989, loss 0.0464808, acc 0.984375\n",
      "2020-04-29T11:44:03.728846: step 1990, loss 0.128024, acc 0.953125\n",
      "2020-04-29T11:44:03.900709: step 1991, loss 0.0452867, acc 1\n",
      "2020-04-29T11:44:04.079001: step 1992, loss 0.0639885, acc 0.984375\n",
      "2020-04-29T11:44:04.250864: step 1993, loss 0.122696, acc 0.953125\n",
      "2020-04-29T11:44:04.427106: step 1994, loss 0.0890779, acc 0.96875\n",
      "2020-04-29T11:44:04.598968: step 1995, loss 0.0676977, acc 1\n",
      "2020-04-29T11:44:04.778804: step 1996, loss 0.0586591, acc 0.96875\n",
      "2020-04-29T11:44:04.935042: step 1997, loss 0.037413, acc 0.984375\n",
      "2020-04-29T11:44:05.114162: step 1998, loss 0.0575916, acc 0.984375\n",
      "2020-04-29T11:44:05.286024: step 1999, loss 0.0546703, acc 0.984375\n",
      "2020-04-29T11:44:05.447257: step 2000, loss 0.168039, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2020-04-29T11:44:05.700367: step 2000, loss 0.748773, acc 0.730769\n",
      "\n",
      "Saved model checkpoint to E:\\Project\\伯禹自然语言处理\\03基于卷积神经网络的文本分类\\runs\\1588131485\\checkpoints\\model-2000\n",
      "\n",
      "2020-04-29T11:44:06.360132: step 2001, loss 0.0401895, acc 1\n",
      "2020-04-29T11:44:06.533673: step 2002, loss 0.113859, acc 0.953125\n",
      "2020-04-29T11:44:06.705534: step 2003, loss 0.0526274, acc 0.96875\n",
      "2020-04-29T11:44:06.866380: step 2004, loss 0.0788508, acc 0.96875\n",
      "2020-04-29T11:44:07.046618: step 2005, loss 0.0625656, acc 0.984375\n",
      "2020-04-29T11:44:07.226515: step 2006, loss 0.0596823, acc 0.984375\n",
      "2020-04-29T11:44:07.382250: step 2007, loss 0.100177, acc 0.953125\n",
      "2020-04-29T11:44:07.554113: step 2008, loss 0.0660557, acc 0.96875\n",
      "2020-04-29T11:44:07.737019: step 2009, loss 0.07121, acc 0.984375\n",
      "2020-04-29T11:44:07.893258: step 2010, loss 0.0652308, acc 0.96875\n",
      "2020-04-29T11:44:08.149814: step 2011, loss 0.0152018, acc 1\n",
      "2020-04-29T11:44:08.305425: step 2012, loss 0.165172, acc 0.9375\n",
      "2020-04-29T11:44:08.485010: step 2013, loss 0.0564362, acc 0.96875\n",
      "2020-04-29T11:44:08.641249: step 2014, loss 0.0927736, acc 0.96875\n",
      "2020-04-29T11:44:08.822452: step 2015, loss 0.0775835, acc 0.984375\n",
      "2020-04-29T11:44:08.990803: step 2016, loss 0.0604129, acc 0.984375\n",
      "2020-04-29T11:44:09.152459: step 2017, loss 0.0942849, acc 0.96875\n",
      "2020-04-29T11:44:09.324323: step 2018, loss 0.0664155, acc 0.984375\n",
      "2020-04-29T11:44:09.500514: step 2019, loss 0.0365586, acc 1\n",
      "2020-04-29T11:44:09.656751: step 2020, loss 0.0581824, acc 0.96875\n",
      "2020-04-29T11:44:09.824343: step 2021, loss 0.0398179, acc 1\n",
      "2020-04-29T11:44:10.004453: step 2022, loss 0.0367804, acc 0.984375\n",
      "2020-04-29T11:44:10.170559: step 2023, loss 0.0553191, acc 0.96875\n",
      "2020-04-29T11:44:10.326799: step 2024, loss 0.0960424, acc 0.953125\n",
      "2020-04-29T11:44:10.503488: step 2025, loss 0.0739342, acc 0.984375\n",
      "2020-04-29T11:44:10.675352: step 2026, loss 0.0786286, acc 0.953125\n",
      "2020-04-29T11:44:10.852710: step 2027, loss 0.0329254, acc 1\n",
      "2020-04-29T11:44:11.019207: step 2028, loss 0.0722831, acc 0.96875\n",
      "2020-04-29T11:44:11.185489: step 2029, loss 0.158473, acc 0.953125\n",
      "2020-04-29T11:44:11.341729: step 2030, loss 0.0745059, acc 0.96875\n",
      "2020-04-29T11:44:11.525775: step 2031, loss 0.0511189, acc 0.984375\n",
      "2020-04-29T11:44:11.697638: step 2032, loss 0.0932269, acc 0.984375\n",
      "2020-04-29T11:44:11.871581: step 2033, loss 0.0594382, acc 0.984375\n",
      "2020-04-29T11:44:12.027820: step 2034, loss 0.0867375, acc 0.9375\n",
      "2020-04-29T11:44:12.210311: step 2035, loss 0.108944, acc 0.96875\n",
      "2020-04-29T11:44:12.366550: step 2036, loss 0.0942485, acc 0.9375\n",
      "2020-04-29T11:44:12.538367: step 2037, loss 0.155649, acc 0.9375\n",
      "2020-04-29T11:44:12.710230: step 2038, loss 0.0342137, acc 1\n",
      "2020-04-29T11:44:12.887265: step 2039, loss 0.0497745, acc 0.984375\n",
      "2020-04-29T11:44:13.043506: step 2040, loss 0.0296336, acc 1\n",
      "2020-04-29T11:44:13.224383: step 2041, loss 0.11539, acc 0.9375\n",
      "2020-04-29T11:44:13.396247: step 2042, loss 0.0799783, acc 0.96875\n",
      "2020-04-29T11:44:13.571036: step 2043, loss 0.0620477, acc 0.96875\n",
      "2020-04-29T11:44:13.727275: step 2044, loss 0.0398013, acc 0.984375\n",
      "2020-04-29T11:44:13.909238: step 2045, loss 0.0615018, acc 0.96875\n",
      "2020-04-29T11:44:14.081996: step 2046, loss 0.0977217, acc 0.953125\n",
      "2020-04-29T11:44:14.255594: step 2047, loss 0.08437, acc 0.984375\n",
      "2020-04-29T11:44:14.427456: step 2048, loss 0.0553183, acc 0.96875\n",
      "2020-04-29T11:44:14.606902: step 2049, loss 0.0711397, acc 0.96875\n",
      "2020-04-29T11:44:14.763142: step 2050, loss 0.157572, acc 0.921875\n",
      "2020-04-29T11:44:14.946699: step 2051, loss 0.0620366, acc 0.984375\n",
      "2020-04-29T11:44:15.102938: step 2052, loss 0.0424964, acc 1\n",
      "2020-04-29T11:44:15.290090: step 2053, loss 0.0682688, acc 0.96875\n",
      "2020-04-29T11:44:15.446330: step 2054, loss 0.0710573, acc 0.96875\n",
      "2020-04-29T11:44:15.631916: step 2055, loss 0.185263, acc 0.921875\n",
      "2020-04-29T11:44:15.788156: step 2056, loss 0.105949, acc 0.96875\n",
      "2020-04-29T11:44:15.978078: step 2057, loss 0.03189, acc 1\n",
      "2020-04-29T11:44:16.125900: step 2058, loss 0.0765559, acc 0.96875\n",
      "2020-04-29T11:44:16.309291: step 2059, loss 0.0577106, acc 0.984375\n",
      "2020-04-29T11:44:16.465530: step 2060, loss 0.0241618, acc 1\n",
      "2020-04-29T11:44:16.643614: step 2061, loss 0.0632226, acc 0.984375\n",
      "2020-04-29T11:44:16.815477: step 2062, loss 0.133234, acc 0.953125\n",
      "2020-04-29T11:44:16.996352: step 2063, loss 0.0585569, acc 0.984375\n",
      "2020-04-29T11:44:17.160301: step 2064, loss 0.0499351, acc 1\n",
      "2020-04-29T11:44:17.333774: step 2065, loss 0.053306, acc 0.984375\n",
      "2020-04-29T11:44:17.505637: step 2066, loss 0.0333423, acc 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-29T11:44:17.662430: step 2067, loss 0.0317524, acc 1\n",
      "2020-04-29T11:44:17.834292: step 2068, loss 0.0836406, acc 0.953125\n",
      "2020-04-29T11:44:18.019169: step 2069, loss 0.220013, acc 0.921875\n",
      "2020-04-29T11:44:18.169702: step 2070, loss 0.119444, acc 0.9375\n",
      "2020-04-29T11:44:18.351616: step 2071, loss 0.177953, acc 0.9375\n",
      "2020-04-29T11:44:18.507855: step 2072, loss 0.0961869, acc 0.953125\n",
      "2020-04-29T11:44:18.687798: step 2073, loss 0.1661, acc 0.953125\n",
      "2020-04-29T11:44:18.844037: step 2074, loss 0.0944858, acc 0.9375\n",
      "2020-04-29T11:44:19.015046: step 2075, loss 0.0177858, acc 1\n",
      "2020-04-29T11:44:19.186908: step 2076, loss 0.103761, acc 0.9375\n",
      "2020-04-29T11:44:19.361434: step 2077, loss 0.0840494, acc 0.96875\n",
      "2020-04-29T11:44:19.517673: step 2078, loss 0.068574, acc 0.96875\n",
      "2020-04-29T11:44:19.695150: step 2079, loss 0.141062, acc 0.953125\n",
      "2020-04-29T11:44:19.867014: step 2080, loss 0.130639, acc 0.9375\n",
      "2020-04-29T11:44:20.049676: step 2081, loss 0.0362558, acc 1\n",
      "2020-04-29T11:44:20.205291: step 2082, loss 0.0815412, acc 0.96875\n",
      "2020-04-29T11:44:20.382048: step 2083, loss 0.0945459, acc 0.9375\n",
      "2020-04-29T11:44:20.538286: step 2084, loss 0.0805122, acc 0.96875\n",
      "2020-04-29T11:44:20.713571: step 2085, loss 0.0973444, acc 0.953125\n",
      "2020-04-29T11:44:20.885434: step 2086, loss 0.129709, acc 0.953125\n",
      "2020-04-29T11:44:21.058027: step 2087, loss 0.0792016, acc 0.96875\n",
      "2020-04-29T11:44:21.223929: step 2088, loss 0.121718, acc 0.96875\n",
      "2020-04-29T11:44:21.384003: step 2089, loss 0.039203, acc 1\n",
      "2020-04-29T11:44:21.555866: step 2090, loss 0.0986031, acc 0.96875\n",
      "2020-04-29T11:44:21.717236: step 2091, loss 0.0556894, acc 1\n",
      "2020-04-29T11:44:21.889100: step 2092, loss 0.060202, acc 0.96875\n",
      "2020-04-29T11:44:22.064346: step 2093, loss 0.091678, acc 0.96875\n",
      "2020-04-29T11:44:22.220585: step 2094, loss 0.165006, acc 0.953125\n",
      "2020-04-29T11:44:22.398630: step 2095, loss 0.0757161, acc 0.984375\n",
      "2020-04-29T11:44:22.554869: step 2096, loss 0.113684, acc 0.9375\n",
      "2020-04-29T11:44:22.732190: step 2097, loss 0.0868259, acc 0.96875\n",
      "2020-04-29T11:44:22.904053: step 2098, loss 0.106563, acc 0.96875\n",
      "2020-04-29T11:44:23.067286: step 2099, loss 0.137789, acc 0.9375\n",
      "2020-04-29T11:44:23.239149: step 2100, loss 0.0802444, acc 0.966667\n",
      "\n",
      "Evaluation:\n",
      "2020-04-29T11:44:23.478583: step 2100, loss 0.764888, acc 0.738274\n",
      "\n",
      "Saved model checkpoint to E:\\Project\\伯禹自然语言处理\\03基于卷积神经网络的文本分类\\runs\\1588131485\\checkpoints\\model-2100\n",
      "\n",
      "2020-04-29T11:44:24.165670: step 2101, loss 0.0878981, acc 0.984375\n",
      "2020-04-29T11:44:24.350795: step 2102, loss 0.0772384, acc 0.984375\n",
      "2020-04-29T11:44:24.522658: step 2103, loss 0.0287799, acc 1\n",
      "2020-04-29T11:44:24.685070: step 2104, loss 0.0301858, acc 1\n",
      "2020-04-29T11:44:24.856933: step 2105, loss 0.059166, acc 0.984375\n",
      "2020-04-29T11:44:25.044919: step 2106, loss 0.0574882, acc 0.984375\n",
      "2020-04-29T11:44:25.210058: step 2107, loss 0.0791184, acc 0.96875\n",
      "2020-04-29T11:44:25.386826: step 2108, loss 0.0777327, acc 0.96875\n",
      "2020-04-29T11:44:25.558689: step 2109, loss 0.0250517, acc 0.984375\n",
      "2020-04-29T11:44:25.735444: step 2110, loss 0.0543164, acc 0.984375\n",
      "2020-04-29T11:44:25.907306: step 2111, loss 0.0368024, acc 0.984375\n",
      "2020-04-29T11:44:26.069821: step 2112, loss 0.071082, acc 0.953125\n",
      "2020-04-29T11:44:26.241683: step 2113, loss 0.0429616, acc 1\n",
      "2020-04-29T11:44:26.418460: step 2114, loss 0.0581707, acc 0.96875\n",
      "2020-04-29T11:44:26.590322: step 2115, loss 0.0871481, acc 0.96875\n",
      "2020-04-29T11:44:26.769380: step 2116, loss 0.121625, acc 0.96875\n",
      "2020-04-29T11:44:26.925620: step 2117, loss 0.0247022, acc 0.984375\n",
      "2020-04-29T11:44:27.104132: step 2118, loss 0.01248, acc 1\n",
      "2020-04-29T11:44:27.260370: step 2119, loss 0.0838819, acc 0.953125\n",
      "2020-04-29T11:44:27.442634: step 2120, loss 0.0456786, acc 1\n",
      "2020-04-29T11:44:27.598873: step 2121, loss 0.0563589, acc 0.984375\n",
      "2020-04-29T11:44:27.776037: step 2122, loss 0.0649966, acc 0.96875\n",
      "2020-04-29T11:44:27.947899: step 2123, loss 0.0341424, acc 0.984375\n",
      "2020-04-29T11:44:28.132172: step 2124, loss 0.0650743, acc 0.96875\n",
      "2020-04-29T11:44:28.288752: step 2125, loss 0.0339143, acc 0.984375\n",
      "2020-04-29T11:44:28.471393: step 2126, loss 0.0107128, acc 1\n",
      "2020-04-29T11:44:28.627631: step 2127, loss 0.0591654, acc 0.984375\n",
      "2020-04-29T11:44:28.811002: step 2128, loss 0.0696812, acc 0.984375\n",
      "2020-04-29T11:44:28.969832: step 2129, loss 0.139307, acc 0.96875\n",
      "2020-04-29T11:44:29.155143: step 2130, loss 0.0713206, acc 0.984375\n",
      "2020-04-29T11:44:29.311382: step 2131, loss 0.0786002, acc 0.953125\n",
      "2020-04-29T11:44:29.489663: step 2132, loss 0.0714088, acc 0.984375\n",
      "2020-04-29T11:44:29.661545: step 2133, loss 0.0442213, acc 0.984375\n",
      "2020-04-29T11:44:29.824545: step 2134, loss 0.115913, acc 0.984375\n",
      "2020-04-29T11:44:29.989954: step 2135, loss 0.0705682, acc 0.96875\n",
      "2020-04-29T11:44:30.173455: step 2136, loss 0.102851, acc 0.96875\n",
      "2020-04-29T11:44:30.329694: step 2137, loss 0.10373, acc 0.953125\n",
      "2020-04-29T11:44:30.506494: step 2138, loss 0.0274556, acc 1\n",
      "2020-04-29T11:44:30.662733: step 2139, loss 0.0777802, acc 0.96875\n",
      "2020-04-29T11:44:30.840324: step 2140, loss 0.0604739, acc 0.984375\n",
      "2020-04-29T11:44:31.001283: step 2141, loss 0.0325029, acc 0.984375\n",
      "2020-04-29T11:44:31.175630: step 2142, loss 0.127598, acc 0.9375\n",
      "2020-04-29T11:44:31.347492: step 2143, loss 0.0643132, acc 0.984375\n",
      "2020-04-29T11:44:31.508896: step 2144, loss 0.0447432, acc 1\n",
      "2020-04-29T11:44:31.680761: step 2145, loss 0.0264972, acc 1\n",
      "2020-04-29T11:44:31.858404: step 2146, loss 0.0418791, acc 0.984375\n",
      "2020-04-29T11:44:32.030271: step 2147, loss 0.122776, acc 0.9375\n",
      "2020-04-29T11:44:32.200441: step 2148, loss 0.0535858, acc 0.984375\n",
      "2020-04-29T11:44:32.356680: step 2149, loss 0.0628656, acc 0.984375\n",
      "2020-04-29T11:44:32.528837: step 2150, loss 0.0118073, acc 1\n",
      "2020-04-29T11:44:32.700700: step 2151, loss 0.0799024, acc 0.984375\n",
      "2020-04-29T11:44:32.877016: step 2152, loss 0.0433838, acc 0.984375\n",
      "2020-04-29T11:44:33.045998: step 2153, loss 0.0279298, acc 1\n",
      "2020-04-29T11:44:33.215671: step 2154, loss 0.0552995, acc 0.984375\n",
      "2020-04-29T11:44:33.371910: step 2155, loss 0.0627471, acc 0.984375\n",
      "2020-04-29T11:44:33.544346: step 2156, loss 0.0629279, acc 0.96875\n",
      "2020-04-29T11:44:33.716208: step 2157, loss 0.0391311, acc 1\n",
      "2020-04-29T11:44:33.894367: step 2158, loss 0.0205307, acc 1\n",
      "2020-04-29T11:44:34.050604: step 2159, loss 0.161078, acc 0.9375\n",
      "2020-04-29T11:44:34.230940: step 2160, loss 0.0371582, acc 1\n",
      "2020-04-29T11:44:34.402803: step 2161, loss 0.0829527, acc 0.96875\n",
      "2020-04-29T11:44:34.593677: step 2162, loss 0.0249851, acc 1\n",
      "2020-04-29T11:44:34.749915: step 2163, loss 0.146692, acc 0.953125\n",
      "2020-04-29T11:44:34.934273: step 2164, loss 0.0105089, acc 1\n",
      "2020-04-29T11:44:35.090511: step 2165, loss 0.0801701, acc 0.953125\n",
      "2020-04-29T11:44:35.280908: step 2166, loss 0.0455888, acc 0.984375\n",
      "2020-04-29T11:44:35.437146: step 2167, loss 0.0639583, acc 0.953125\n",
      "2020-04-29T11:44:35.613817: step 2168, loss 0.0747596, acc 0.984375\n",
      "2020-04-29T11:44:35.785680: step 2169, loss 0.0421003, acc 0.984375\n",
      "2020-04-29T11:44:35.992769: step 2170, loss 0.0133482, acc 1\n",
      "2020-04-29T11:44:36.180662: step 2171, loss 0.045248, acc 0.984375\n",
      "2020-04-29T11:44:36.365483: step 2172, loss 0.044345, acc 0.984375\n",
      "2020-04-29T11:44:36.547147: step 2173, loss 0.0686091, acc 0.96875\n",
      "2020-04-29T11:44:36.703385: step 2174, loss 0.0519079, acc 0.984375\n",
      "2020-04-29T11:44:36.887195: step 2175, loss 0.076731, acc 0.984375\n",
      "2020-04-29T11:44:37.074683: step 2176, loss 0.0432078, acc 1\n",
      "2020-04-29T11:44:37.246669: step 2177, loss 0.0850953, acc 0.984375\n",
      "2020-04-29T11:44:37.418227: step 2178, loss 0.0463898, acc 0.984375\n",
      "2020-04-29T11:44:37.574465: step 2179, loss 0.0509373, acc 0.96875\n",
      "2020-04-29T11:44:37.780802: step 2180, loss 0.0556193, acc 0.96875\n",
      "2020-04-29T11:44:37.952663: step 2181, loss 0.109957, acc 0.953125\n",
      "2020-04-29T11:44:38.123848: step 2182, loss 0.0393096, acc 0.984375\n",
      "2020-04-29T11:44:38.311715: step 2183, loss 0.0450633, acc 1\n",
      "2020-04-29T11:44:38.489411: step 2184, loss 0.0345063, acc 1\n",
      "2020-04-29T11:44:38.665812: step 2185, loss 0.0239649, acc 1\n",
      "2020-04-29T11:44:38.822051: step 2186, loss 0.124106, acc 0.984375\n",
      "2020-04-29T11:44:39.001043: step 2187, loss 0.0326232, acc 1\n",
      "2020-04-29T11:44:39.172909: step 2188, loss 0.0458323, acc 0.984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-29T11:44:39.334233: step 2189, loss 0.0762358, acc 0.984375\n",
      "2020-04-29T11:44:39.506096: step 2190, loss 0.0876177, acc 0.96875\n",
      "2020-04-29T11:44:39.685950: step 2191, loss 0.0271109, acc 1\n",
      "2020-04-29T11:44:39.842188: step 2192, loss 0.0651362, acc 0.96875\n",
      "2020-04-29T11:44:40.026555: step 2193, loss 0.0206879, acc 1\n",
      "2020-04-29T11:44:40.187443: step 2194, loss 0.0317447, acc 0.984375\n",
      "2020-04-29T11:44:40.368364: step 2195, loss 0.0607828, acc 0.984375\n",
      "2020-04-29T11:44:40.524601: step 2196, loss 0.0434011, acc 0.984375\n",
      "2020-04-29T11:44:40.700969: step 2197, loss 0.0611354, acc 0.984375\n",
      "2020-04-29T11:44:40.857207: step 2198, loss 0.0328953, acc 0.984375\n",
      "2020-04-29T11:44:41.036484: step 2199, loss 0.160944, acc 0.90625\n",
      "2020-04-29T11:44:41.190468: step 2200, loss 0.0383334, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2020-04-29T11:44:41.431556: step 2200, loss 0.778073, acc 0.744841\n",
      "\n",
      "Saved model checkpoint to E:\\Project\\伯禹自然语言处理\\03基于卷积神经网络的文本分类\\runs\\1588131485\\checkpoints\\model-2200\n",
      "\n",
      "2020-04-29T11:44:42.081122: step 2201, loss 0.0354214, acc 0.984375\n",
      "2020-04-29T11:44:42.257162: step 2202, loss 0.154079, acc 0.953125\n",
      "2020-04-29T11:44:42.413401: step 2203, loss 0.0361756, acc 0.984375\n",
      "2020-04-29T11:44:42.588039: step 2204, loss 0.142308, acc 0.9375\n",
      "2020-04-29T11:44:42.759902: step 2205, loss 0.0403134, acc 1\n",
      "2020-04-29T11:44:42.936812: step 2206, loss 0.105575, acc 0.953125\n",
      "2020-04-29T11:44:43.103082: step 2207, loss 0.156076, acc 0.953125\n",
      "2020-04-29T11:44:43.273983: step 2208, loss 0.0369984, acc 0.984375\n",
      "2020-04-29T11:44:43.434240: step 2209, loss 0.065988, acc 0.984375\n",
      "2020-04-29T11:44:43.606127: step 2210, loss 0.0589273, acc 0.984375\n",
      "2020-04-29T11:44:43.777992: step 2211, loss 0.0496619, acc 1\n",
      "2020-04-29T11:44:43.939039: step 2212, loss 0.0848375, acc 0.984375\n",
      "2020-04-29T11:44:44.110901: step 2213, loss 0.0544531, acc 0.984375\n",
      "2020-04-29T11:44:44.288806: step 2214, loss 0.0810981, acc 0.96875\n",
      "2020-04-29T11:44:44.460670: step 2215, loss 0.0469956, acc 0.984375\n",
      "2020-04-29T11:44:44.639166: step 2216, loss 0.0838304, acc 0.96875\n",
      "2020-04-29T11:44:44.811029: step 2217, loss 0.0599356, acc 0.984375\n",
      "2020-04-29T11:44:44.985973: step 2218, loss 0.063451, acc 0.984375\n",
      "2020-04-29T11:44:45.135192: step 2219, loss 0.0743973, acc 0.96875\n",
      "2020-04-29T11:44:45.324912: step 2220, loss 0.0716577, acc 0.96875\n",
      "2020-04-29T11:44:45.496776: step 2221, loss 0.0730422, acc 1\n",
      "2020-04-29T11:44:45.658000: step 2222, loss 0.0464613, acc 0.984375\n",
      "2020-04-29T11:44:45.829862: step 2223, loss 0.0184197, acc 1\n",
      "2020-04-29T11:44:46.006374: step 2224, loss 0.0744964, acc 0.96875\n",
      "2020-04-29T11:44:46.173969: step 2225, loss 0.114385, acc 0.96875\n",
      "2020-04-29T11:44:46.345158: step 2226, loss 0.0295746, acc 0.984375\n",
      "2020-04-29T11:44:46.501397: step 2227, loss 0.0567684, acc 0.96875\n",
      "2020-04-29T11:44:46.683388: step 2228, loss 0.0258827, acc 1\n",
      "2020-04-29T11:44:46.839628: step 2229, loss 0.0718196, acc 0.984375\n",
      "2020-04-29T11:44:47.025515: step 2230, loss 0.150808, acc 0.96875\n",
      "2020-04-29T11:44:47.197378: step 2231, loss 0.049896, acc 0.96875\n",
      "2020-04-29T11:44:47.360675: step 2232, loss 0.0335277, acc 1\n",
      "2020-04-29T11:44:47.532537: step 2233, loss 0.0442961, acc 0.984375\n",
      "2020-04-29T11:44:47.709846: step 2234, loss 0.0303396, acc 1\n",
      "2020-04-29T11:44:47.866084: step 2235, loss 0.0439829, acc 0.984375\n",
      "2020-04-29T11:44:48.054803: step 2236, loss 0.0200929, acc 1\n",
      "2020-04-29T11:44:48.221141: step 2237, loss 0.0731763, acc 0.984375\n",
      "2020-04-29T11:44:48.400069: step 2238, loss 0.0793918, acc 0.984375\n",
      "2020-04-29T11:44:48.556308: step 2239, loss 0.050946, acc 0.984375\n",
      "2020-04-29T11:44:48.727737: step 2240, loss 0.0374695, acc 0.984375\n",
      "2020-04-29T11:44:48.899600: step 2241, loss 0.0612477, acc 0.984375\n",
      "2020-04-29T11:44:49.077207: step 2242, loss 0.0383022, acc 0.984375\n",
      "2020-04-29T11:44:49.233445: step 2243, loss 0.0514884, acc 0.96875\n",
      "2020-04-29T11:44:49.427224: step 2244, loss 0.122714, acc 0.96875\n",
      "2020-04-29T11:44:49.583460: step 2245, loss 0.149823, acc 0.953125\n",
      "2020-04-29T11:44:49.761574: step 2246, loss 0.0813985, acc 0.953125\n",
      "2020-04-29T11:44:49.933436: step 2247, loss 0.088064, acc 0.984375\n",
      "2020-04-29T11:44:50.110661: step 2248, loss 0.0581268, acc 0.984375\n",
      "2020-04-29T11:44:50.273566: step 2249, loss 0.0227655, acc 1\n",
      "2020-04-29T11:44:50.430812: step 2250, loss 0.0943255, acc 0.966667\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\tensorflow1.15-cpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from tensorflow.contrib import learn\n",
    "\n",
    "# Parameters\n",
    "# ==================================================\n",
    "\n",
    "# Data loading params\n",
    "tf.flags.DEFINE_float(\"dev_sample_percentage\", .1, \"Percentage of the training data to use for validation\")\n",
    "tf.flags.DEFINE_string(\"positive_data_file\", \"./input/rt-polarity.pos\", \"Data source for the positive data.\")\n",
    "tf.flags.DEFINE_string(\"negative_data_file\", \"./input/rt-polarity.neg\", \"Data source for the negative data.\")\n",
    "\n",
    "# Model Hyperparameters\n",
    "tf.flags.DEFINE_integer(\"embedding_dim\", 128, \"Dimensionality of character embedding (default: 128)\")\n",
    "tf.flags.DEFINE_string(\"filter_sizes\", \"3,4,5\", \"Comma-separated filter sizes (default: '3,4,5')\")\n",
    "tf.flags.DEFINE_integer(\"num_filters\", 128, \"Number of filters per filter size (default: 128)\")\n",
    "tf.flags.DEFINE_float(\"dropout_keep_prob\", 0.5, \"Dropout keep probability (default: 0.5)\")\n",
    "tf.flags.DEFINE_float(\"l2_reg_lambda\", 0.0, \"L2 regularization lambda (default: 0.0)\")\n",
    "\n",
    "# Training parameters\n",
    "tf.flags.DEFINE_integer(\"batch_size\", 64, \"Batch Size (default: 64)\")\n",
    "tf.flags.DEFINE_integer(\"num_epochs\", 15, \"Number of training epochs (default: 20)\")\n",
    "tf.flags.DEFINE_integer(\"evaluate_every\", 100, \"Evaluate model on dev set after this many steps (default: 100)\")\n",
    "tf.flags.DEFINE_integer(\"checkpoint_every\", 100, \"Save model after this many steps (default: 100)\")\n",
    "tf.flags.DEFINE_integer(\"num_checkpoints\", 5, \"Number of checkpoints to store (default: 5)\")\n",
    "# Misc Parameters\n",
    "tf.flags.DEFINE_boolean(\"allow_soft_placement\", True, \"Allow device soft device placement\")\n",
    "tf.flags.DEFINE_boolean(\"log_device_placement\", False, \"Log placement of ops on devices\")\n",
    "\n",
    "FLAGS = tf.flags.FLAGS\n",
    "# FLAGS._parse_flags()\n",
    "# print(\"\\nParameters:\")\n",
    "# for attr, value in sorted(FLAGS.__flags.items()):\n",
    "#     print(\"{}={}\".format(attr.upper(), value))\n",
    "# print(\"\")\n",
    "\n",
    "timestamp = str(int(time.time()))\n",
    "\n",
    "def preprocess():\n",
    "    # Data Preparation\n",
    "    # ==================================================\n",
    "\n",
    "    # Load data\n",
    "    print(\"Loading data...\")\n",
    "    x_text, y = load_data_and_labels(FLAGS.positive_data_file, FLAGS.negative_data_file)\n",
    "\n",
    "    # Build vocabulary\n",
    "    max_document_length = max([len(x.split(\" \")) for x in x_text])\n",
    "    vocab_processor = learn.preprocessing.VocabularyProcessor(max_document_length)\n",
    "    x = np.array(list(vocab_processor.fit_transform(x_text)))\n",
    "\n",
    "    # Randomly shuffle data\n",
    "    np.random.seed(10)\n",
    "    shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
    "    x_shuffled = x[shuffle_indices]\n",
    "    y_shuffled = y[shuffle_indices]\n",
    "\n",
    "    # Split train/test set\n",
    "    # TODO: This is very crude, should use cross-validation\n",
    "    dev_sample_index = -1 * int(FLAGS.dev_sample_percentage * float(len(y)))\n",
    "    x_train, x_dev = x_shuffled[:dev_sample_index], x_shuffled[dev_sample_index:]\n",
    "    y_train, y_dev = y_shuffled[:dev_sample_index], y_shuffled[dev_sample_index:]\n",
    "\n",
    "    del x, y, x_shuffled, y_shuffled\n",
    "\n",
    "    print(\"Vocabulary Size: {:d}\".format(len(vocab_processor.vocabulary_)))\n",
    "    print(\"Train/Dev split: {:d}/{:d}\".format(len(y_train), len(y_dev)))\n",
    "    return x_train, y_train, vocab_processor, x_dev, y_dev\n",
    "\n",
    "def train(x_train, y_train, vocab_processor, x_dev, y_dev):\n",
    "    # Training\n",
    "    # ==================================================\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        session_conf = tf.ConfigProto(\n",
    "          allow_soft_placement=FLAGS.allow_soft_placement,\n",
    "          log_device_placement=FLAGS.log_device_placement)\n",
    "        sess = tf.Session(config=session_conf)\n",
    "        with sess.as_default():\n",
    "            cnn = TextCNN(\n",
    "                sequence_length=x_train.shape[1],\n",
    "                num_classes=y_train.shape[1],\n",
    "                vocab_size=len(vocab_processor.vocabulary_),\n",
    "                embedding_size=FLAGS.embedding_dim,\n",
    "                filter_sizes=list(map(int, FLAGS.filter_sizes.split(\",\"))),\n",
    "                num_filters=FLAGS.num_filters,\n",
    "                l2_reg_lambda=FLAGS.l2_reg_lambda)\n",
    "\n",
    "            # Define Training procedure\n",
    "            global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "            optimizer = tf.train.AdamOptimizer(1e-3)\n",
    "            grads_and_vars = optimizer.compute_gradients(cnn.loss)\n",
    "            train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step)\n",
    "\n",
    "            # Keep track of gradient values and sparsity (optional)\n",
    "            grad_summaries = []\n",
    "            for g, v in grads_and_vars:\n",
    "                if g is not None:\n",
    "                    grad_hist_summary = tf.summary.histogram(\"{}/grad/hist\".format(v.name), g)\n",
    "                    sparsity_summary = tf.summary.scalar(\"{}/grad/sparsity\".format(v.name), tf.nn.zero_fraction(g))\n",
    "                    grad_summaries.append(grad_hist_summary)\n",
    "                    grad_summaries.append(sparsity_summary)\n",
    "            grad_summaries_merged = tf.summary.merge(grad_summaries)\n",
    "\n",
    "            # Output directory for models and summaries\n",
    "            out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", timestamp))\n",
    "            print(\"Writing to {}\\n\".format(out_dir))\n",
    "\n",
    "            # Summaries for loss and accuracy\n",
    "            loss_summary = tf.summary.scalar(\"loss\", cnn.loss)\n",
    "            acc_summary = tf.summary.scalar(\"accuracy\", cnn.accuracy)\n",
    "\n",
    "            # Train Summaries\n",
    "            train_summary_op = tf.summary.merge([loss_summary, acc_summary, grad_summaries_merged])\n",
    "            train_summary_dir = os.path.join(out_dir, \"summaries\", \"train\")\n",
    "            train_summary_writer = tf.summary.FileWriter(train_summary_dir, sess.graph)\n",
    "\n",
    "            # Dev summaries\n",
    "            dev_summary_op = tf.summary.merge([loss_summary, acc_summary])\n",
    "            dev_summary_dir = os.path.join(out_dir, \"summaries\", \"dev\")\n",
    "            dev_summary_writer = tf.summary.FileWriter(dev_summary_dir, sess.graph)\n",
    "\n",
    "            # Checkpoint directory. Tensorflow assumes this directory already exists so we need to create it\n",
    "            checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "            checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")\n",
    "            if not os.path.exists(checkpoint_dir):\n",
    "                os.makedirs(checkpoint_dir)\n",
    "            saver = tf.train.Saver(tf.global_variables(), max_to_keep=FLAGS.num_checkpoints)\n",
    "\n",
    "            # Write vocabulary\n",
    "            vocab_processor.save(os.path.join(out_dir, \"vocab\"))\n",
    "\n",
    "            # Initialize all variables\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            def train_step(x_batch, y_batch):\n",
    "                \"\"\"\n",
    "                A single training step\n",
    "                \"\"\"\n",
    "                feed_dict = {\n",
    "                  cnn.input_x: x_batch,\n",
    "                  cnn.input_y: y_batch,\n",
    "                  cnn.dropout_keep_prob: FLAGS.dropout_keep_prob\n",
    "                }\n",
    "                _, step, summaries, loss, accuracy = sess.run(\n",
    "                    [train_op, global_step, train_summary_op, cnn.loss, cnn.accuracy],\n",
    "                    feed_dict)\n",
    "                time_str = datetime.datetime.now().isoformat()\n",
    "                print(\"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy))\n",
    "                train_summary_writer.add_summary(summaries, step)\n",
    "\n",
    "            def dev_step(x_batch, y_batch, writer=None):\n",
    "                \"\"\"\n",
    "                Evaluates model on a dev set\n",
    "                \"\"\"\n",
    "                feed_dict = {\n",
    "                  cnn.input_x: x_batch,\n",
    "                  cnn.input_y: y_batch,\n",
    "                  cnn.dropout_keep_prob: 1.0\n",
    "                }\n",
    "                step, summaries, loss, accuracy = sess.run(\n",
    "                    [global_step, dev_summary_op, cnn.loss, cnn.accuracy],\n",
    "                    feed_dict)\n",
    "                time_str = datetime.datetime.now().isoformat()\n",
    "                print(\"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy))\n",
    "                if writer:\n",
    "                    writer.add_summary(summaries, step)\n",
    "\n",
    "            # Generate batches\n",
    "            batches = batch_iter(\n",
    "                list(zip(x_train, y_train)), FLAGS.batch_size, FLAGS.num_epochs)\n",
    "            # Training loop. For each batch...\n",
    "            for batch in batches:\n",
    "                x_batch, y_batch = zip(*batch)\n",
    "                train_step(x_batch, y_batch)\n",
    "                current_step = tf.train.global_step(sess, global_step)\n",
    "                if current_step % FLAGS.evaluate_every == 0:\n",
    "                    print(\"\\nEvaluation:\")\n",
    "                    dev_step(x_dev, y_dev, writer=dev_summary_writer)\n",
    "                    print(\"\")\n",
    "                if current_step % FLAGS.checkpoint_every == 0:\n",
    "                    path = saver.save(sess, checkpoint_prefix, global_step=current_step)\n",
    "                    print(\"Saved model checkpoint to {}\\n\".format(path))\n",
    "\n",
    "def main(argv=None):\n",
    "    x_train, y_train, vocab_processor, x_dev, y_dev = preprocess()\n",
    "    train(x_train, y_train, vocab_processor, x_dev, y_dev)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('.'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "You can run directly to use the whole dataset for evaluation, or you may split a piece from the training dataset for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from tensorflow.contrib import learn\n",
    "import csv\n",
    "\n",
    "# Parameters\n",
    "# ==================================================\n",
    "\n",
    "# Eval Parameters\n",
    "tf.flags.DEFINE_string(\"checkpoint_dir\", \"./runs/\" + timestamp + \"/checkpoints/\", \"Checkpoint directory from training run\")\n",
    "tf.flags.DEFINE_boolean(\"eval_train\", True, \"Evaluate on all training data\")\n",
    "\n",
    "\n",
    "FLAGS = tf.flags.FLAGS\n",
    "# FLAGS._parse_flags()\n",
    "# print(\"\\nParameters:\")\n",
    "# for attr, value in sorted(FLAGS.__flags.items()):\n",
    "#     print(\"{}={}\".format(attr.upper(), value))\n",
    "# print(\"\")\n",
    "\n",
    "# CHANGE THIS: Load data. Load your own data here\n",
    "if FLAGS.eval_train:\n",
    "    x_raw, y_test = load_data_and_labels(FLAGS.positive_data_file, FLAGS.negative_data_file)\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "else:\n",
    "    x_raw = [\"a masterpiece four years in the making\", \"everything is off.\"]\n",
    "    y_test = [1, 0]\n",
    "\n",
    "# Map data into vocabulary\n",
    "vocab_path = os.path.join(FLAGS.checkpoint_dir, \"..\", \"vocab\")\n",
    "vocab_processor = learn.preprocessing.VocabularyProcessor.restore(vocab_path)\n",
    "x_test = np.array(list(vocab_processor.transform(x_raw)))\n",
    "\n",
    "print(\"\\nEvaluating...\\n\")\n",
    "\n",
    "# Evaluation\n",
    "# ==================================================\n",
    "checkpoint_file = tf.train.latest_checkpoint(FLAGS.checkpoint_dir)\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    session_conf = tf.ConfigProto(\n",
    "      allow_soft_placement=FLAGS.allow_soft_placement,\n",
    "      log_device_placement=FLAGS.log_device_placement)\n",
    "    sess = tf.Session(config=session_conf)\n",
    "    with sess.as_default():\n",
    "        # Load the saved meta graph and restore variables\n",
    "        saver = tf.train.import_meta_graph(\"{}.meta\".format(checkpoint_file))\n",
    "        saver.restore(sess, checkpoint_file)\n",
    "\n",
    "        # Get the placeholders from the graph by name\n",
    "        input_x = graph.get_operation_by_name(\"input_x\").outputs[0]\n",
    "        # input_y = graph.get_operation_by_name(\"input_y\").outputs[0]\n",
    "        dropout_keep_prob = graph.get_operation_by_name(\"dropout_keep_prob\").outputs[0]\n",
    "\n",
    "        # Tensors we want to evaluate\n",
    "        predictions = graph.get_operation_by_name(\"output/predictions\").outputs[0]\n",
    "\n",
    "        # Generate batches for one epoch\n",
    "        batches = batch_iter(list(x_test), FLAGS.batch_size, 1, shuffle=False)\n",
    "\n",
    "        # Collect the predictions here\n",
    "        all_predictions = []\n",
    "\n",
    "        for x_test_batch in batches:\n",
    "            batch_predictions = sess.run(predictions, {input_x: x_test_batch, dropout_keep_prob: 1.0})\n",
    "            all_predictions = np.concatenate([all_predictions, batch_predictions])\n",
    "\n",
    "# Print accuracy if y_test is defined\n",
    "if y_test is not None:\n",
    "    correct_predictions = float(sum(all_predictions == y_test))\n",
    "    print(\"Total number of test examples: {}\".format(len(y_test)))\n",
    "    print(\"Accuracy: {:g}\".format(correct_predictions/float(len(y_test))))\n",
    "\n",
    "# Save the evaluation to a csv\n",
    "predictions_human_readable = np.column_stack((np.array(x_raw), all_predictions))\n",
    "out_path = os.path.join(FLAGS.checkpoint_dir, \"..\", \"prediction.csv\")\n",
    "print(\"Saving evaluation to {0}\".format(out_path))\n",
    "with open(out_path, 'w') as f:\n",
    "    csv.writer(f).writerows(predictions_human_readable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow1.15-cpu]",
   "language": "python",
   "name": "conda-env-tensorflow1.15-cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
